<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Paul Graham's Essays</title>
    <link>https://enigma.github.io/pgrss/rss.xml</link>
    <description>Paul Graham's Essays</description>
    <atom:link href="https://enigma.github.io/pgrss/rss.xml" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>en</language>
    <lastBuildDate>Sun, 25 May 2025 00:01:12 +0000</lastBuildDate>
    <item>
      <title>Superlinear Returns</title>
      <link>https://paulgraham.com//superlinear.html</link>
      <description>&lt;font face="verdana" size="2"&gt;October 2023&lt;br/&gt;&lt;br/&gt;One of the most important things I didn't understand about the world when I was a child is the degree to which the returns for performance are superlinear.&lt;br/&gt;&lt;br/&gt;Teachers and coaches implicitly told us the returns were linear. "You get out," I heard a thousand times, "what you put in." They meant well, but this is rarely true. If your product is only half as good as your competitor's, you don't get half as many customers. You get no customer&lt;/font&gt;</description>
      <content:encoded>&lt;font face="verdana" size="2"&gt;October 2023&lt;br/&gt;&lt;br/&gt;One of the most important things I didn't understand about the world
when I was a child is the degree to which the returns for performance
are superlinear.&lt;br/&gt;&lt;br/&gt;Teachers and coaches implicitly told us the returns were linear.
"You get out," I heard a thousand times, "what you put in." They
meant well, but this is rarely true. If your product is only half
as good as your competitor's, you don't get half as many customers.
You get no customers, and you go out of business.&lt;br/&gt;&lt;br/&gt;It's obviously true that the returns for performance are superlinear
in business. Some think this is a flaw of capitalism, and that if
we changed the rules it would stop being true. But superlinear
returns for performance are a feature of the world, not an artifact
of rules we've invented. We see the same pattern in fame, power,
military victories, knowledge, and even benefit to humanity. In all
of these, the rich get richer.
&lt;font color="#dddddd"&gt;[&lt;a href="#f1n"&gt;&lt;font color="#dddddd"&gt;1&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;You can't understand the world without understanding the concept
of superlinear returns. And if you're ambitious you definitely
should, because this will be the wave you surf on.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;It may seem as if there are a lot of different situations with
superlinear returns, but as far as I can tell they reduce to two
fundamental causes: exponential growth and thresholds.&lt;br/&gt;&lt;br/&gt;The most obvious case of superlinear returns is when you're working
on something that grows exponentially. For example, growing bacterial
cultures. When they grow at all, they grow exponentially. But they're
tricky to grow. Which means the difference in outcome between someone
who's adept at it and someone who's not is very great.&lt;br/&gt;&lt;br/&gt;Startups can also grow exponentially, and we see the same pattern
there. Some manage to achieve high growth rates. Most don't. And
as a result you get qualitatively different outcomes: the companies
with high growth rates tend to become immensely valuable, while the
ones with lower growth rates may not even survive.&lt;br/&gt;&lt;br/&gt;Y Combinator encourages founders to focus on growth rate rather
than absolute numbers. It prevents them from being discouraged early
on, when the absolute numbers are still low. It also helps them
decide what to focus on: you can use growth rate as a compass to
tell you how to evolve the company. But the main advantage is that
by focusing on growth rate you tend to get something that grows
exponentially.&lt;br/&gt;&lt;br/&gt;YC doesn't explicitly tell founders that with growth rate "you get
out what you put in," but it's not far from the truth. And if growth
rate were proportional to performance, then the reward for performance
&lt;i&gt;p&lt;/i&gt; over time &lt;i&gt;t&lt;/i&gt; would be proportional to &lt;i&gt;p&lt;sup&gt;t&lt;/sup&gt;&lt;/i&gt;.&lt;br/&gt;&lt;br/&gt;Even after decades of thinking about this, I find that sentence
startling.&lt;br/&gt;&lt;br/&gt;Whenever how well you do depends on how well you've done, you'll
get exponential growth. But neither our DNA nor our customs prepare
us for it. No one finds exponential growth natural; every child is
surprised, the first time they hear it, by the story of the man who
asks the king for a single grain of rice the first day and double
the amount each successive day.&lt;br/&gt;&lt;br/&gt;What we don't understand naturally we develop customs to deal with,
but we don't have many customs about exponential growth either,
because there have been so few instances of it in human history.
In principle herding should have been one: the more animals you
had, the more offspring they'd have. But in practice grazing land
was the limiting factor, and there was no plan for growing that
exponentially.&lt;br/&gt;&lt;br/&gt;Or more precisely, no generally applicable plan. There &lt;i&gt;was&lt;/i&gt; a way
to grow one's territory exponentially: by conquest. The more territory
you control, the more powerful your army becomes, and the easier
it is to conquer new territory. This is why history is full of
empires. But so few people created or ran empires that their
experiences didn't affect customs very much. The emperor was a
remote and terrifying figure, not a source of lessons one could use
in one's own life.&lt;br/&gt;&lt;br/&gt;The most common case of exponential growth in preindustrial times
was probably scholarship. The more you know, the easier it is to
learn new things. The result, then as now, was that some people
were startlingly more knowledgeable than the rest about certain
topics. But this didn't affect customs much either. Although empires
of ideas can overlap and there can thus be far more emperors, in
preindustrial times this type of empire had little practical effect.
&lt;font color="#dddddd"&gt;[&lt;a href="#f2n"&gt;&lt;font color="#dddddd"&gt;2&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;That has changed in the last few centuries. Now the emperors of
ideas can design bombs that defeat the emperors of territory. But
this phenomenon is still so new that we haven't fully assimilated
it. Few even of the participants realize they're benefitting from
exponential growth or ask what they can learn from other instances
of it.&lt;br/&gt;&lt;br/&gt;The other source of superlinear returns is embodied in the expression
"winner take all." In a sports match the relationship between
performance and return is a step function: the winning team gets
one win whether they do much better or just slightly better.
&lt;font color="#dddddd"&gt;[&lt;a href="#f3n"&gt;&lt;font color="#dddddd"&gt;3&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;The source of the step function is not competition per se, however.
It's that there are thresholds in the outcome. You don't need
competition to get those. There can be thresholds in situations
where you're the only participant, like proving a theorem or hitting
a target.&lt;br/&gt;&lt;br/&gt;It's remarkable how often a situation with one source of superlinear
returns also has the other. Crossing thresholds leads to exponential
growth: the winning side in a battle usually suffers less damage,
which makes them more likely to win in the future. And exponential
growth helps you cross thresholds: in a market with network effects,
a company that grows fast enough can shut out potential competitors.&lt;br/&gt;&lt;br/&gt;Fame is an interesting example of a phenomenon that combines both
sources of superlinear returns. Fame grows exponentially because
existing fans bring you new ones. But the fundamental reason it's
so concentrated is thresholds: there's only so much room on the
A-list in the average person's head.&lt;br/&gt;&lt;br/&gt;The most important case combining both sources of superlinear returns
may be learning. Knowledge grows exponentially, but there are also
thresholds in it. Learning to ride a bicycle, for example. Some of
these thresholds are akin to machine tools: once you learn to read,
you're able to learn anything else much faster. But the most important
thresholds of all are those representing new discoveries. Knowledge
seems to be fractal in the sense that if you push hard at the
boundary of one area of knowledge, you sometimes discover a whole
new field. And if you do, you get first crack at all the new
discoveries to be made in it. Newton did this, and so did Durer and
Darwin.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
Are there general rules for finding situations with superlinear
returns? The most obvious one is to seek work that compounds.&lt;br/&gt;&lt;br/&gt;There are two ways work can compound. It can compound directly, in
the sense that doing well in one cycle causes you to do better in
the next. That happens for example when you're building infrastructure,
or growing an audience or brand. Or work can compound by teaching
you, since learning compounds. This second case is an interesting
one because you may feel you're doing badly as it's happening. You
may be failing to achieve your immediate goal. But if you're learning
a lot, then you're getting exponential growth nonetheless.&lt;br/&gt;&lt;br/&gt;This is one reason Silicon Valley is so tolerant of failure. People
in Silicon Valley aren't blindly tolerant of failure. They'll only
continue to bet on you if you're learning from your failures. But
if you are, you are in fact a good bet: maybe your company didn't
grow the way you wanted, but you yourself have, and that should
yield results eventually.&lt;br/&gt;&lt;br/&gt;Indeed, the forms of exponential growth that don't consist of
learning are so often intermixed with it that we should probably
treat this as the rule rather than the exception. Which yields
another heuristic: always be learning. If you're not learning,
you're probably not on a path that leads to superlinear returns.&lt;br/&gt;&lt;br/&gt;But don't overoptimize &lt;i&gt;what&lt;/i&gt; you're learning. Don't limit yourself
to learning things that are already known to be valuable. You're
learning; you don't know for sure yet what's going to be valuable,
and if you're too strict you'll lop off the outliers.&lt;br/&gt;&lt;br/&gt;What about step functions? Are there also useful heuristics of the
form "seek thresholds" or "seek competition?" Here the situation
is trickier. The existence of a threshold doesn't guarantee the
game will be worth playing. If you play a round of Russian roulette,
you'll be in a situation with a threshold, certainly, but in the
best case you're no better off. "Seek competition" is similarly
useless; what if the prize isn't worth competing for? Sufficiently
fast exponential growth guarantees both the shape and magnitude of
the return curve — because something that grows fast enough will
grow big even if it's trivially small at first — but thresholds
only guarantee the shape.
&lt;font color="#dddddd"&gt;[&lt;a href="#f4n"&gt;&lt;font color="#dddddd"&gt;4&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;A principle for taking advantage of thresholds has to include a
test to ensure the game is worth playing. Here's one that does: if
you come across something that's mediocre yet still popular, it
could be a good idea to replace it. For example, if a company makes
a product that people dislike yet still buy, then presumably they'd
buy a better alternative if you made one.
&lt;font color="#dddddd"&gt;[&lt;a href="#f5n"&gt;&lt;font color="#dddddd"&gt;5&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;It would be great if there were a way to find promising intellectual
thresholds. Is there a way to tell which questions have whole new
fields beyond them? I doubt we could ever predict this with certainty,
but the prize is so valuable that it would be useful to have
predictors that were even a little better than random, and there's
hope of finding those. We can to some degree predict when a research
problem &lt;i&gt;isn't&lt;/i&gt; likely to lead to new discoveries: when it seems
legit but boring. Whereas the kind that do lead to new discoveries
tend to seem very mystifying, but perhaps unimportant. (If they
were mystifying and obviously important, they'd be famous open
questions with lots of people already working on them.) So one
heuristic here is to be driven by curiosity rather than careerism
— to give free rein to your curiosity instead of working on what
you're supposed to.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
The prospect of superlinear returns for performance is an exciting
one for the ambitious. And there's good news in this department:
this territory is expanding in both directions. There are more types
of work in which you can get superlinear returns, and the returns
themselves are growing.&lt;br/&gt;&lt;br/&gt;There are two reasons for this, though they're so closely intertwined
that they're more like one and a half: progress in technology, and
the decreasing importance of organizations.&lt;br/&gt;&lt;br/&gt;Fifty years ago it used to be much more necessary to be part of an
organization to work on ambitious projects. It was the only way to
get the resources you needed, the only way to have colleagues, and
the only way to get distribution. So in 1970 your prestige was in
most cases the prestige of the organization you belonged to. And
prestige was an accurate predictor, because if you weren't part of
an organization, you weren't likely to achieve much. There were a
handful of exceptions, most notably artists and writers, who worked
alone using inexpensive tools and had their own brands. But even
they were at the mercy of organizations for reaching audiences.
&lt;font color="#dddddd"&gt;[&lt;a href="#f6n"&gt;&lt;font color="#dddddd"&gt;6&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;A world dominated by organizations damped variation in the returns
for performance. But this world has eroded significantly just in
my lifetime. Now a lot more people can have the freedom that artists
and writers had in the 20th century. There are lots of ambitious
projects that don't require much initial funding, and lots of new
ways to learn, make money, find colleagues, and reach audiences.&lt;br/&gt;&lt;br/&gt;There's still plenty of the old world left, but the rate of change
has been dramatic by historical standards. Especially considering
what's at stake. It's hard to imagine a more fundamental change
than one in the returns for performance.&lt;br/&gt;&lt;br/&gt;Without the damping effect of institutions, there will be more
variation in outcomes. Which doesn't imply everyone will be better
off: people who do well will do even better, but those who do badly
will do worse. That's an important point to bear in mind. Exposing
oneself to superlinear returns is not for everyone. Most people
will be better off as part of the pool. So who should shoot for
superlinear returns? Ambitious people of two types: those who know
they're so good that they'll be net ahead in a world with higher
variation, and those, particularly the young, who can afford to
risk trying it to find out.
&lt;font color="#dddddd"&gt;[&lt;a href="#f7n"&gt;&lt;font color="#dddddd"&gt;7&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;The switch away from institutions won't simply be an exodus of their
current inhabitants. Many of the new winners will be people they'd
never have let in. So the resulting democratization of opportunity
will be both greater and more authentic than any tame intramural
version the institutions themselves might have cooked up.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
Not everyone is happy about this great unlocking of ambition. It
threatens some vested interests and contradicts some ideologies. &lt;font color="#dddddd"&gt;[&lt;a href="#f8n"&gt;&lt;font color="#dddddd"&gt;8&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;
But if you're an ambitious individual it's good news for you.
How should you take advantage of it?&lt;br/&gt;&lt;br/&gt;The most obvious way to take advantage of superlinear returns for
performance is by doing exceptionally good work. At the far end of
the curve, incremental effort is a bargain. All the more so because
there's less competition at the far end — and not just for the
obvious reason that it's hard to do something exceptionally well,
but also because people find the prospect so intimidating that few
even try. Which means it's not just a bargain to do exceptional
work, but a bargain even to try to.&lt;br/&gt;&lt;br/&gt;There are many variables that affect how good your work is, and if
you want to be an outlier you need to get nearly all of them right.
For example, to do something exceptionally well, you have to be
interested in it. Mere diligence is not enough. So in a world with
superlinear returns, it's even more valuable to know what you're
interested in, and to find ways to work on it.
&lt;font color="#dddddd"&gt;[&lt;a href="#f9n"&gt;&lt;font color="#dddddd"&gt;9&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;
It will also be
important to choose work that suits your circumstances. For example,
if there's a kind of work that inherently requires a huge expenditure
of time and energy, it will be increasingly valuable to do it when
you're young and don't yet have children.&lt;br/&gt;&lt;br/&gt;There's a surprising amount of technique to doing great work.
It's not just a matter of trying hard. I'm going to take a shot
giving a recipe in one paragraph.&lt;br/&gt;&lt;br/&gt;Choose work you have a natural aptitude for and a deep interest in.
Develop a habit of working on your own projects; it doesn't matter
what they are so long as you find them excitingly ambitious. Work
as hard as you can without burning out, and this will eventually
bring you to one of the frontiers of knowledge. These look smooth
from a distance, but up close they're full of gaps. Notice and
explore such gaps, and if you're lucky one will expand into a whole
new field. Take as much risk as you can afford; if you're not failing
occasionally you're probably being too conservative. Seek out the
best colleagues. Develop good taste and learn from the best examples.
Be honest, especially with yourself. Exercise and eat and sleep
well and avoid the more dangerous drugs. When in doubt, follow your
curiosity. It never lies, and it knows more than you do about what's
worth paying attention to.
&lt;font color="#dddddd"&gt;[&lt;a href="#f10n"&gt;&lt;font color="#dddddd"&gt;10&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;And there is of course one other thing you need: to be lucky. Luck
is always a factor, but it's even more of a factor when you're
working on your own rather than as part of an organization. And
though there are some valid aphorisms about luck being where
preparedness meets opportunity and so on, there's also a component
of true chance that you can't do anything about. The solution is
to take multiple shots. Which is another reason to start taking
risks early.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
The best example of a field with superlinear returns is probably
science. It has exponential growth, in the form of learning, combined
with thresholds at the extreme edge of performance — literally at
the limits of knowledge.&lt;br/&gt;&lt;br/&gt;The result has been a level of inequality in scientific discovery
that makes the wealth inequality of even the most stratified societies
seem mild by comparison. Newton's discoveries were arguably greater
than all his contemporaries' combined.
&lt;font color="#dddddd"&gt;[&lt;a href="#f11n"&gt;&lt;font color="#dddddd"&gt;11&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;This point may seem obvious, but it might be just as well to spell
it out. Superlinear returns imply inequality. The steeper the return
curve, the greater the variation in outcomes.&lt;br/&gt;&lt;br/&gt;In fact, the correlation between superlinear returns and inequality
is so strong that it yields another heuristic for finding work of
this type: look for fields where a few big winners outperform
everyone else. A kind of work where everyone does about the same
is unlikely to be one with superlinear returns.&lt;br/&gt;&lt;br/&gt;What are fields where a few big winners outperform everyone else?
Here are some obvious ones: sports, politics, art, music, acting,
directing, writing, math, science, starting companies, and investing.
In sports the phenomenon is due to externally imposed thresholds;
you only need to be a few percent faster to win every race. In
politics, power grows much as it did in the days of emperors. And
in some of the other fields (including politics) success is driven
largely by fame, which has its own source of superlinear growth.
But when we exclude sports and politics and the effects of fame, a
remarkable pattern emerges: the remaining list is exactly the same
as the list of fields where you have to be &lt;a href="think.html"&gt;&lt;u&gt;independent-minded&lt;/u&gt;&lt;/a&gt; to
succeed — where your ideas have to be not just correct, but novel
as well.
&lt;font color="#dddddd"&gt;[&lt;a href="#f12n"&gt;&lt;font color="#dddddd"&gt;12&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;This is obviously the case in science. You can't publish papers
saying things that other people have already said. But it's just
as true in investing, for example. It's only useful to believe that
a company will do well if most other investors don't; if everyone
else thinks the company will do well, then its stock price will
already reflect that, and there's no room to make money.&lt;br/&gt;&lt;br/&gt;What else can we learn from these fields? In all of them you have
to put in the initial effort. Superlinear returns seem small at
first. &lt;i&gt;At this rate,&lt;/i&gt; you find yourself thinking, &lt;i&gt;I'll never get
anywhere.&lt;/i&gt; But because the reward curve rises so steeply at the far
end, it's worth taking extraordinary measures to get there.&lt;br/&gt;&lt;br/&gt;In the startup world, the name for this principle is "do things
that don't scale." If you pay a ridiculous amount of attention to
your tiny initial set of customers, ideally you'll kick off exponential
growth by word of mouth. But this same principle applies to anything
that grows exponentially. Learning, for example. When you first
start learning something, you feel lost. But it's worth making the
initial effort to get a toehold, because the more you learn, the
easier it will get.&lt;br/&gt;&lt;br/&gt;There's another more subtle lesson in the list of fields with
superlinear returns: not to equate work with a job. For most of the
20th century the two were identical for nearly everyone, and as a
result we've inherited a custom that equates productivity with
having a job. Even now to most people the phrase "your work" means
their job. But to a writer or artist or scientist it means whatever
they're currently studying or creating. For someone like that, their
work is something they carry with them from job to job, if they
have jobs at all. It may be done for an employer, but it's part of
their portfolio.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
It's an intimidating prospect to enter a field where a few big
winners outperform everyone else. Some people do this deliberately,
but you don't need to. If you have sufficient natural ability and
you follow your curiosity sufficiently far, you'll end up in one.
Your curiosity won't let you be interested in boring questions, and
interesting questions tend to create fields with superlinear returns
if they're not already part of one.&lt;br/&gt;&lt;br/&gt;The territory of superlinear returns is by no means static. Indeed,
the most extreme returns come from expanding it. So while both
ambition and curiosity can get you into this territory, curiosity
may be the more powerful of the two. Ambition tends to make you
climb existing peaks, but if you stick close enough to an interesting
enough question, it may grow into a mountain beneath you.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;Notes&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;There's a limit to how sharply you can distinguish between effort,
performance, and return, because they're not sharply distinguished
in fact. What counts as return to one person might be performance
to another. But though the borders of these concepts are blurry,
they're not meaningless. I've tried to write about them as precisely
as I could without crossing into error.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f1n"&gt;&lt;font color="#000000"&gt;1&lt;/font&gt;&lt;/a&gt;]
Evolution itself is probably the most pervasive example of
superlinear returns for performance. But this is hard for us to
empathize with because we're not the recipients; we're the returns.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f2n"&gt;&lt;font color="#000000"&gt;2&lt;/font&gt;&lt;/a&gt;]
Knowledge did of course have a practical effect before the
Industrial Revolution. The development of agriculture changed human
life completely. But this kind of change was the result of broad,
gradual improvements in technique, not the discoveries of a few
exceptionally learned people.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f3n"&gt;&lt;font color="#000000"&gt;3&lt;/font&gt;&lt;/a&gt;]
It's not mathematically correct to describe a step function as
superlinear, but a step function starting from zero works like a
superlinear function when it describes the reward curve for effort
by a rational actor. If it starts at zero then the part before the
step is below any linearly increasing return, and the part after
the step must be above the necessary return at that point or no one
would bother.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f4n"&gt;&lt;font color="#000000"&gt;4&lt;/font&gt;&lt;/a&gt;]
Seeking competition could be a good heuristic in the sense that
some people find it motivating. It's also somewhat of a guide to
promising problems, because it's a sign that other people find them
promising. But it's a very imperfect sign: often there's a clamoring
crowd chasing some problem, and they all end up being trumped by
someone quietly working on another one.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f5n"&gt;&lt;font color="#000000"&gt;5&lt;/font&gt;&lt;/a&gt;]
Not always, though. You have to be careful with this rule. When
something is popular despite being mediocre, there's often a hidden
reason why. Perhaps monopoly or regulation make it hard to compete.
Perhaps customers have bad taste or have broken procedures for
deciding what to buy. There are huge swathes of mediocre things
that exist for such reasons.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f6n"&gt;&lt;font color="#000000"&gt;6&lt;/font&gt;&lt;/a&gt;]
In my twenties I wanted to be an &lt;a href="worked.html"&gt;&lt;u&gt;artist&lt;/u&gt;&lt;/a&gt; 
and even went to art
school to study painting. Mostly because I liked art, but a nontrivial
part of my motivation came from the fact that artists seemed least
at the mercy of organizations.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f7n"&gt;&lt;font color="#000000"&gt;7&lt;/font&gt;&lt;/a&gt;]
In principle everyone is getting superlinear returns. Learning
compounds, and everyone learns in the course of their life. But in
practice few push this kind of everyday learning to the point where
the return curve gets really steep.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f8n"&gt;&lt;font color="#000000"&gt;8&lt;/font&gt;&lt;/a&gt;]
It's unclear exactly what advocates of "equity" mean by it.
They seem to disagree among themselves. But whatever they mean is
probably at odds with a world in which institutions have less power
to control outcomes, and a handful of outliers do much better than
everyone else.&lt;br/&gt;&lt;br/&gt;It may seem like bad luck for this concept that it arose at just
the moment when the world was shifting in the opposite direction,
but I don't think this was a coincidence. I think one reason it
arose now is because its adherents feel threatened by rapidly
increasing variation in performance.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f9n"&gt;&lt;font color="#000000"&gt;9&lt;/font&gt;&lt;/a&gt;]
Corollary: Parents who pressure their kids to work on something
prestigious, like medicine, even though they have no interest in
it, will be hosing them even more than they have in the past.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f10n"&gt;&lt;font color="#000000"&gt;10&lt;/font&gt;&lt;/a&gt;]
The original version of this paragraph was the first draft of
"&lt;a href="greatwork.html"&gt;&lt;u&gt;How to Do Great Work&lt;/u&gt;&lt;/a&gt;." 
As soon as I wrote it I realized it was a more important topic than superlinear
returns, so I paused the present essay to expand this paragraph into its
own. Practically nothing remains of the original version, because
after I finished "How to Do Great Work" I rewrote it based on that.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f11n"&gt;&lt;font color="#000000"&gt;11&lt;/font&gt;&lt;/a&gt;]
Before the Industrial Revolution, people who got rich usually
did it like emperors: capturing some resource made them more powerful
and enabled them to capture more. Now it can be done like a scientist,
by discovering or building something uniquely valuable. Most people
who get rich use a mix of the old and the new ways, but in the most
advanced economies the ratio has &lt;a href="richnow.html"&gt;&lt;u&gt;shifted dramatically&lt;/u&gt;&lt;/a&gt; toward discovery
just in the last half century.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f12n"&gt;&lt;font color="#000000"&gt;12&lt;/font&gt;&lt;/a&gt;]
It's not surprising that conventional-minded people would
dislike inequality if independent-mindedness is one of the biggest
drivers of it. But it's not simply that they don't want anyone to
have what they can't. The conventional-minded literally can't imagine
what it's like to have novel ideas. So the whole phenomenon of great
variation in performance seems unnatural to them, and when they
encounter it they assume it must be due to cheating or to some
malign external influence.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;font color="888888"&gt;&lt;b&gt;Thanks&lt;/b&gt; 
to Trevor Blackwell, Patrick Collison, Tyler Cowen,
Jessica Livingston, Harj Taggar, and Garry Tan for reading drafts
of this.&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;&lt;/font&gt;</content:encoded>
      <guid isPermaLink="false">https://paulgraham.com//superlinear.html</guid>
      <pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>The Best Essay</title>
      <link>https://paulgraham.com//best.html</link>
      <description>&lt;font face="verdana" size="2"&gt;March 2024&lt;br/&gt;&lt;br/&gt;Despite its title this isn't meant to be the best essay. My goal here is to figure out what the best essay would be like.&lt;br/&gt;&lt;br/&gt;It would be well-written, but you can write well about any topic. What made it special would be what it was about.&lt;br/&gt;&lt;br/&gt;Obviously some topics would be better than others. It probably wouldn't be about this year's lipstick colors. But it wouldn't be vaporous talk about elevated themes either. A good essay has to be&lt;/font&gt;</description>
      <content:encoded>&lt;font face="verdana" size="2"&gt;March 2024&lt;br/&gt;&lt;br/&gt;Despite its title this isn't meant to be the best essay. My goal
here is to figure out what the best essay would be like.&lt;br/&gt;&lt;br/&gt;It would be well-written, but you can write well about any topic.
What made it special would be what it was about.&lt;br/&gt;&lt;br/&gt;Obviously some topics would be better than others. It probably
wouldn't be about this year's lipstick colors. But it wouldn't be
vaporous talk about elevated themes either. A good essay has to be
surprising. It has to tell people something they don't already know.&lt;br/&gt;&lt;br/&gt;The best essay would be on the most important topic you could tell
people something surprising about.&lt;br/&gt;&lt;br/&gt;That may sound obvious, but it has some unexpected consequences.
One is that science enters the picture like an elephant stepping
into a rowboat. For example, Darwin first described the idea of
natural selection in an essay written in 1844.
Talk about an
important topic you could tell people something surprising about.
If that's the test of a great essay, this was surely the best one
written in 1844. 
And indeed, the best possible essay at any given
time would usually be one describing the most important scientific
or technological discovery it was possible to make.
&lt;font color="#dddddd"&gt;[&lt;a href="#f1n"&gt;&lt;font color="#dddddd"&gt;1&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;Another unexpected consequence: I imagined when I started writing
this that the best essay would be fairly timeless — that the best
essay you could write in 1844 would be much the same as the best
one you could write now. But in fact the opposite seems to be true.
It might be true that the best painting would be timeless in this
sense. But it wouldn't be impressive to write an essay introducing
natural selection now. The best essay &lt;i&gt;now&lt;/i&gt; would be one describing
a great discovery we didn't yet know about.&lt;br/&gt;&lt;br/&gt;If the question of how to write the best possible essay reduces to
the question of how to make great discoveries, then I started with
the wrong question. Perhaps what this exercise shows is that we
shouldn't waste our time writing essays but instead focus on making
discoveries in some specific domain. But I'm interested in essays
and what can be done with them, so I want to see if there's some
other question I could have asked.&lt;br/&gt;&lt;br/&gt;There is, and on the face of it, it seems almost identical to the
one I started with. Instead of asking &lt;i&gt;what would the best essay
be?&lt;/i&gt; I should have asked &lt;i&gt;how do you write essays well?&lt;/i&gt; Though
these seem only phrasing apart, their answers diverge. The answer
to the first question, as we've seen, isn't really about essay
writing. The second question forces it to be.&lt;br/&gt;&lt;br/&gt;Writing essays, at its best, is a way of discovering ideas. How do
you do that well? How do you discover by writing?&lt;br/&gt;&lt;br/&gt;An essay should ordinarily start with what I'm going to call a
question, though I mean this in a very general sense: it doesn't
have to be a question grammatically, just something that acts like
one in the sense that it spurs some response.&lt;br/&gt;&lt;br/&gt;How do you get this initial question? It probably won't work to
choose some important-sounding topic at random and go at it.
Professional traders won't even trade unless they have what they
call an &lt;i&gt;edge&lt;/i&gt; — a convincing story about why in some class of
trades they'll win more than they lose. Similarly, you shouldn't
attack a topic unless you have a way in — some new insight about
it or way of approaching it.&lt;br/&gt;&lt;br/&gt;You don't need to have a complete thesis; you just need some kind
of gap you can explore. In fact, merely having questions about
something other people take for granted can be edge enough.&lt;br/&gt;&lt;br/&gt;If you come across a question that's sufficiently puzzling, it could
be worth exploring even if it doesn't seem very momentous. Many an
important discovery has been made by pulling on a thread that seemed
insignificant at first. How can they &lt;i&gt;all&lt;/i&gt; be finches? 
&lt;font color="#dddddd"&gt;[&lt;a href="#f2n"&gt;&lt;font color="#dddddd"&gt;2&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;Once you've got a question, then what? You start thinking out loud
about it. Not literally out loud, but you commit to a specific
string of words in response, as you would if you were talking. This
initial response is usually mistaken or incomplete. Writing converts
your ideas from vague to bad. But that's a step forward, because
once you can see the brokenness, you can fix it.&lt;br/&gt;&lt;br/&gt;Perhaps beginning writers are alarmed at the thought of starting
with something mistaken or incomplete, but you shouldn't be, because
this is why essay writing works. Forcing yourself to commit to some
specific string of words gives you a starting point, and if it's
wrong, you'll see that when you reread it. At least half of essay
writing is rereading what you've written and asking &lt;i&gt;is this correct
and complete?&lt;/i&gt; You have to be very strict when rereading, not just
because you want to keep yourself honest, but because a gap between
your response and the truth is often a sign of new ideas to be
discovered.&lt;br/&gt;&lt;br/&gt;The prize for being strict with what you've written is not just
refinement. When you take a roughly correct answer and try to make
it exactly right, sometimes you find that you can't, and that the
reason is that you were depending on a false assumption. And when
you discard it, the answer turns out to be completely different.
&lt;font color="#dddddd"&gt;[&lt;a href="#f3n"&gt;&lt;font color="#dddddd"&gt;3&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;Ideally the response to a question is two things: the first step
in a process that converges on the truth, and a source of additional
questions (in my very general sense of the word). So the process
continues recursively, as response spurs response. 
&lt;font color="#dddddd"&gt;[&lt;a href="#f4n"&gt;&lt;font color="#dddddd"&gt;4&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;Usually there are several possible responses to a question, which
means you're traversing a tree. But essays are linear, not tree-shaped,
which means you have to choose one branch to follow at each point.
How do you choose? Usually you should follow whichever offers the
greatest combination of generality and novelty. I don't consciously
rank branches this way; I just follow whichever seems most exciting;
but generality and novelty are what make a branch exciting. 
&lt;font color="#dddddd"&gt;[&lt;a href="#f5n"&gt;&lt;font color="#dddddd"&gt;5&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;If you're willing to do a lot of rewriting, you don't have to guess
right. You can follow a branch and see how it turns out, and if it
isn't good enough, cut it and backtrack. I do this all the time.
In this essay I've already cut a 17-paragraph subtree, in addition
to countless shorter ones. Maybe I'll reattach it at the end, or
boil it down to a footnote, or spin it off as its own essay; we'll
see. 
&lt;font color="#dddddd"&gt;[&lt;a href="#f6n"&gt;&lt;font color="#dddddd"&gt;6&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;In general you want to be quick to cut. One of the most dangerous
temptations in writing (and in software and painting) is to keep
something that isn't right, just because it contains a few good bits
or cost you a lot of effort.&lt;br/&gt;&lt;br/&gt;The most surprising new question being thrown off at this point is
&lt;i&gt;does it really matter what the initial question is?&lt;/i&gt; If the space
of ideas is highly connected, it shouldn't, because you should be
able to get from any question to the most valuable ones in a few
hops. And we see evidence that it's highly connected in the way,
for example, that people who are obsessed with some topic can turn
any conversation toward it. But that only works if you know where
you want to go, and you don't in an essay. That's the whole point.
You don't want to be the obsessive conversationalist, or all your
essays will be about the same thing. 
&lt;font color="#dddddd"&gt;[&lt;a href="#f7n"&gt;&lt;font color="#dddddd"&gt;7&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;The other reason the initial question matters is that you usually
feel somewhat obliged to stick to it. I don't think about this when
I decide which branch to follow. I just follow novelty and generality.
Sticking to the question is enforced later, when I notice I've
wandered too far and have to backtrack. But I think this is
the optimal solution. You don't want the hunt for novelty and
generality to be constrained in the moment. Go with it and see what
you get.
&lt;font color="#dddddd"&gt;[&lt;a href="#f8n"&gt;&lt;font color="#dddddd"&gt;8&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;Since the initial question does constrain you, in the best case it
sets an upper bound on the quality of essay you'll write. If you
do as well as you possibly can on the chain of thoughts that follow
from the initial question, the initial question itself is the only
place where there's room for variation.&lt;br/&gt;&lt;br/&gt;It would be a mistake to let this make you too conservative though,
because you can't predict where a question will lead. Not if you're
doing things right, because doing things right means making
discoveries, and by definition you can't predict those. So the way
to respond to this situation is not to be cautious about which
initial question you choose, but to write a lot of essays. Essays
are for taking risks.&lt;br/&gt;&lt;br/&gt;Almost any question can get you a good essay. Indeed, it took some
effort to think of a sufficiently unpromising topic in the third
paragraph, because any essayist's first impulse on hearing that the
best essay couldn't be about x would be to try to write it. But if
most questions yield good essays, only some yield great ones.&lt;br/&gt;&lt;br/&gt;Can we predict which questions will yield great essays? Considering
how long I've been writing essays, it's alarming how novel that
question feels.&lt;br/&gt;&lt;br/&gt;One thing I like in an initial question is outrageousness. I love
questions that seem naughty in some way — for example, by seeming
counterintuitive or overambitious or heterodox. Ideally all three.
This essay is an example. Writing about the best essay implies there
is such a thing, which pseudo-intellectuals will dismiss as reductive,
though it follows necessarily from the possibility of one essay
being better than another. And thinking about how to do something
so ambitious is close enough to doing it that it holds your attention.&lt;br/&gt;&lt;br/&gt;I like to start an essay with a gleam in my eye. This could be just
a taste of mine, but there's one aspect of it that probably isn't:
to write a really good essay on some topic, you have to be interested
in it. A good writer can write well about anything, but to stretch
for the novel insights that are the raison d'etre of the essay, you
have to care.&lt;br/&gt;&lt;br/&gt;If caring about it is one of the criteria for a good initial question,
then the optimal question varies from person to person. It also
means you're more likely to write great essays if you care about a
lot of different things. The more curious you are, the greater the
probable overlap between the set of things you're curious about and
the set of topics that yield great essays.&lt;br/&gt;&lt;br/&gt;What other qualities would a great initial question have? It's
probably good if it has implications in a lot of different areas.
And I find it's a good sign if it's one that people think has already
been thoroughly explored. But the truth is that I've barely thought
about how to choose initial questions, because I rarely do it. I
rarely &lt;i&gt;choose&lt;/i&gt; what to write about; I just start thinking about
something, and sometimes it turns into an essay.&lt;br/&gt;&lt;br/&gt;Am I going to stop writing essays about whatever I happen to be
thinking about and instead start working my way through some
systematically generated list of topics? That doesn't sound like
much fun. And yet I want to write good essays, and if the initial
question matters, I should care about it.&lt;br/&gt;&lt;br/&gt;Perhaps the answer is to go one step earlier: to write about whatever
pops into your head, but try to ensure that what pops into your
head is good. Indeed, now that I think about it, this has to be the
answer, because a mere list of topics wouldn't be any use if you
didn't have edge with any of them. To start writing an essay, you
need a topic plus some initial insight about it, and you can't
generate those systematically. If only. 
&lt;font color="#dddddd"&gt;[&lt;a href="#f9n"&gt;&lt;font color="#dddddd"&gt;9&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;You can probably cause yourself to have more of them, though. The
quality of the ideas that come out of your head depends on what goes
in, and you can improve that in two dimensions, breadth and depth.&lt;br/&gt;&lt;br/&gt;You can't learn everything, so getting breadth implies learning
about topics that are very different from one another. When I tell
people about my book-buying trips to Hay and they ask what I buy
books about, I usually feel a bit sheepish answering, because the
topics seem like a laundry list of unrelated subjects. But perhaps
that's actually optimal in this business.&lt;br/&gt;&lt;br/&gt;You can also get ideas by talking to people, by doing and building
things, and by going places and seeing things. I don't think it's
important to talk to new people so much as the sort of people who
make you have new ideas. I get more new ideas after talking for an
afternoon with Robert Morris than from talking to 20 new smart
people. I know because that's what a block of office hours at Y
Combinator consists of.&lt;br/&gt;&lt;br/&gt;While breadth comes from reading and talking and seeing, depth comes
from doing. The way to really learn about some domain is to have
to solve problems in it. Though this could take the form of writing,
I suspect that to be a good essayist you also have to do, or have
done, some other kind of work. That may not be true for most other
fields, but essay writing is different. You could spend half your
time working on something else and be net ahead, so long as it was
hard.&lt;br/&gt;&lt;br/&gt;I'm not proposing that as a recipe so much as an encouragement to
those already doing it. If you've spent all your life so far working
on other things, you're already halfway there. Though of course to
be good at writing you have to like it, and if you like writing
you'd probably have spent at least some time doing it.&lt;br/&gt;&lt;br/&gt;Everything I've said about initial questions applies also to the
questions you encounter in writing the essay. They're the same
thing; every subtree of an essay is usually a shorter essay, just
as every subtree of a Calder mobile is a smaller mobile. So any
technique that gets you good initial questions also gets you good
whole essays.&lt;br/&gt;&lt;br/&gt;At some point the cycle of question and response reaches what feels
like a natural end. Which is a little suspicious; shouldn't every
answer suggest more questions? I think what happens is that you
start to feel sated. Once you've covered enough interesting ground,
you start to lose your appetite for new questions. Which is just
as well, because the reader is probably feeling sated too. And it's
not lazy to stop asking questions, because you could instead be
asking the initial question of a new essay.&lt;br/&gt;&lt;br/&gt;That's the ultimate source of drag on the connectedness of ideas:
the discoveries you make along the way. If you discover enough
starting from question A, you'll never make it to question B. Though
if you keep writing essays you'll gradually fix this problem by
burning off such discoveries. So bizarrely enough, writing lots of
essays makes it as if the space of ideas were more highly connected.&lt;br/&gt;&lt;br/&gt;When a subtree comes to an end, you can do one of two things. You
can either stop, or pull the Cubist trick of laying separate subtrees
end to end by returning to a question you skipped earlier. Usually
it requires some sleight of hand to make the essay flow continuously
at this point, but not this time. This time I actually need an
example of the phenomenon. For example, we discovered earlier that
the best possible essay wouldn't usually be timeless in the way the
best painting would. This seems surprising enough to be
worth investigating further.&lt;br/&gt;&lt;br/&gt;There are two senses in which an essay can be timeless: to be about
a matter of permanent importance, and always to have the same effect
on readers. With art these two senses blend together. Art that
looked beautiful to the ancient Greeks still looks beautiful to us.
But with essays the two senses diverge, because essays
teach, and you can't teach people something they already know.
Natural selection is certainly a matter of permanent importance,
but an essay explaining it couldn't have the same effect on us that
it would have had on Darwin's contemporaries, precisely because his
ideas were so successful that everyone already knows about them.
&lt;font color="#dddddd"&gt;[&lt;a href="#f10n"&gt;&lt;font color="#dddddd"&gt;10&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;I imagined when I started writing this that the best possible essay
would be timeless in the stricter, evergreen sense: that it would
contain some deep, timeless wisdom that would appeal equally to
Aristotle and Feynman. That doesn't seem to be true. But if the
best possible essay wouldn't usually be timeless in this stricter
sense, what would it take to write essays that were?&lt;br/&gt;&lt;br/&gt;The answer to that turns out to be very strange: to be the evergreen
kind of timeless, an essay has to be ineffective, in the sense that
its discoveries aren't assimilated into our shared culture. Otherwise
there will be nothing new in it for the second generation of readers.
If you want to surprise readers not just now but in the future as
well, you have to write essays that won't stick — essays that,
no matter how good they are, won't become part of what people in
the future learn before they read them. 
&lt;font color="#dddddd"&gt;[&lt;a href="#f11n"&gt;&lt;font color="#dddddd"&gt;11&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;I can imagine several ways to do that. One would be to write about
things people never learn. For example, it's a long-established
pattern for ambitious people to chase after various types of prizes,
and only later, perhaps too late, to realize that some of them
weren't worth as much as they thought. If you write about that, you
can be confident of a conveyor belt of future readers to be surprised
by it.&lt;br/&gt;&lt;br/&gt;Ditto if you write about the tendency of the inexperienced to overdo
things — of young engineers to produce overcomplicated solutions,
for example. There are some kinds of mistakes people never learn
to avoid except by making them. Any of those should be a timeless
topic.&lt;br/&gt;&lt;br/&gt;Sometimes when we're slow to grasp things it's not just because
we're obtuse or in denial but because we've been deliberately lied
to. There are a lot of things adults &lt;a href="lies.html"&gt;&lt;u&gt;lie&lt;/u&gt;&lt;/a&gt; 
to kids about, and when
you reach adulthood, they don't take you aside and hand you a list
of them. They don't remember which lies they told you, and most
were implicit anyway. So contradicting such lies will be a source
of surprises for as long as adults keep telling them.&lt;br/&gt;&lt;br/&gt;Sometimes it's systems that lie to you. For example, the educational
systems in most countries train you to win by 
&lt;a href="lesson.html"&gt;&lt;u&gt;hacking the test&lt;/u&gt;&lt;/a&gt;. But
that's not how you win at the most important real-world tests, and
after decades of training, this is hard for new arrivals in the real
world to grasp. Helping them overcome such institutional lies will
work as long as the institutions remain broken. 
&lt;font color="#dddddd"&gt;[&lt;a href="#f12n"&gt;&lt;font color="#dddddd"&gt;12&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;Another recipe for timelessness is to write about things readers
already know, but in much more detail than can be transmitted
culturally. "Everyone knows," for example, that it can be rewarding
to have &lt;a href="kids.html"&gt;&lt;u&gt;kids&lt;/u&gt;&lt;/a&gt;. But till you have them you don't know precisely what
forms that takes, and even then much of what you know you may never
have put into words.&lt;br/&gt;&lt;br/&gt;I've written about all these kinds of topics. But I didn't do it
in a deliberate attempt to write essays that were timeless in the
stricter sense. And indeed, the fact that this depends on one's ideas
not sticking suggests that it's not worth making a deliberate attempt
to. You should write about topics of timeless importance, yes, but
if you do such a good job that your conclusions stick and future
generations find your essay obvious instead of novel, so much the
better. You've crossed into Darwin territory.&lt;br/&gt;&lt;br/&gt;Writing about topics of timeless importance is an instance of
something even more general, though: breadth of applicability. And
there are more kinds of breadth than chronological — applying to
lots of different fields, for example. So breadth is the ultimate
aim.&lt;br/&gt;&lt;br/&gt;I already aim for it. Breadth and novelty are the two things I'm
always chasing. But I'm glad I understand where timelessness fits.&lt;br/&gt;&lt;br/&gt;I understand better where a lot of things fit now. This essay has
been a kind of tour of essay writing. I started out hoping to get
advice about topics; if you assume good writing, the only thing
left to differentiate the best essay is its topic. And I did get
advice about topics: discover natural selection. Yeah, that would
be nice. But when you step back and ask what's the best you can do
short of making some great discovery like that, the answer turns
out to be about procedure. Ultimately the quality of an essay is a
function of the ideas discovered in it, and the way you get them
is by casting a wide net for questions and then being very exacting
with the answers.&lt;br/&gt;&lt;br/&gt;The most striking feature of this map of essay writing are the
alternating stripes of inspiration and effort required. The questions
depend on inspiration, but the answers can be got by sheer persistence.
You don't have to get an answer right the first time, but there's
no excuse for not getting it right eventually, because you can keep
rewriting till you do. And this is not just a theoretical possibility.
It's a pretty accurate description of the way I work. I'm rewriting
as we speak.&lt;br/&gt;&lt;br/&gt;But although I wish I could say that writing great essays depends mostly
on effort, in the limit case it's inspiration that makes the
difference. In the limit case, the questions are the harder thing
to get. That pool has no bottom.&lt;br/&gt;&lt;br/&gt;How to get more questions? That is the most important question of
all.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;Notes&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;[&lt;a name="f1n"&gt;&lt;font color="#000000"&gt;1&lt;/font&gt;&lt;/a&gt;]
There might be some resistance to this conclusion on the
grounds that some of these discoveries could only be understood by
a small number of readers. But you get into all sorts of difficulties
if you want to disqualify essays on this account. How do you decide
where the cutoff should be? If a virus kills off everyone except a 
handful of people sequestered at Los Alamos,
could an essay that had been disqualified now be eligible? Etc.&lt;br/&gt;&lt;br/&gt;Darwin's 1844 essay was derived from an earlier version written in 1839.
Extracts from it were published in 1858.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f2n"&gt;&lt;font color="#000000"&gt;2&lt;/font&gt;&lt;/a&gt;]
When you find yourself very curious about an apparently minor
question, that's an exciting sign. Evolution has designed you to
pay attention to things that matter. So when you're very curious
about something random, that could mean you've unconsciously noticed
it's less random than it seems.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f3n"&gt;&lt;font color="#000000"&gt;3&lt;/font&gt;&lt;/a&gt;]
Corollary: If you're not intellectually honest, your writing
won't just be biased, but also boring, because you'll miss all the
ideas you'd have discovered if you pushed for the truth.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f4n"&gt;&lt;font color="#000000"&gt;4&lt;/font&gt;&lt;/a&gt;]
Sometimes this process begins before you start writing.
Sometimes you've already figured out the first few things you want
to say. Schoolchildren are often taught they should decide &lt;i&gt;everything&lt;/i&gt;
they want to say, and write this down as an outline before they
start writing the essay itself. Maybe that's a good way to get them
started — or not, I don't know — but it's antithetical to the
spirit of essay writing. The more detailed your outline, the less
your ideas can benefit from the sort of discovery that essays are for.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f5n"&gt;&lt;font color="#000000"&gt;5&lt;/font&gt;&lt;/a&gt;]
The problem with this type of "greedy" algorithm is that you
can end up on a local maximum. If the most valuable question is
preceded by a boring one, you'll overlook it. But I can't imagine
a better strategy. There's no lookahead except by writing. So use
a greedy algorithm and a lot of time.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f6n"&gt;&lt;font color="#000000"&gt;6&lt;/font&gt;&lt;/a&gt;]
I ended up reattaching the first 5 of the 17 paragraphs, and
discarding the rest.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f7n"&gt;&lt;font color="#000000"&gt;7&lt;/font&gt;&lt;/a&gt;]
Stephen Fry confessed to making use of this phenomenon when
taking exams at Oxford. He had in his head a standard essay about
some general literary topic, and he would find a way to turn the
exam question toward it and then just reproduce it again.&lt;br/&gt;&lt;br/&gt;Strictly speaking it's the graph of ideas that would be highly
connected, not the space, but that usage would confuse people who
don't know graph theory, whereas people who do know it will get
what I mean if I say "space".&lt;br/&gt;&lt;br/&gt;[&lt;a name="f8n"&gt;&lt;font color="#000000"&gt;8&lt;/font&gt;&lt;/a&gt;]
Too far doesn't depend just on the distance from the original
topic. It's more like that distance divided by the value of whatever
I've discovered in the subtree.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f9n"&gt;&lt;font color="#000000"&gt;9&lt;/font&gt;&lt;/a&gt;]
Or can you? I should try writing about this. Even if the
chance of succeeding is small, the expected value is huge.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f10n"&gt;&lt;font color="#000000"&gt;10&lt;/font&gt;&lt;/a&gt;]
There was a vogue in the 20th century for saying that the
purpose of art was also to teach. Some artists tried to justify
their work by explaining that their goal was not to produce something
good, but to challenge our preconceptions about art. And to be fair,
art can teach somewhat. The ancient Greeks' naturalistic sculptures
represented a new idea, and must have been extra exciting to
contemporaries on that account. But they still look good to us.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f11n"&gt;&lt;font color="#000000"&gt;11&lt;/font&gt;&lt;/a&gt;]
Bertrand Russell caused huge controversy in the early 20th
century with his ideas about "trial marriage." But they make boring
reading now, because they prevailed. "Trial marriage" is what we
call "dating."&lt;br/&gt;&lt;br/&gt;[&lt;a name="f12n"&gt;&lt;font color="#000000"&gt;12&lt;/font&gt;&lt;/a&gt;]
If you'd asked me 10 years ago, I'd have predicted that schools
would continue to teach hacking the test for centuries. But now it
seems plausible that students will soon be taught individually by
AIs, and that exams will be replaced by ongoing, invisible
micro-assessments.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;font color="888888"&gt;&lt;b&gt;Thanks&lt;/b&gt; to Sam Altman, Trevor Blackwell, 
Jessica Livingston, Robert
Morris, Courtenay Pipkin, and Harj Taggar for reading drafts of
this.&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;&lt;/font&gt;</content:encoded>
      <guid isPermaLink="false">https://paulgraham.com//best.html</guid>
      <pubDate>Fri, 01 Mar 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to Start Google</title>
      <link>https://paulgraham.com//google.html</link>
      <description>&lt;font face="verdana" size="2"&gt;March 2024&lt;br/&gt;&lt;br/&gt;&lt;i&gt;(This is a talk I gave to 14 and 15 year olds about what to do now if they might want to start a startup later. Lots of schools think they should tell students something about startups. This is what I think they should tell them.)&lt;/i&gt;&lt;br/&gt;&lt;br/&gt;Most of you probably think that when you're released into the so-called real world you'll eventually have to get some kind of job. That's not true, and today I'm going to talk about a trick you can use t&lt;/font&gt;</description>
      <content:encoded>&lt;font face="verdana" size="2"&gt;March 2024&lt;br/&gt;&lt;br/&gt;&lt;i&gt;(This is a talk I gave to 14 and 15 year olds about what to do now
if they might want to start a startup later. Lots of schools think
they should tell students something about startups. This is what I
think they should tell them.)&lt;/i&gt;&lt;br/&gt;&lt;br/&gt;Most of you probably think that when you're released into the
so-called real world you'll eventually have to get some kind of
job. That's not true, and today I'm going to talk about a trick you
can use to avoid ever having to get a job.&lt;br/&gt;&lt;br/&gt;The trick is to start your own company. So it's not a trick for
avoiding &lt;i&gt;work&lt;/i&gt;, because if you start your own company you'll
work harder than you would if you had an ordinary job. But you will
avoid many of the annoying things that come with a job, including
a boss telling you what to do.&lt;br/&gt;&lt;br/&gt;It's more exciting to work on your own project than someone else's.
And you can also get a lot richer. In fact, this is the standard
way to get 
&lt;a href="richnow.html"&gt;&lt;u&gt;really rich&lt;/u&gt;&lt;/a&gt;. If you look at the lists of the richest
people that occasionally get published in the press, nearly all of
them did it by starting their own companies.&lt;br/&gt;&lt;br/&gt;Starting your own company can mean anything from starting a barber
shop to starting Google. I'm here to talk about one extreme end of
that continuum. I'm going to tell you how to start Google.&lt;br/&gt;&lt;br/&gt;The companies at the Google end of the continuum are called startups
when they're young. The reason I know about them is that my wife
Jessica and I started something called Y Combinator that is basically
a startup factory. Since 2005, Y Combinator has funded over 4000
startups. So we know exactly what you need to start a startup,
because we've helped people do it for the last 19 years.&lt;br/&gt;&lt;br/&gt;You might have thought I was joking when I said I was going to tell
you how to start Google. You might be thinking "How could &lt;i&gt;we&lt;/i&gt;
start Google?" But that's effectively what the people who did start
Google were thinking before they started it. If you'd told Larry
Page and Sergey Brin, the founders of Google, that the company they
were about to start would one day be worth over a trillion dollars,
their heads would have exploded.&lt;br/&gt;&lt;br/&gt;All you can know when you start working on a startup is that it
seems worth pursuing. You can't know whether it will turn into
a company worth billions or one that goes out of business. So when I
say I'm going to tell you how to start Google, I mean I'm going to
tell you how to get to the point where you can start a company that
has as much chance of being Google as Google had of being Google.
&lt;font color="#dddddd"&gt;[&lt;a href="#f1n"&gt;&lt;font color="#dddddd"&gt;1&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;How do you get from where you are now to the point where you can
start a successful startup? You need three things. You need to be
good at some kind of technology, you need an idea for what you're
going to build, and you need cofounders to start the company with.&lt;br/&gt;&lt;br/&gt;How do you get good at technology? And how do you choose which
technology to get good at? Both of those questions turn out to have
the same answer: work on your own projects. Don't try to guess
whether gene editing or LLMs or rockets will turn out to be the
most valuable technology to know about. No one can predict that.
Just work on whatever interests you the most. You'll work much
harder on something you're interested in than something you're doing
because you think you're supposed to.&lt;br/&gt;&lt;br/&gt;If you're not sure what technology to get good at, get good at
programming. That has been the source of the median startup for the
last 30 years, and this is probably not going to change in the next
10.&lt;br/&gt;&lt;br/&gt;Those of you who are taking computer science classes in school may
at this point be thinking, ok, we've got this sorted. We're already
being taught all about programming. But sorry, this is not enough.
You have to be working on your own projects, not just learning stuff
in classes. You can do well in computer science classes without
ever really learning to program. In fact you can graduate with a
degree in computer science from a top university and still not be
any good at programming. That's why tech companies all make you
take a coding test before they'll hire you, regardless of where you
went to university or how well you did there. They know grades and
exam results prove nothing.&lt;br/&gt;&lt;br/&gt;If you really want to learn to program, you have to work on your
own projects. You learn so much faster that way. Imagine you're
writing a game and there's something you want to do in it, and you
don't know how. You're going to figure out how a lot faster than
you'd learn anything in a class.&lt;br/&gt;&lt;br/&gt;You don't have to learn programming, though. If you're wondering
what counts as technology, it includes practically everything you
could describe using the words "make" or "build." So welding would
count, or making clothes, or making videos. Whatever you're most
interested in. The critical distinction is whether you're producing
or just consuming. Are you writing computer games, or just playing
them? That's the cutoff.&lt;br/&gt;&lt;br/&gt;Steve Jobs, the founder of Apple, spent time when he was a teenager
studying calligraphy — the sort of beautiful writing that
you see in medieval manuscripts. No one, including him, thought
that this would help him in his career. He was just doing it because
he was interested in it. But it turned out to help him a lot. The
computer that made Apple really big, the Macintosh, came out at
just the moment when computers got powerful enough to make letters
like the ones in printed books instead of the computery-looking
letters you see in 8 bit games. Apple destroyed everyone else at
this, and one reason was that Steve was one of the few people in
the computer business who really got graphic design.&lt;br/&gt;&lt;br/&gt;Don't feel like your projects have to be &lt;i&gt;serious&lt;/i&gt;. They can
be as frivolous as you like, so long as you're building things
you're excited about. Probably 90% of programmers start out building
games. They and their friends like to play games. So they build
the kind of things they and their friends want. And that's exactly
what you should be doing at 15 if you want to start a startup one
day.&lt;br/&gt;&lt;br/&gt;You don't have to do just one project. In fact it's good to learn
about multiple things. Steve Jobs didn't just learn calligraphy.
He also learned about electronics, which was even more valuable.
Whatever you're interested in. (Do you notice a theme here?)&lt;br/&gt;&lt;br/&gt;So that's the first of the three things you need, to get good at
some kind or kinds of technology. You do it the same way you get
good at the violin or football: practice. If you start a startup
at 22, and you start writing your own programs now, then by the
time you start the company you'll have spent at least 7 years
practicing writing code, and you can get pretty good at anything
after practicing it for 7 years.&lt;br/&gt;&lt;br/&gt;Let's suppose you're 22 and you've succeeded: You're now really
good at some technology. How do you get 
&lt;a href="startupideas.html"&gt;&lt;u&gt;startup ideas&lt;/u&gt;&lt;/a&gt;? It might
seem like that's the hard part. Even if you are a good programmer,
how do you get the idea to start Google?&lt;br/&gt;&lt;br/&gt;Actually it's easy to get startup ideas once you're good at technology.
Once you're good at some technology, when you look at the world you
see dotted outlines around the things that are missing. You start
to be able to see both the things that are missing from the technology
itself, and all the broken things that could be fixed using it, and
each one of these is a potential startup.&lt;br/&gt;&lt;br/&gt;In the town near our house there's a shop with a sign warning that
the door is hard to close. The sign has been there for several
years. To the people in the shop it must seem like this mysterious
natural phenomenon that the door sticks, and all they can do is put
up a sign warning customers about it. But any carpenter looking at
this situation would think "why don't you just plane off the part
that sticks?"&lt;br/&gt;&lt;br/&gt;Once you're good at programming, all the missing software in the
world starts to become as obvious as a sticking door to a carpenter.
I'll give you a real world example. Back in the 20th century,
American universities used to publish printed directories with all
the students' names and contact info. When I tell you what these
directories were called, you'll know which startup I'm talking
about. They were called facebooks, because they usually had a picture
of each student next to their name.&lt;br/&gt;&lt;br/&gt;So Mark Zuckerberg shows up at Harvard in 2002, and the university
still hasn't gotten the facebook online. Each individual house has
an online facebook, but there isn't one for the whole university.
The university administration has been diligently having meetings
about this, and will probably have solved the problem in another
decade or so. Most of the students don't consciously notice that
anything is wrong. But Mark is a programmer. He looks at this
situation and thinks "Well, this is stupid. I could write a program
to fix this in one night. Just let people upload their own photos
and then combine the data into a new site for the whole university."
So he does. And almost literally overnight he has thousands of
users.&lt;br/&gt;&lt;br/&gt;Of course Facebook was not a startup yet. It was just a... project.
There's that word again. Projects aren't just the best way to learn
about technology. They're also the best source of startup ideas.&lt;br/&gt;&lt;br/&gt;Facebook was not unusual in this respect. Apple and Google also
began as projects. Apple wasn't meant to be a company. Steve Wozniak
just wanted to build his own computer. It only turned into a company
when Steve Jobs said "Hey, I wonder if we could sell plans for this
computer to other people." That's how Apple started. They weren't
even selling computers, just plans for computers. Can you imagine
how lame this company seemed?&lt;br/&gt;&lt;br/&gt;Ditto for Google. Larry and Sergey weren't trying to start a company
at first. They were just trying to make search better. Before Google,
most search engines didn't try to sort the results they gave you
in order of importance. If you searched for "rugby" they just gave
you every web page that contained the word "rugby." And the web was
so small in 1997 that this actually worked! Kind of. There might
only be 20 or 30 pages with the word "rugby," but the web was growing
exponentially, which meant this way of doing search was becoming
exponentially more broken. Most users just thought, "Wow, I sure
have to look through a lot of search results to find what I want."
Door sticks. But like Mark, Larry and Sergey were programmers. Like
Mark, they looked at this situation and thought "Well, this is
stupid. Some pages about rugby matter more than others. Let's figure
out which those are and show them first."&lt;br/&gt;&lt;br/&gt;It's obvious in retrospect that this was a great idea for a startup.
It wasn't obvious at the time. It's never obvious. If it was obviously
a good idea to start Apple or Google or Facebook, someone else would
have already done it. That's why the best startups grow out of
projects that aren't meant to be startups. You're not trying to
start a company. You're just following your instincts about what's
interesting. And if you're young and good at technology, then your
unconscious instincts about what's interesting are better than your
conscious ideas about what would be a good company.&lt;br/&gt;&lt;br/&gt;So it's critical, if you're a young founder, to build things for
yourself and your friends to use. The biggest mistake young founders
make is to build something for some mysterious group of other people.
But if you can make something that you and your friends truly want
to use — something your friends aren't just using out of
loyalty to you, but would be really sad to lose if you shut it down
— then you almost certainly have the germ of a good startup
idea. It may not seem like a startup to you. It may not be obvious
how to make money from it. But trust me, there's a way.&lt;br/&gt;&lt;br/&gt;What you need in a startup idea, and all you need, is something
your friends actually want. And those ideas aren't hard to see once
you're good at technology. There are sticking doors everywhere.
&lt;font color="#dddddd"&gt;[&lt;a href="#f2n"&gt;&lt;font color="#dddddd"&gt;2&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;Now for the third and final thing you need: a cofounder, or cofounders.
The optimal startup has two or three founders, so you need one or
two cofounders. How do you find them? Can you predict what I'm going
to say next? It's the same thing: projects. You find cofounders by
working on projects with them. What you need in a cofounder is
someone who's good at what they do and that you work well with, and
the only way to judge this is to work with them on things.&lt;br/&gt;&lt;br/&gt;At this point I'm going to tell you something you might not want
to hear. It really matters to do well in your classes, even the
ones that are just memorization or blathering about literature,
because you need to do well in your classes to get into a good
university. And if you want to start a startup you should try to
get into the best university you can, because that's where the best
cofounders are. It's also where the best employees are. When Larry
and Sergey started Google, they began by just hiring all the smartest
people they knew out of Stanford, and this was a real advantage for
them.&lt;br/&gt;&lt;br/&gt;The empirical evidence is clear on this. If you look at where the
largest numbers of successful startups come from, it's pretty much
the same as the list of the most selective universities.&lt;br/&gt;&lt;br/&gt;I don't think it's the prestigious names of these universities that
cause more good startups to come out of them. Nor do I think it's
because the quality of the teaching is better. What's driving this
is simply the difficulty of getting in. You have to be pretty smart
and determined to get into MIT or Cambridge, so if you do manage
to get in, you'll find the other students include a lot of smart
and determined people.
&lt;font color="#dddddd"&gt;[&lt;a href="#f3n"&gt;&lt;font color="#dddddd"&gt;3&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;You don't have to start a startup with someone you meet at university.
The founders of Twitch met when they were seven. The founders of
Stripe, Patrick and John Collison, met when John was born. But
universities are the main source of cofounders. And because they're
where the cofounders are, they're also where the ideas are, because
the best ideas grow out of projects you do with the people who
become your cofounders.&lt;br/&gt;&lt;br/&gt;So the list of what you need to do to get from here to starting a
startup is quite short. You need to get good at technology, and the
way to do that is to work on your own projects. And you need to do
as well in school as you can, so you can get into a good university,
because that's where the cofounders and the ideas are.&lt;br/&gt;&lt;br/&gt;That's it, just two things, build stuff and do well in school.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;Notes&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;[&lt;a name="f1n"&gt;&lt;font color="#000000"&gt;1&lt;/font&gt;&lt;/a&gt;]
The rhetorical trick in this sentence is that the "Google"s
refer to different things. What I mean is: a company that has as
much chance of growing as big as Google ultimately did as Larry and
Sergey could have reasonably expected Google itself would at the
time they started it. But I think the original version is zippier.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f2n"&gt;&lt;font color="#000000"&gt;2&lt;/font&gt;&lt;/a&gt;]
Making something for your friends isn't the only source of
startup ideas. It's just the best source for young founders, who
have the least knowledge of what other people want, and whose own
wants are most predictive of future demand.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f3n"&gt;&lt;font color="#000000"&gt;3&lt;/font&gt;&lt;/a&gt;]
Strangely enough this is particularly true in countries like
the US where undergraduate admissions are done badly. US admissions
departments make applicants jump through a lot of arbitrary hoops
that have little to do with their intellectual ability. But the
more arbitrary a test, the more it becomes a test of mere determination
and resourcefulness. And those are the two most important qualities
in startup founders. So US admissions departments are better at
selecting founders than they would be if they were better at selecting
students.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;font color="888888"&gt;&lt;b&gt;Thanks&lt;/b&gt; to Jared Friedman, Carolynn Levy, Jessica Livingston, Harj Taggar, and Garry Tan for reading drafts of this.&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;&lt;/font&gt;</content:encoded>
      <guid isPermaLink="false">https://paulgraham.com//google.html</guid>
      <pubDate>Fri, 01 Mar 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>The Reddits</title>
      <link>https://paulgraham.com//reddits.html</link>
      <description>&lt;font face="verdana" size="2"&gt;March 2024&lt;br/&gt;&lt;br/&gt;I met the Reddits before we even started Y Combinator. In fact they were one of the reasons we started it.&lt;br/&gt;&lt;br/&gt;YC grew out of a talk I gave to the Harvard Computer Society (the undergrad computer club) about how to start a startup. Everyone else in the audience was probably local, but Steve and Alexis came up on the train from the University of Virginia, where they were seniors. Since they'd come so far I agreed to meet them for coffee. They&lt;/font&gt;</description>
      <content:encoded>&lt;font face="verdana" size="2"&gt;March 2024&lt;br/&gt;&lt;br/&gt;I met the Reddits before we even started Y Combinator. In fact they
were one of the reasons we started it.&lt;br/&gt;&lt;br/&gt;YC grew out of a talk I gave to the Harvard Computer Society (the
undergrad computer club) about how to start a startup. Everyone
else in the audience was probably local, but Steve and Alexis came
up on the train from the University of Virginia, where they were
seniors. Since they'd come so far I agreed to meet them for coffee.
They told me about the startup idea we'd later fund them to drop:
a way to order fast food on your cellphone.&lt;br/&gt;&lt;br/&gt;This was before smartphones. They'd have had to make deals with
cell carriers and fast food chains just to get it launched. So it
was not going to happen. It still doesn't exist, 19 years later.
But I was impressed with their brains and their energy. In fact I
was so impressed with them and some of the other people I met at
that talk that I decided to start something to fund them. A few
days later I told Steve and Alexis that we were starting Y Combinator,
and encouraged them to apply.&lt;br/&gt;&lt;br/&gt;That first batch we didn't have any way to identify applicants, so
we made up nicknames for them. The Reddits were the "Cell food
muffins." "Muffin" is a term of endearment Jessica uses for things
like small dogs and two year olds. So that gives you some idea what
kind of impression Steve and Alexis made in those days. They had
the look of slightly ruffled surprise that baby birds have.&lt;br/&gt;&lt;br/&gt;Their idea was bad though. And since we thought then that we were
funding ideas rather than founders, we rejected them. But we felt
bad about it. Jessica was sad that we'd rejected the muffins. And
it seemed wrong to me to turn down the people we'd been inspired
to start YC to fund.&lt;br/&gt;&lt;br/&gt;I don't think the startup sense of the word "pivot" had been invented
yet, but we wanted to fund Steve and Alexis, so if their idea was
bad, they'd have to work on something else. And I knew what else.
In those days there was a site called Delicious where you could
save links. It had a page called del.icio.us/popular that listed
the most-saved links, and people were using this page as a de facto
Reddit. I knew because a lot of the traffic to my site was coming
from it. There needed to be something like del.icio.us/popular, but
designed for sharing links instead of being a byproduct of saving
them.&lt;br/&gt;&lt;br/&gt;So I called Steve and Alexis and said that we liked them, just not
their idea, so we'd fund them if they'd work on something else.
They were on the train home to Virginia at that point. They got off
at the next station and got on the next train north, and by the end
of the day were committed to working on what's now called Reddit.&lt;br/&gt;&lt;br/&gt;They would have liked to call it Snoo, as in "What snoo?" But
snoo.com was too expensive, so they settled for calling the mascot
Snoo and picked a name for the site that wasn't registered. Early
on Reddit was just a provisional name, or so they told me at least,
but it's probably too late to change it now.&lt;br/&gt;&lt;br/&gt;As with all the really great startups, there's an uncannily close
match between the company and the founders. Steve in particular.
Reddit has a certain personality — curious, skeptical, ready to
be amused — and that personality is Steve's.&lt;br/&gt;&lt;br/&gt;Steve will roll his eyes at this, but he's an intellectual; he's
interested in ideas for their own sake. That was how he came to be
in that audience in Cambridge in the first place. He knew me because
he was interested in a programming language I've written about
called Lisp, and Lisp is one of those languages few people learn
except out of intellectual curiosity. Steve's kind of vacuum-cleaner
curiosity is exactly what you want when you're starting a site
that's a list of links to literally anything interesting.&lt;br/&gt;&lt;br/&gt;Steve was not a big fan of authority, so he also liked the idea of
a site without editors. In those days the top forum for programmers
was a site called Slashdot. It was a lot like Reddit, except the
stories on the frontpage were chosen by human moderators. And though
they did a good job, that one small difference turned out to be a
big difference. Being driven by user submissions meant Reddit was
fresher than Slashdot. News there was newer, and users will always
go where the newest news is.&lt;br/&gt;&lt;br/&gt;I pushed the Reddits to launch fast. A version one didn't need to
be more than a couple hundred lines of code. How could that take
more than a week or two to build? And they did launch comparatively
fast, about three weeks into the first YC batch. The first users
were Steve, Alexis, me, and some of their YC batchmates and college
friends. It turns out you don't need that many users to collect a
decent list of interesting links, especially if you have multiple
accounts per user.&lt;br/&gt;&lt;br/&gt;Reddit got two more people from their YC batch: Chris Slowe and
Aaron Swartz, and they too were unusually smart. Chris was just
finishing his PhD in physics at Harvard. Aaron was younger, a college
freshman, and even more anti-authority than Steve. It's not
exaggerating to describe him as a martyr for what authority later
did to him.&lt;br/&gt;&lt;br/&gt;Slowly but inexorably Reddit's traffic grew. At first the numbers
were so small they were hard to distinguish from background noise.
But within a few weeks it was clear that there was a core of real
users returning regularly to the site. And although all kinds of
things have happened to Reddit the company in the years since,
Reddit the &lt;i&gt;site&lt;/i&gt; never looked back.&lt;br/&gt;&lt;br/&gt;Reddit the site (and now app) is such a fundamentally useful thing
that it's almost unkillable. Which is why, despite a long stretch
after Steve left when the management strategy ranged from benign
neglect to spectacular blunders, traffic just kept growing. You
can't do that with most companies. Most companies you take your eye
off the ball for six months and you're in deep trouble. But Reddit
was special, and when Steve came back in 2015, I knew the world was
in for a surprise.&lt;br/&gt;&lt;br/&gt;People thought they had Reddit's number: one of the players in
Silicon Valley, but not one of the big ones. But those who knew
what had been going on behind the scenes knew there was more to the
story than this. If Reddit could grow to the size it had with
management that was harmless at best, what could it do if Steve
came back? We now know the answer to that question. Or at least a
lower bound on the answer. Steve is not out of ideas yet.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/font&gt;</content:encoded>
      <guid isPermaLink="false">https://paulgraham.com//reddits.html</guid>
      <pubDate>Fri, 01 Mar 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>The Right Kind of Stubborn</title>
      <link>https://paulgraham.com//persistence.html</link>
      <description>&lt;font face="verdana" size="2"&gt;July 2024&lt;br/&gt;&lt;br/&gt;Successful people tend to be persistent. New ideas often don't work at first, but they're not deterred. They keep trying and eventually find something that does.&lt;br/&gt;&lt;br/&gt;Mere obstinacy, on the other hand, is a recipe for failure. Obstinate people are so annoying. They won't listen. They beat their heads against a wall and get nowhere.&lt;br/&gt;&lt;br/&gt;But is there any real difference between these two cases? Are persistent and obstinate people actually b&lt;/font&gt;</description>
      <content:encoded>&lt;font face="verdana" size="2"&gt;July 2024&lt;br/&gt;&lt;br/&gt;Successful people tend to be persistent. New ideas often don't work
at first, but they're not deterred. They keep trying and eventually
find something that does.&lt;br/&gt;&lt;br/&gt;Mere obstinacy, on the other hand, is a recipe for failure. Obstinate
people are so annoying. They won't listen. They beat their heads
against a wall and get nowhere.&lt;br/&gt;&lt;br/&gt;But is there any real difference between these two cases? Are
persistent and obstinate people actually behaving differently? Or
are they doing the same thing, and we just label them later as
persistent or obstinate depending on whether they turned out to be
right or not?&lt;br/&gt;&lt;br/&gt;If that's the only difference then there's nothing to be learned
from the distinction. Telling someone to be persistent rather than
obstinate would just be telling them to be right rather than wrong,
and they already know that. Whereas if persistence and obstinacy
are actually different kinds of behavior, it would be worthwhile
to tease them apart.
&lt;font color="#dddddd"&gt;[&lt;a href="#f1n"&gt;&lt;font color="#dddddd"&gt;1&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;I've talked to a lot of determined people, and it seems to me that
they're different kinds of behavior. I've often walked away from a
conversation thinking either "Wow, that guy is determined" or "Damn,
that guy is stubborn," and I don't think I'm just talking about
whether they seemed right or not. That's part of it, but not all
of it.&lt;br/&gt;&lt;br/&gt;There's something annoying about the obstinate that's not simply
due to being mistaken. They won't listen. And that's not true of
all determined people. I can't think of anyone more determined than
the Collison brothers, and when you point out a problem to them,
they not only listen, but listen with an almost predatory intensity.
Is there a hole in the bottom of their boat? Probably not, but if
there is, they want to know about it.&lt;br/&gt;&lt;br/&gt;It's the same with most successful people. They're never &lt;i&gt;more&lt;/i&gt;
engaged than when you disagree with them. Whereas the obstinate
don't want to hear you. When you point out problems, their eyes
glaze over, and their replies sound like ideologues talking about
matters of doctrine.
&lt;font color="#dddddd"&gt;[&lt;a href="#f2n"&gt;&lt;font color="#dddddd"&gt;2&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;The reason the persistent and the obstinate seem similar is that
they're both hard to stop. But they're hard to stop in different
senses. The persistent are like boats whose engines can't be throttled
back. The obstinate are like boats whose rudders can't be turned.
&lt;font color="#dddddd"&gt;[&lt;a href="#f3n"&gt;&lt;font color="#dddddd"&gt;3&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;In the degenerate case they're indistinguishable: when there's only
one way to solve a problem, your only choice is whether to give up
or not, and persistence and obstinacy both say no. This is presumably
why the two are so often conflated in popular culture. It assumes
simple problems. But as problems get more complicated, we can see
the difference between them. The persistent are much more attached
to points high in the decision tree than to minor ones lower down,
while the obstinate spray "don't give up" indiscriminately over the
whole tree.&lt;br/&gt;&lt;br/&gt;The persistent are attached to the goal. The obstinate are attached
to their ideas about how to reach it.&lt;br/&gt;&lt;br/&gt;Worse still, that means they'll tend to be attached to their &lt;i&gt;first&lt;/i&gt;
ideas about how to solve a problem, even though these are the least
informed by the experience of working on it. So the obstinate aren't
merely attached to details, but disproportionately likely to be
attached to wrong ones.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Why are they like this? Why are the obstinate obstinate? One
possibility is that they're overwhelmed. They're not very capable.
They take on a hard problem. They're immediately in over their head.
So they grab onto ideas the way someone on the deck of a rolling
ship might grab onto the nearest handhold.&lt;br/&gt;&lt;br/&gt;That was my initial theory, but on examination it doesn't hold up.
If being obstinate were simply a consequence of being in over one's
head, you could make persistent people become obstinate by making
them solve harder problems. But that's not what happens. If you
handed the Collisons an extremely hard problem to solve, they
wouldn't become obstinate. If anything they'd become less obstinate.
They'd know they had to be open to anything.&lt;br/&gt;&lt;br/&gt;Similarly, if obstinacy were caused by the situation, the obstinate
would stop being obstinate when solving easier problems. But they
don't. And if obstinacy isn't caused by the situation, it must come
from within. It must be a feature of one's personality.&lt;br/&gt;&lt;br/&gt;Obstinacy is a reflexive resistance to changing one's ideas. This
is not identical with stupidity, but they're closely related. A
reflexive resistance to changing one's ideas becomes a sort of
induced stupidity as contrary evidence mounts. And obstinacy is a
form of not giving up that's easily practiced by the stupid. You
don't have to consider complicated tradeoffs; you just dig in your
heels. It even works, up to a point.&lt;br/&gt;&lt;br/&gt;The fact that obstinacy works for simple problems is an important
clue. Persistence and obstinacy aren't opposites. The relationship
between them is more like the relationship between the two kinds
of respiration we can do: aerobic respiration, and the anaerobic
respiration we inherited from our most distant ancestors. Anaerobic
respiration is a more primitive process, but it has its uses. When
you leap suddenly away from a threat, that's what you're using.&lt;br/&gt;&lt;br/&gt;The optimal amount of obstinacy is not zero. It can be good if your
initial reaction to a setback is an unthinking "I won't give up,"
because this helps prevent panic. But unthinking only gets you so
far. The further someone is toward the obstinate end of the continuum,
the less likely they are to succeed in solving hard problems.
&lt;font color="#dddddd"&gt;[&lt;a href="#f4n"&gt;&lt;font color="#dddddd"&gt;4&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;Obstinacy is a simple thing. Animals have it. But persistence turns
out to have a fairly complicated internal structure.&lt;br/&gt;&lt;br/&gt;One thing that distinguishes the persistent is their energy. At the
risk of putting too much weight on words, they persist rather than
merely resisting. They keep trying things. Which means the persistent
must also be imaginative. To keep trying things, you have to keep
thinking of things to try.&lt;br/&gt;&lt;br/&gt;Energy and imagination make a wonderful combination. Each gets the
best out of the other. Energy creates demand for the ideas produced
by imagination, which thus produces more, and imagination gives
energy somewhere to go.
&lt;font color="#dddddd"&gt;[&lt;a href="#f5n"&gt;&lt;font color="#dddddd"&gt;5&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;Merely having energy and imagination is quite rare. But to solve
hard problems you need three more qualities: resilience, good
judgement, and a focus on some kind of goal.&lt;br/&gt;&lt;br/&gt;Resilience means not having one's morale destroyed by setbacks.
Setbacks are inevitable once problems reach a certain size, so if
you can't bounce back from them, you can only do good work on a
small scale. But resilience is not the same as obstinacy. Resilience
means setbacks can't change your morale, not that they can't change
your mind.&lt;br/&gt;&lt;br/&gt;Indeed, persistence often requires that one change one's mind.
That's where good judgement comes in. The persistent are quite
rational. They focus on expected value. It's this, not recklessness,
that lets them work on things that are unlikely to succeed.&lt;br/&gt;&lt;br/&gt;There is one point at which the persistent are often irrational
though: at the very top of the decision tree. When they choose
between two problems of roughly equal expected value, the choice
usually comes down to personal preference. Indeed, they'll often
classify projects into deliberately wide bands of expected value
in order to ensure that the one they want to work on still qualifies.&lt;br/&gt;&lt;br/&gt;Empirically this doesn't seem to be a problem. It's ok to be
irrational near the top of the decision tree. One reason is that
we humans will work harder on a problem we love. But there's another
more subtle factor involved as well: our preferences among problems
aren't random. When we love a problem that other people don't, it's
often because we've unconsciously noticed that it's more important
than they realize.&lt;br/&gt;&lt;br/&gt;Which leads to our fifth quality: there needs to be some overall
goal. If you're like me you began, as a kid, merely with the desire
to do something great. In theory that should be the most powerful
motivator of all, since it includes everything that could possibly
be done. But in practice it's not much use, precisely because it
includes too much. It doesn't tell you what to do at this moment.&lt;br/&gt;&lt;br/&gt;So in practice your energy and imagination and resilience and good
judgement have to be directed toward some fairly specific goal. Not
too specific, or you might miss a great discovery adjacent to what
you're searching for, but not too general, or it won't work to
motivate you.
&lt;font color="#dddddd"&gt;[&lt;a href="#f6n"&gt;&lt;font color="#dddddd"&gt;6&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;When you look at the internal structure of persistence, it doesn't
resemble obstinacy at all. It's so much more complex. Five distinct
qualities — energy, imagination, resilience, good judgement, and
focus on a goal — combine to produce a phenomenon that seems a bit
like obstinacy in the sense that it causes you not to give up. But
the way you don't give up is completely different. Instead of merely
resisting change, you're driven toward a goal by energy and resilience,
through paths discovered by imagination and optimized by judgement.
You'll give way on any point low down in the decision tree, if its
expected value drops sufficiently, but energy and resilience keep
pushing you toward whatever you chose higher up.&lt;br/&gt;&lt;br/&gt;Considering what it's made of, it's not surprising that the right
kind of stubbornness is so much rarer than the wrong kind, or that
it gets so much better results. Anyone can do obstinacy. Indeed,
kids and drunks and fools are best at it. Whereas very few people
have enough of all five of the qualities that produce the right kind
of stubbornness, but when they do the results are magical.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
&lt;b&gt;Notes&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;[&lt;a name="f1n"&gt;&lt;font color="#000000"&gt;1&lt;/font&gt;&lt;/a&gt;]
I'm going to use "persistent" for the good kind of stubborn
and "obstinate" for the bad kind, but I can't claim I'm simply
following current usage. Conventional opinion barely distinguishes
between good and bad kinds of stubbornness, and usage is correspondingly
promiscuous. I could have invented a new word for the good kind,
but it seemed better just to stretch "persistent."&lt;br/&gt;&lt;br/&gt;[&lt;a name="f2n"&gt;&lt;font color="#000000"&gt;2&lt;/font&gt;&lt;/a&gt;]
There are some domains where one can succeed by being obstinate.
Some political leaders have been notorious for it. But it won't
work in situations where you have to pass external tests. And indeed
the political leaders who are famous for being obstinate are famous
for getting power, not for using it well.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f3n"&gt;&lt;font color="#000000"&gt;3&lt;/font&gt;&lt;/a&gt;]
There will be some resistance to turning the rudder of a
persistent person, because there's some cost to changing direction.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f4n"&gt;&lt;font color="#000000"&gt;4&lt;/font&gt;&lt;/a&gt;]
The obstinate do sometimes succeed in solving hard problems.
One way is through luck: like the stopped clock that's right twice
a day, they seize onto some arbitrary idea, and it turns out to be
right. Another is when their obstinacy cancels out some other form
of error. For example, if a leader has overcautious subordinates,
their estimates of the probability of success will always be off
in the same direction. So if he mindlessly says "push ahead regardless"
in every borderline case, he'll usually turn out to be right.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f5n"&gt;&lt;font color="#000000"&gt;5&lt;/font&gt;&lt;/a&gt;]
If you stop there, at just energy and imagination, you get
the conventional caricature of an artist or poet.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f6n"&gt;&lt;font color="#000000"&gt;6&lt;/font&gt;&lt;/a&gt;]
Start by erring on the small side. If you're inexperienced
you'll inevitably err on one side or the other, and if you err on
the side of making the goal too broad, you won't get anywhere.
Whereas if you err on the small side you'll at least be moving
forward. Then, once you're moving, you expand the goal.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;font color="888888"&gt;&lt;b&gt;Thanks&lt;/b&gt; to Trevor Blackwell, 
Jessica Livingston, Jackie McDonough,
Courtenay Pipkin, Harj Taggar, and Garry Tan for reading drafts of
this.&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;&lt;/font&gt;</content:encoded>
      <guid isPermaLink="false">https://paulgraham.com//persistence.html</guid>
      <pubDate>Mon, 01 Jul 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Founder Mode</title>
      <link>https://paulgraham.com//foundermode.html</link>
      <description>&lt;font face="verdana" size="2"&gt;September 2024&lt;br/&gt;&lt;br/&gt;At a YC event last week Brian Chesky gave a talk that everyone who was there will remember. Most founders I talked to afterward said it was the best they'd ever heard. Ron Conway, for the first time in his life, forgot to take notes. I'm not going to try to reproduce it here. Instead I want to talk about a question it raised.&lt;br/&gt;&lt;br/&gt;The theme of Brian's talk was that the conventional wisdom about how to run larger companies is mistaken. As &lt;/font&gt;</description>
      <content:encoded>&lt;font face="verdana" size="2"&gt;September 2024&lt;br/&gt;&lt;br/&gt;At a YC event last week Brian Chesky gave a talk that everyone who
was there will remember. Most founders I talked to afterward said
it was the best they'd ever heard. Ron Conway, for the first time
in his life, forgot to take notes. I'm not going to try to reproduce
it here. Instead I want to talk about a question it raised.&lt;br/&gt;&lt;br/&gt;The theme of Brian's talk was that the conventional wisdom about
how to run larger companies is mistaken. As Airbnb grew, well-meaning
people advised him that he had to run the company in a certain way
for it to scale. Their advice could be optimistically summarized
as "hire good people and give them room to do their jobs." He
followed this advice and the results were disastrous. So he had to
figure out a better way on his own, which he did partly by studying
how Steve Jobs ran Apple. So far it seems to be working. Airbnb's
free cash flow margin is now among the best in Silicon Valley.&lt;br/&gt;&lt;br/&gt;The audience at this event included a lot of the most successful
founders we've funded, and one after another said that the same
thing had happened to them. They'd been given the same advice about
how to run their companies as they grew, but instead of helping
their companies, it had damaged them.&lt;br/&gt;&lt;br/&gt;Why was everyone telling these founders the wrong thing? That was
the big mystery to me. And after mulling it over for a bit I figured
out the answer: what they were being told was how to run a company
you hadn't founded — how to run a company if you're merely a
professional manager. But this m.o. is so much less effective that
to founders it feels broken. There are things founders can do that
managers can't, and not doing them feels wrong to founders, because
it is.&lt;br/&gt;&lt;br/&gt;In effect there are two different ways to run a company: founder
mode and manager mode. Till now most people even in Silicon Valley
have implicitly assumed that scaling a startup meant switching to
manager mode. But we can infer the existence of another mode from
the dismay of founders who've tried it, and the success of their
attempts to escape from it.&lt;br/&gt;&lt;br/&gt;There are as far as I know no books specifically about founder mode.
Business schools don't know it exists. All we have so far are the
experiments of individual founders who've been figuring it out for
themselves. But now that we know what we're looking for, we can
search for it. I hope in a few years founder mode will be as well
understood as manager mode. We can already guess at some of the
ways it will differ.&lt;br/&gt;&lt;br/&gt;The way managers are taught to run companies seems to be like modular
design in the sense that you treat subtrees of the org chart as
black boxes. You tell your direct reports what to do, and it's up
to them to figure out how. But you don't get involved in the details
of what they do. That would be micromanaging them, which is bad.&lt;br/&gt;&lt;br/&gt;Hire good people and give them room to do their jobs. Sounds great
when it's described that way, doesn't it? Except in practice, judging
from the report of founder after founder, what this often turns out
to mean is: hire professional fakers and let them drive the company
into the ground.&lt;br/&gt;&lt;br/&gt;One theme I noticed both in Brian's talk and when talking to founders
afterward was the idea of being gaslit. Founders feel like they're
being gaslit from both sides — by the people telling them they
have to run their companies like managers, and by the people working
for them when they do. Usually when everyone around you disagrees
with you, your default assumption should be that you're mistaken.
But this is one of the rare exceptions. VCs who haven't been founders
themselves don't know how founders should run companies, and C-level
execs, as a class, include some of the most skillful liars in the
world.
&lt;font color="#dddddd"&gt;[&lt;a href="#f1n"&gt;&lt;font color="#dddddd"&gt;1&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;Whatever founder mode consists of, it's pretty clear that it's going
to break the principle that the CEO should engage with the company
only via his or her direct reports. "Skip-level" meetings will
become the norm instead of a practice so unusual that there's a
name for it. And once you abandon that constraint there are a huge
number of permutations to choose from.&lt;br/&gt;&lt;br/&gt;For example, Steve Jobs used to run an annual retreat for what he
considered the 100 most important people at Apple, and these were
not the 100 people highest on the org chart. Can you imagine the
force of will it would take to do this at the average company? And
yet imagine how useful such a thing could be. It could make a big
company feel like a startup. Steve presumably wouldn't have kept
having these retreats if they didn't work. But I've never heard of
another company doing this. So is it a good idea, or a bad one? We
still don't know. That's how little we know about founder mode.
&lt;font color="#dddddd"&gt;[&lt;a href="#f2n"&gt;&lt;font color="#dddddd"&gt;2&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;Obviously founders can't keep running a 2000 person company the way
they ran it when it had 20. There's going to have to be some amount
of delegation. Where the borders of autonomy end up, and how sharp
they are, will probably vary from company to company. They'll even
vary from time to time within the same company, as managers earn
trust. So founder mode will be more complicated than manager mode.
But it will also work better. We already know that from the examples
of individual founders groping their way toward it.&lt;br/&gt;&lt;br/&gt;Indeed, another prediction I'll make about founder mode is that
once we figure out what it is, we'll find that a number of individual
founders were already most of the way there — except that in doing
what they did they were regarded by many as eccentric or worse.
&lt;font color="#dddddd"&gt;[&lt;a href="#f3n"&gt;&lt;font color="#dddddd"&gt;3&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;Curiously enough it's an encouraging thought that we still know so
little about founder mode. Look at what founders have achieved
already, and yet they've achieved this against a headwind of bad
advice. Imagine what they'll do once we can tell them how to run
their companies like Steve Jobs instead of John Sculley.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;Notes&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;[&lt;a name="f1n"&gt;&lt;font color="#000000"&gt;1&lt;/font&gt;&lt;/a&gt;]
The more diplomatic way of phrasing this statement would be
to say that experienced C-level execs are often very skilled at
managing up. And I don't think anyone with knowledge of this world
would dispute that.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f2n"&gt;&lt;font color="#000000"&gt;2&lt;/font&gt;&lt;/a&gt;]
If the practice of having such retreats became so widespread
that even mature companies dominated by politics started to do it,
we could quantify the senescence of companies by the average depth
on the org chart of those invited.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f3n"&gt;&lt;font color="#000000"&gt;3&lt;/font&gt;&lt;/a&gt;]
I also have another less optimistic prediction: as soon as
the concept of founder mode becomes established, people will start
misusing it. Founders who are unable to delegate even things they
should will use founder mode as the excuse. Or managers who aren't
founders will decide they should try to act like founders. That may
even work, to some extent, but the results will be messy when it
doesn't; the modular approach does at least limit the damage a bad
CEO can do.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;font color="888888"&gt;&lt;b&gt;Thanks&lt;/b&gt; to Brian Chesky, Patrick Collison, 
Ron Conway, Jessica
Livingston, Elon Musk, Ryan Petersen, Harj Taggar, and Garry Tan
for reading drafts of this.&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;&lt;/font&gt;</content:encoded>
      <guid isPermaLink="false">https://paulgraham.com//foundermode.html</guid>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>When To Do What You Love</title>
      <link>https://paulgraham.com//when.html</link>
      <description>&lt;font face="verdana" size="2"&gt;September 2024&lt;br/&gt;&lt;br/&gt;There's some debate about whether it's a good idea to "follow your passion." In fact the question is impossible to answer with a simple yes or no. Sometimes you should and sometimes you shouldn't, but the border between should and shouldn't is very complicated. The only way to give a general answer is to trace it.&lt;br/&gt;&lt;br/&gt;When people talk about this question, there's always an implicit "instead of." All other things being equal, why wouldn't&lt;/font&gt;</description>
      <content:encoded>&lt;font face="verdana" size="2"&gt;September 2024&lt;br/&gt;&lt;br/&gt;There's some debate about whether it's a good idea to "follow your
passion." In fact the question is impossible to answer with a simple
yes or no. Sometimes you should and sometimes you shouldn't, but
the border between should and shouldn't is very complicated. The
only way to give a general answer is to trace it.&lt;br/&gt;&lt;br/&gt;When people talk about this question, there's always an implicit
"instead of." All other things being equal, why wouldn't you work
on what interests you the most? So even raising the question implies
that all other things aren't equal, and that you have to choose
between working on what interests you the most and something else,
like what pays the best.&lt;br/&gt;&lt;br/&gt;And indeed if your main goal is to make money, you can't usually
afford to work on what interests you the most. People pay you for
doing what they want, not what you want. But there's an obvious
exception: when you both want the same thing. For example, if you
love football, and you're good enough at it, you can get paid a lot
to play it.&lt;br/&gt;&lt;br/&gt;Of course the odds are against you in a case like football, because
so many other people like playing it too. This is not to say you
shouldn't try though. It depends how much ability you have and how
hard you're willing to work.&lt;br/&gt;&lt;br/&gt;The odds are better when you have strange tastes: when you like
something that pays well and that few other people like. For example,
it's clear that Bill Gates truly loved running a software company.
He didn't just love programming, which a lot of people do. He loved
writing software for customers. That is a very strange taste indeed,
but if you have it, you can make a lot by indulging it.&lt;br/&gt;&lt;br/&gt;There are even some people who have a genuine intellectual interest
in making money. This is distinct from mere greed. They just can't
help noticing when something is mispriced, and can't help doing
something about it. It's like a puzzle for them.
&lt;font color="#dddddd"&gt;[&lt;a href="#f1n"&gt;&lt;font color="#dddddd"&gt;1&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;In fact there's an edge case here so spectacular that it turns all
the preceding advice on its head. If you want to make a really 
huge
amount of money — hundreds of millions or even billions of dollars
— it turns out to be very useful to work on what interests you the
most. The reason is not the extra motivation you get from doing
this, but that the way to make a really large amount of money is
to start a startup, and working on what interests you is an excellent
way to discover &lt;a href="startupideas.html"&gt;&lt;u&gt;startup ideas&lt;/u&gt;&lt;/a&gt;.&lt;br/&gt;&lt;br/&gt;Many if not most of the biggest startups began as projects the
founders were doing for fun. Apple, Google, and Facebook all began
that way. Why is this pattern so common? Because the best ideas
tend to be such outliers that you'd overlook them if you were
consciously looking for ways to make money. Whereas if you're young
and good at technology, your unconscious instincts about what would
be interesting to work on are very well aligned with what needs to
be built.&lt;br/&gt;&lt;br/&gt;So there's something like a midwit peak for making money. If you
don't need to make much, you can work on whatever you're most
interested in; if you want to become moderately rich, you can't
usually afford to; but if you want to become super rich, and you're
young and good at technology, working on what you're most interested
in becomes a good idea again.&lt;br/&gt;&lt;br/&gt;What if you're not sure what you want? What if you're attracted to
the idea of making money and more attracted to some kinds of work
than others, but neither attraction predominates? How do you break
ties?&lt;br/&gt;&lt;br/&gt;The key here is to understand that such ties are only apparent.
When you have trouble choosing between following your interests and
making money, it's never because you have complete knowledge of
yourself and of the types of work you're choosing between, and the
options are perfectly balanced. When you can't decide which path
to take, it's almost always due to ignorance. In fact you're usually
suffering from three kinds of ignorance simultaneously: you don't
know what makes you happy, what the various kinds of work are really
like, or how well you could do them. 
&lt;font color="#dddddd"&gt;[&lt;a href="#f2n"&gt;&lt;font color="#dddddd"&gt;2&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;In a way this ignorance is excusable. It's often hard to predict
these things, and no one even tells you that you need to. If you're
ambitious you're told you should go to college, and this is good
advice so far as it goes, but that's where it usually ends. No one
tells you how to figure out what to work on, or how hard this can
be.&lt;br/&gt;&lt;br/&gt;What do you do in the face of uncertainty? Get more certainty. And
probably the best way to do that is to try working on things you're
interested in. That will get you more information about how interested
you are in them, how good you are at them, and how much scope they
offer for ambition.&lt;br/&gt;&lt;br/&gt;Don't wait. Don't wait till the end of college to figure out what
to work on. Don't even wait for internships during college. You
don't necessarily need a job doing x in order to work on x; often
you can just start doing it in some form yourself. And since figuring
out what to work on is a problem that could take years to solve,
the sooner you start, the better.&lt;br/&gt;&lt;br/&gt;One useful trick for judging different kinds of work is to look at
who your colleagues will be. You'll become like whoever you work
with. Do you want to become like these people?&lt;br/&gt;&lt;br/&gt;Indeed, the difference in character between different kinds of work
is magnified by the fact that everyone else is facing the same
decisions as you. If you choose a kind of work mainly for how well
it pays, you'll be surrounded by other people who chose it for the
same reason, and that will make it even more soul-sucking than it
seems from the outside. Whereas if you choose work you're genuinely
interested in, you'll be surrounded mostly by other people who are
genuinely interested in it, and that will make it extra inspiring.
&lt;font color="#dddddd"&gt;[&lt;a href="#f3n"&gt;&lt;font color="#dddddd"&gt;3&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;The other thing you do in the face of uncertainty is to make choices
that are uncertainty-proof. The less sure you are about what to do,
the more important it is to choose options that give you more options
in the future. I call this "staying upwind." If you're unsure whether
to major in math or economics, for example, choose math; math is
upwind of economics in the sense that it will be easier to switch
later from math to economics than from economics to math.&lt;br/&gt;&lt;br/&gt;There's one case, though, where it's easy to say whether you should
work on what interests you the most: if you want to do 
&lt;a href="greatwork.html"&gt;&lt;u&gt;great work&lt;/u&gt;&lt;/a&gt;.
This is not a sufficient condition for doing great work, but it is
a necessary one.&lt;br/&gt;&lt;br/&gt;There's a lot of selection bias in advice about whether to "follow
your passion," and this is the reason. Most such advice comes from
people who are famously successful, and if you ask someone who's
famously successful how to do what they did, most will tell you
that you have to work on what you're most interested in. And this
is in fact true.&lt;br/&gt;&lt;br/&gt;That doesn't mean it's the right advice for everyone. Not everyone
can do great work, or wants to. But if you do want to, the complicated
question of whether or not to work on what interests you the most
becomes simple. The answer is yes. The root of great work is a sort
of ambitious curiosity, and you can't manufacture that.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;Notes&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;[&lt;a name="f1n"&gt;&lt;font color="#000000"&gt;1&lt;/font&gt;&lt;/a&gt;]
These examples show why it's a mistake to assume that economic
inequality must be evidence of some kind of brokenness or unfairness.
It's obvious that different people have different interests, and
that some interests yield far more money than others, so how can
it not be obvious that some people will end up much richer than
others? In a world where some people like to write enterprise
software and others like to make studio pottery, economic inequality
is the natural outcome.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f2n"&gt;&lt;font color="#000000"&gt;2&lt;/font&gt;&lt;/a&gt;]
Difficulty choosing between interests is a different matter.
That's not always due to ignorance. It's often intrinsically
difficult. I still have trouble doing it.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f3n"&gt;&lt;font color="#000000"&gt;3&lt;/font&gt;&lt;/a&gt;]
You can't always take people at their word on this. Since
it's more prestigious to work on things you're interested in than
to be driven by money, people who are driven mainly by money will
often claim to be more interested in their work than they actually
are. One way to test such claims is by doing the following thought
experiment: if their work didn't pay well, would they take day jobs
doing something else in order to do it in their spare time? Lots
of mathematicians and scientists and engineers would. Historically
lots &lt;i&gt;have&lt;/i&gt;. But I don't think as many investment bankers would.&lt;br/&gt;&lt;br/&gt;This thought experiment is also useful for distinguishing between
university departments.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;font color="888888"&gt;&lt;b&gt;Thanks&lt;/b&gt; to Trevor Blackwell, Paul Buchheit, 
Jessica Livingston,
Robert Morris, Harj Taggar, and Garry Tan for reading drafts of
this.&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;&lt;/font&gt;</content:encoded>
      <guid isPermaLink="false">https://paulgraham.com//when.html</guid>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Writes and Write-Nots</title>
      <link>https://paulgraham.com//writes.html</link>
      <description>&lt;font face="verdana" size="2"&gt;October 2024&lt;br/&gt;&lt;br/&gt;I'm usually reluctant to make predictions about technology, but I feel fairly confident about this one: in a couple decades there won't be many people who can write.&lt;br/&gt;&lt;br/&gt;One of the strangest things you learn if you're a writer is how many people have trouble writing. Doctors know how many people have a mole they're worried about; people who are good at setting up computers know how many people aren't; writers know how many people need help&lt;/font&gt;</description>
      <content:encoded>&lt;font face="verdana" size="2"&gt;October 2024&lt;br/&gt;&lt;br/&gt;I'm usually reluctant to make predictions about technology, but I
feel fairly confident about this one: in a couple decades there
won't be many people who can write.&lt;br/&gt;&lt;br/&gt;One of the strangest things you learn if you're a writer is how
many people have trouble writing. Doctors know how many people have
a mole they're worried about; people who are good at setting up
computers know how many people aren't; writers know how many people
need help writing.&lt;br/&gt;&lt;br/&gt;The reason so many people have trouble writing is that it's
fundamentally difficult. To write well you have to think clearly,
and thinking clearly is hard.&lt;br/&gt;&lt;br/&gt;And yet writing pervades many jobs, and the more prestigious the
job, the more writing it tends to require.&lt;br/&gt;&lt;br/&gt;These two powerful opposing forces, the pervasive expectation of
writing and the irreducible difficulty of doing it, create enormous
pressure. This is why eminent professors often turn out to have
resorted to plagiarism. The most striking thing to me about these
cases is the pettiness of the thefts. The stuff they steal is usually
the most mundane boilerplate — the sort of thing that anyone who
was even halfway decent at writing could turn out with no effort
at all. Which means they're not even halfway decent at writing.&lt;br/&gt;&lt;br/&gt;Till recently there was no convenient escape valve for the pressure
created by these opposing forces. You could pay someone to write
for you, like JFK, or plagiarize, like MLK, but if you couldn't buy
or steal words, you had to write them yourself. And as a result
nearly everyone who was expected to write had to learn how.&lt;br/&gt;&lt;br/&gt;Not anymore. AI has blown this world open. Almost all pressure to
write has dissipated. You can have AI do it for you, both in school
and at work.&lt;br/&gt;&lt;br/&gt;The result will be a world divided into writes and write-nots.
There will still be some people who can write. Some of us like it.
But the middle ground between those who are good at writing and
those who can't write at all will disappear. Instead of good writers,
ok writers, and people who can't write, there will just be good
writers and people who can't write.&lt;br/&gt;&lt;br/&gt;Is that so bad? Isn't it common for skills to disappear when
technology makes them obsolete? There aren't many blacksmiths left,
and it doesn't seem to be a problem.&lt;br/&gt;&lt;br/&gt;Yes, it's bad. The reason is something I mentioned earlier: writing
is thinking. In fact there's a kind of thinking that can only be
done by writing. You can't make this point better than Leslie Lamport
did:
&lt;blockquote&gt;
  If you're thinking without writing, you only think you're thinking.
&lt;/blockquote&gt;
So a world divided into writes and write-nots is more dangerous
than it sounds. It will be a world of thinks and think-nots. I know
which half I want to be in, and I bet you do too.&lt;br/&gt;&lt;br/&gt;This situation is not unprecedented. In preindustrial times most
people's jobs made them strong. Now if you want to be strong, you
work out. So there are still strong people, but only those who
choose to be.&lt;br/&gt;&lt;br/&gt;It will be the same with writing. There will still be smart people,
but only those who choose to be.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;font color="888888"&gt;&lt;b&gt;Thanks&lt;/b&gt; to Jessica Livingston, Ben Miller, 
and Robert Morris for reading drafts of this.&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;&lt;/font&gt;</content:encoded>
      <guid isPermaLink="false">https://paulgraham.com//writes.html</guid>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>The Origins of Wokeness</title>
      <link>https://paulgraham.com//woke.html</link>
      <description>&lt;font face="verdana" size="2"&gt;January 2025&lt;br/&gt;&lt;br/&gt;The word "prig" isn't very common now, but if you look up the definition, it will sound familiar. Google's isn't bad: &lt;blockquote&gt; A self-righteously moralistic person who behaves as if superior to others. &lt;/blockquote&gt; This sense of the word originated in the 18th century, and its age is an important clue: it shows that although wokeness is a comparatively recent phenomenon, it's an instance of a much older one.&lt;br/&gt;&lt;br/&gt;There's a certain &lt;/font&gt;</description>
      <content:encoded>&lt;font face="verdana" size="2"&gt;January 2025&lt;br/&gt;&lt;br/&gt;The word "prig" isn't very common now, but if you look up
the definition, it will sound familiar. Google's isn't bad:
&lt;blockquote&gt;
  A self-righteously moralistic person who behaves as if
  superior to others.
&lt;/blockquote&gt;
This sense of the word originated in the 18th century, and
its age is an important clue: it shows that although
wokeness is a comparatively recent phenomenon, it's an
instance of a much older one.&lt;br/&gt;&lt;br/&gt;There's a certain kind of person who's attracted to a
shallow, exacting kind of moral purity, and who demonstrates
his purity by attacking anyone who breaks the rules. Every
society has these people. All that changes is the rules they
enforce. In Victorian England it was Christian virtue. In
Stalin's Russia it was orthodox Marxism-Leninism. For the
woke, it's social justice.&lt;br/&gt;&lt;br/&gt;So if you want to understand wokeness, the question to ask
is not why people behave this way. Every society has prigs.
The question to ask is why our prigs are priggish about
these ideas, at this moment. And to answer that we have to
ask when and where wokeness began.&lt;br/&gt;&lt;br/&gt;The answer to the first question is the 1980s. Wokeness is a
second, more aggressive wave of political correctness, which
started in the late 1980s, died down in the late 1990s, and
then returned with a vengeance in the early 2010s, finally
peaking after the riots of 2020.&lt;br/&gt;&lt;br/&gt;This was not the original meaning of "woke," but it's rarely
used in the original sense now. Now the pejorative sense is
the dominant one. What &lt;i&gt;does&lt;/i&gt; it mean now? I've often been
asked to define both wokeness and political correctness by
people who think they're meaningless labels, so I will. They
both have the same definition:
&lt;blockquote&gt;
  An aggressively performative focus on social justice.
&lt;/blockquote&gt;
In other words, it's people being prigs about social
justice. And that's the real problem — the
performativeness, not the social justice.&lt;br/&gt;&lt;br/&gt;Racism, for example, is a genuine problem. Not a problem on
the scale that the woke believe it to be, but a genuine one.
I don't think any reasonable person would deny that. The
problem with political correctness was not that it focused
on marginalized groups, but the shallow, aggressive way in
which it did so. Instead of going out into the world and
quietly helping members of marginalized groups, the
politically correct focused on getting people in trouble for
using the wrong words to talk about them.&lt;br/&gt;&lt;br/&gt;As for where political correctness began, if you think about
it, you probably already know the answer. Did it begin
outside universities and spread to them from this external
source? Obviously not; it has always been most extreme in
universities. So where in universities did it begin? Did it
begin in math, or the hard sciences, or engineering, and
spread from there to the humanities and social sciences?
Those are amusing images, but no, obviously it began in the
humanities and social sciences.&lt;br/&gt;&lt;br/&gt;Why there? And why then? What happened in the humanities and
social sciences in the 1980s?&lt;br/&gt;&lt;br/&gt;A successful theory of the origin of political correctness
has to be able to explain why it didn't happen earlier. Why
didn't it happen during the protest movements of the 1960s,
for example? They were concerned with much the same issues.
&lt;font color="#dddddd"&gt;[&lt;a href="#f1n"&gt;&lt;font color="#dddddd"&gt;1&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;The reason the student protests of the 1960s didn't lead to
political correctness was precisely that — they were
student movements. They didn't have any real power. The
students may have been talking a lot about women's
liberation and black power, but it was not what they were
being taught in their classes. Not yet.&lt;br/&gt;&lt;br/&gt;But in the early 1970s the student protestors of the 1960s
began to finish their dissertations and get hired as
professors. At first they were neither powerful nor
numerous. But as more of their peers joined them and the
previous generation of professors started to retire, they
gradually became both.&lt;br/&gt;&lt;br/&gt;The reason political correctness began in the humanities and
social sciences was that these fields offered more scope for
the injection of politics. A 1960s radical who got a job as
a physics professor could still attend protests, but his
political beliefs wouldn't affect his work. Whereas research
in sociology and modern literature can be made as political
as you like.
&lt;font color="#dddddd"&gt;[&lt;a href="#f2n"&gt;&lt;font color="#dddddd"&gt;2&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;I saw political correctness arise. When I started college in
1982 it was not yet a thing. Female students might object if
someone said something they considered sexist, but no one
was getting &lt;i&gt;reported&lt;/i&gt; for it. It was still not a thing when
I started grad school in 1986. It was definitely a thing in
1988 though, and by the early 1990s it seemed to pervade
campus life.&lt;br/&gt;&lt;br/&gt;What happened? How did protest become punishment? Why were
the late 1980s the point at which protests against male
chauvinism (as it used to be called) morphed into formal
complaints to university authorities about sexism?
Basically, the 1960s radicals got tenure. They became the
Establishment they'd protested against two decades before.
Now they were in a position not just to speak out about
their ideas, but to enforce them.&lt;br/&gt;&lt;br/&gt;A new set of moral rules to enforce was exciting news to a
certain kind of student. What made it particularly exciting
was that they were allowed to attack professors. I remember
noticing that aspect of political correctness at the time.
It wasn't simply a grass-roots student movement. It was
faculty members encouraging students to attack other faculty
members. In that respect it was like the Cultural
Revolution. That wasn't a grass-roots movement either; that
was Mao unleashing the younger generation on his political
opponents. And in fact when Roderick MacFarquhar started
teaching a class on the Cultural Revolution at Harvard in
the late 1980s, many saw it as a comment on current events.
I don't know if it actually was, but people thought it was,
and that means the similarities were obvious.
&lt;font color="#dddddd"&gt;[&lt;a href="#f3n"&gt;&lt;font color="#dddddd"&gt;3&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;College students larp. It's their nature. It's usually
harmless. But larping morality turned out to be a poisonous
combination. The result was a kind of moral etiquette,
superficial but very complicated. Imagine having to explain
to a well-meaning visitor from another planet why using the
phrase "people of color" is considered particularly
enlightened, but saying "colored people" gets you fired. And
why exactly one isn't supposed to use the word "negro" now,
even though Martin Luther King used it constantly in his
speeches. There are no underlying principles. You'd just
have to give him a long list of rules to memorize.
&lt;font color="#dddddd"&gt;[&lt;a href="#f4n"&gt;&lt;font color="#dddddd"&gt;4&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;
The danger of these rules was not just that they created
land mines for the unwary, but that their elaborateness made
them an effective substitute for virtue. Whenever a society
has a concept of heresy and orthodoxy, orthodoxy becomes a
substitute for virtue. You can be the worst person in the
world, but as long as you're orthodox you're better than
everyone who isn't. This makes orthodoxy very attractive to
bad people.&lt;br/&gt;&lt;br/&gt;But for it to work as a substitute for virtue, orthodoxy
must be difficult. If all you have to do to be orthodox is
wear some garment or avoid saying some word, everyone knows
to do it, and the only way to seem more virtuous than other
people is to actually be virtuous. The shallow, complicated,
and frequently changing rules of political correctness made
it the perfect substitute for actual virtue. And the result
was a world in which good people who weren't up to date on
current moral fashions were brought down by people whose
characters would make you recoil in horror if you could see
them.&lt;br/&gt;&lt;br/&gt;One big contributing factor in the rise of political
correctness was the lack of other things to be morally pure
about. Previous generations of prigs had been prigs mostly
about religion and sex. But among the cultural elite these
were the deadest of dead letters by the 1980s; if you were
religious, or a virgin, this was something you tended to
conceal rather than advertise. So the sort of people who
enjoy being moral enforcers had become starved of things to
enforce. A new set of rules was just what they'd been
waiting for.&lt;br/&gt;&lt;br/&gt;Curiously enough, the tolerant side of the 1960s left helped
create the conditions in which the intolerant side
prevailed. The relaxed social rules advocated by the old,
easy-going hippy left became the dominant ones, at least
among the elite, and this left nothing for the naturally
intolerant to be intolerant about.&lt;br/&gt;&lt;br/&gt;Another possibly contributing factor was the fall of the
Soviet empire. Marxism had been a popular focus of moral
purity on the left before political correctness emerged as a
competitor, but the pro-democracy movements in Eastern Bloc
countries took most of the shine off it. Especially the fall
of the Berlin Wall in 1989. You couldn't be on the side of
the Stasi. I remember looking at the moribund Soviet Studies
section of a used bookshop in Cambridge in the late 1980s
and thinking "what will those people go on about now?" As it
turned out the answer was right under my nose.&lt;br/&gt;&lt;br/&gt;One thing I noticed at the time about the first phase of
political correctness was that it was more popular with
women than men. As many writers (perhaps most eloquently
George Orwell) have observed, women seem more attracted than
men to the idea of being moral enforcers. But there was
another more specific reason women tended to be the
enforcers of political correctness. There was at this time a
great backlash against sexual harassment; the mid 1980s were
the point when the definition of sexual harassment was
expanded from explicit sexual advances to creating a
"hostile environment." Within universities the classic form
of accusation was for a (female) student to say that a
professor made her "feel uncomfortable." But the vagueness
of this accusation allowed the radius of forbidden behavior
to expand to include talking about heterodox ideas. Those
make people uncomfortable too.
&lt;font color="#dddddd"&gt;[&lt;a href="#f5n"&gt;&lt;font color="#dddddd"&gt;5&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;Was it sexist to propose that Darwin's greater male
variability hypothesis might explain some variation in human
performance? Sexist enough to get Larry Summers pushed out
as president of Harvard, apparently. One woman who heard the
talk in which he mentioned this idea said it made her feel
"physically ill" and that she had to leave halfway through.
If the test of a hostile environment is how it makes people
feel, this certainly sounds like one. And yet it does seem
plausible that greater male variability explains some of the
variation in human performance. So which should prevail,
comfort or truth? Surely if truth should prevail anywhere,
it should be in universities; that's supposed to be their
specialty; but for decades starting in the late 1980s the
politically correct tried to pretend this conflict didn't
exist.
&lt;font color="#dddddd"&gt;[&lt;a href="#f6n"&gt;&lt;font color="#dddddd"&gt;6&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;Political correctness seemed to burn out in the second half
of the 1990s. One reason, perhaps the main reason, was that
it literally became a joke. It offered rich material for
comedians, who performed their usual disinfectant action
upon it. Humor is one of the most powerful weapons against
priggishness of any sort, because prigs, being humorless,
can't respond in kind. Humor was what defeated Victorian
prudishness, and by 2000 it seemed to have done the same
thing to political correctness.&lt;br/&gt;&lt;br/&gt;Unfortunately this was an illusion. Within universities the
embers of political correctness were still glowing brightly.
After all, the forces that created it were still there. The
professors who started it were now becoming deans and
department heads. And in addition to their departments there
were now a bunch of new ones explicitly focused on social
justice. Students were still hungry for things to be morally
pure about. And there had been an explosion in the number of
university administrators, many of whose jobs involved
enforcing various forms of political correctness.&lt;br/&gt;&lt;br/&gt;In the early 2010s the embers of political correctness burst
into flame anew. There were several differences between this
new phase and the original one. It was more virulent. It
spread further into the real world, although it still burned
hottest within universities. And it was concerned with a
wider variety of sins. In the first phase of political
correctness there were really only three things people got
accused of: sexism, racism, and homophobia (which at the
time was a neologism invented for the purpose). But between
then and 2010 a lot of people had spent a lot of time trying
to invent new kinds of -isms and -phobias and seeing which
could be made to stick.&lt;br/&gt;&lt;br/&gt;The second phase was, in multiple senses, political
correctness metastasized. Why did it happen when it did? My
guess is that it was due to the rise of social media,
particularly Tumblr and Twitter, because one of the most
distinctive features of the second wave of political
correctness was the &lt;i&gt;cancel mob&lt;/i&gt;: a mob of angry people
uniting on social media to get someone ostracized or fired.
Indeed this second wave of political correctness was
originally called "cancel culture"; it didn't start to be
called "wokeness" till the 2020s.&lt;br/&gt;&lt;br/&gt;One aspect of social media that surprised almost everyone at
first was the popularity of outrage. Users seemed to &lt;i&gt;like&lt;/i&gt;
being outraged. We're so used to this idea now that we take
it for granted, but really it's pretty strange. Being
outraged is not a pleasant feeling. You wouldn't expect
people to seek it out. But they do. And above all, they want
to share it. I happened to be running a forum from 2007 to
2014, so I can actually quantify how much they want to share
it: our users were about three times more likely to upvote
something if it outraged them.&lt;br/&gt;&lt;br/&gt;This tilt toward outrage wasn't due to wokeness. It's an
inherent feature of social media, or at least this
generation of it. But it did make social media the perfect
mechanism for fanning the flames of wokeness.
&lt;font color="#dddddd"&gt;[&lt;a href="#f7n"&gt;&lt;font color="#dddddd"&gt;7&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;It wasn't just public social networks that drove the rise of
wokeness though. Group chat apps were also critical,
especially in the final step, cancellation. Imagine if a
group of employees trying to get someone fired had to do it
using only email. It would be hard to organize a mob. But
once you have group chat, mobs form naturally.&lt;br/&gt;&lt;br/&gt;Another contributing factor in this second wave of political
correctness was the dramatic increase in the polarization of
the press. In the print era, newspapers were constrained to
be, or at least seem, politically neutral. The department
stores that ran ads in the New York Times wanted to reach
everyone in the region, both liberal and conservative, so
the Times had to serve both. But the Times didn't regard
this neutrality as something forced upon them. They embraced
it as their duty as a &lt;i&gt;paper of record&lt;/i&gt; — as one of the big
newspapers that aimed to be chronicles of their times,
reporting every sufficiently important story from a neutral
point of view.&lt;br/&gt;&lt;br/&gt;When I grew up the papers of record seemed timeless, almost
sacred institutions. Papers like the New York Times and
Washington Post had immense prestige, partly because other
sources of news were limited, but also because they did make
some effort to be neutral.&lt;br/&gt;&lt;br/&gt;Unfortunately it turned out that the paper of record was
mostly an artifact of the constraints imposed by print.
&lt;font color="#dddddd"&gt;[&lt;a href="#f8n"&gt;&lt;font color="#dddddd"&gt;8&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;
When your market was determined by geography, you had
to be neutral. But publishing online enabled — in fact
probably forced — newspapers to switch to serving markets
defined by ideology instead of geography. Most that remained
in business fell in the direction they'd already been
leaning: left. On October 11, 2020 the New York Times
announced that "The paper is in the midst of an evolution
from the stodgy paper of record into a juicy collection of
great narratives."
&lt;font color="#dddddd"&gt;[&lt;a href="#f9n"&gt;&lt;font color="#dddddd"&gt;9&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;
Meanwhile journalists, of a sort,
had arisen to serve the right as well. And so journalism,
which in the previous era had been one of the great
centralizing forces, now became one of the great polarizing
ones.&lt;br/&gt;&lt;br/&gt;The rise of social media and the increasing polarization of
journalism reinforced one another. In fact there arose a new
variety of journalism involving a loop through social media.
Someone would say something controversial on social media.
Within hours it would become a news story. Outraged readers
would then post links to the story on social media, driving
further arguments online. It was the cheapest source of
clicks imaginable. You didn't have to maintain overseas news
bureaus or pay for month-long investigations. All you had to
do was watch Twitter for controversial remarks and repost
them on your site, with some additional comments to inflame
readers further.&lt;br/&gt;&lt;br/&gt;For the press there was money in wokeness. But they weren't
the only ones. That was one of the biggest differences
between the two waves of political correctness: the first
was driven almost entirely by amateurs, but the second was
often driven by professionals. For some it was their whole
job. By 2010 a new class of administrators had arisen whose
job was basically to enforce wokeness. They played a role
similar to that of the political commissars who got attached
to military and industrial organizations in the USSR: they
weren't directly in the flow of the organization's work, but
watched from the side to ensure that nothing improper
happened in the doing of it. These new administrators could
often be recognized by the word "inclusion" in their titles.
Within institutions this was the preferred euphemism for
wokeness; a new list of banned words, for example, would
usually be called an "inclusive language guide."
&lt;font color="#dddddd"&gt;[&lt;a href="#f10n"&gt;&lt;font color="#dddddd"&gt;10&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;This new class of bureaucrats pursued a woke agenda as if
their jobs depended on it, because they did. If you hire
people to keep watch for a particular type of problem,
they're going to find it, because otherwise there's no
justification for their existence.
&lt;font color="#dddddd"&gt;[&lt;a href="#f11n"&gt;&lt;font color="#dddddd"&gt;11&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;
But these
bureaucrats also represented a second and possibly even
greater danger. Many were involved in hiring, and when
possible they tried to ensure their employers hired only
people who shared their political beliefs. The most
egregious cases were the new "DEI statements" that some
universities started to require from faculty candidates,
proving their commitment to wokeness. Some universities used
these statements as the initial filter and only even
considered candidates who scored high enough on them. You're
not hiring Einstein that way; imagine what you get instead.&lt;br/&gt;&lt;br/&gt;Another factor in the rise of wokeness was the Black Lives
Matter movement, which started in 2013 when a white man was
acquitted after killing a black teenager in Florida. But
this didn't launch wokeness; it was well underway by 2013.&lt;br/&gt;&lt;br/&gt;Similarly for the Me Too Movement, which took off in 2017
after the first news stories about Harvey Weinstein's
history of raping women. It accelerated wokeness, but didn't
play the same role in launching it that the 80s version did
in launching political correctness.&lt;br/&gt;&lt;br/&gt;The election of Donald Trump in 2016 also accelerated
wokeness, particularly in the press, where outrage now meant
traffic. Trump made the New York Times a lot of money:
headlines during his first administration mentioned his name
at about four times the rate of previous presidents.&lt;br/&gt;&lt;br/&gt;In 2020 we saw the biggest accelerant of all, after a white
police officer asphyxiated a black suspect on video. At this
point the metaphorical fire became a literal one, as violent
protests broke out across America. But in retrospect this
turned out to be peak woke, or close to it. By every measure
I've seen, wokeness peaked in 2020 or 2021.&lt;br/&gt;&lt;br/&gt;Wokeness is sometimes described as a mind-virus. What makes
it viral is that it defines new types of impropriety. Most
people are afraid of impropriety; they're never exactly sure
what the social rules are or which ones they might be
breaking. Especially if the rules change rapidly. And since
most people already worry that they might be breaking rules
they don't know about, if you tell them they're breaking a
rule, their default reaction is to believe you. Especially
if multiple people tell them. Which in turn is a recipe for
exponential growth. Zealots invent some new impropriety to
avoid. The first people to adopt it are fellow zealots,
eager for new ways to signal their virtue. If there are
enough of these, the initial group of zealots is followed by
a much larger group, motivated by fear. They're not trying
to signal virtue; they're just trying to avoid getting in
trouble. At this point the new impropriety is now firmly
established. Plus its success has increased the rate of
change in social rules, which, remember, is one of the
reasons people are nervous about which rules they might be
breaking. So the cycle accelerates.
&lt;font color="#dddddd"&gt;[&lt;a href="#f12n"&gt;&lt;font color="#dddddd"&gt;12&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;What's true of individuals is even more true of
organizations. Especially organizations without a powerful
leader. Such organizations do everything based on "best
practices." There's no higher authority; if some new "best
practice" achieves critical mass, they &lt;i&gt;must&lt;/i&gt; adopt it. And
in this case the organization can't do what it usually does
when it's uncertain: delay. It might be committing
improprieties right now! So it's surprisingly easy for a
small group of zealots to capture this type of organization
by describing new improprieties it might be guilty of. 
&lt;font color="#dddddd"&gt;[&lt;a href="#f13n"&gt;&lt;font color="#dddddd"&gt;13&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;How does this kind of cycle ever end? Eventually it leads to
disaster, and people start to say enough is enough. The
excesses of 2020 made a lot of people say that.&lt;br/&gt;&lt;br/&gt;Since then wokeness has been in gradual but continual
retreat. Corporate CEOs, starting with Brian Armstrong, have
openly rejected it. Universities, led by the University of
Chicago and MIT, have explicitly confirmed their commitment
to free speech. Twitter, which was arguably the hub of
wokeness, was bought by Elon Musk in order to neutralize it,
and he seems to have succeeded — and not, incidentally, by
censoring left-wing users the way Twitter used to censor
right-wing ones, but without censoring either.
&lt;font color="#dddddd"&gt;[&lt;a href="#f14n"&gt;&lt;font color="#dddddd"&gt;14&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;
Consumers have emphatically rejected brands that ventured
too far into wokeness. The Bud Light brand may have been
permanently damaged by it. I'm not going to claim Trump's
second victory in 2024 was a referendum on wokeness; I think
he won, as presidential candidates always do, because he was
more &lt;a href="charisma.html"&gt;&lt;u&gt;charismatic&lt;/u&gt;&lt;/a&gt;; but voters' 
disgust with wokeness must have helped.&lt;br/&gt;&lt;br/&gt;So what do we do now? Wokeness is already in retreat.
Obviously we should help it along. What's the best way to do
that? And more importantly, how do we avoid a third
outbreak? After all, it seemed to be dead once, but came
back worse than ever.&lt;br/&gt;&lt;br/&gt;In fact there's an even more ambitious goal: is there a way
to prevent any similar outbreak of aggressively performative
moralism in the future — not just a third outbreak of
political correctness, but the next thing like it? Because
there will be a next thing. Prigs are prigs by nature. They
need rules to obey and enforce, and now that Darwin has cut
off their traditional supply of rules, they're constantly
hungry for new ones. All they need is someone to meet them
halfway by defining a new way to be morally pure, and we'll
see the same phenomenon again.&lt;br/&gt;&lt;br/&gt;Let's start with the easier problem. Is there a simple,
principled way to deal with wokeness? I think there is: to
use the customs we already have for dealing with religion.
Wokeness is effectively a religion, just with God replaced
by protected classes. It's not even the first religion of
this kind; Marxism had a similar form, with God replaced by
the masses.
&lt;font color="#dddddd"&gt;[&lt;a href="#f15n"&gt;&lt;font color="#dddddd"&gt;15&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;
And we already have well-established
customs for dealing with religion within organizations. You
can express your own religious identity and explain your
beliefs, but you can't call your coworkers infidels if they
disagree, or try to ban them from saying things that
contradict its doctrines, or insist that the organization
adopt yours as its official religion.&lt;br/&gt;&lt;br/&gt;If we're not sure what to do about any particular
manifestation of wokeness, imagine we were dealing with some
other religion, like Christianity. Should we have people
within organizations whose jobs are to enforce woke
orthodoxy? No, because we wouldn't have people whose jobs
were to enforce Christian orthodoxy. Should we censor
&lt;a href="https://www.telegraph.co.uk/news/2023/02/17/roald-dahl-books-rewritten-offensive-matilda-witches-twits/"&gt;&lt;u&gt;writers&lt;/u&gt;&lt;/a&gt; or 
&lt;a href="https://x.com/KoustaStavroula/status/1562034502897106946"&gt;&lt;u&gt;scientists&lt;/u&gt;&lt;/a&gt; whose work contradicts woke doctrines?
No, because we wouldn't do this to people whose work
contradicted Christian teachings. Should job candidates be
required to write DEI statements? Of course not; imagine an
employer requiring proof of one's religious beliefs. Should
students and employees have to participate in woke
indoctrination sessions in which they're required to answer
questions about their beliefs to ensure compliance? No,
because we wouldn't dream of catechizing people in this way
about their religion.
&lt;font color="#dddddd"&gt;[&lt;a href="#f16n"&gt;&lt;font color="#dddddd"&gt;16&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;One shouldn't feel bad about not wanting to watch woke
movies any more than one would feel bad about not wanting to
listen to Christian rock. In my twenties I drove across
America several times, listening to local radio stations.
Occasionally I'd turn the dial and hear some new song. But
the moment anyone mentioned Jesus I'd turn the dial again.
Even the tiniest bit of being preached to was enough to make
me lose interest.&lt;br/&gt;&lt;br/&gt;But by the same token we should not automatically reject
everything the woke believe. I'm not a Christian, but I can
see that many Christian principles are good ones. It would
be a mistake to discard them all just because one didn't
share the religion that espoused them. It would be the sort
of thing a religious zealot would do.&lt;br/&gt;&lt;br/&gt;If we have genuine pluralism, I think we'll be safe from
future outbreaks of woke intolerance. Wokeness itself won't
go away. There will for the foreseeable future continue to
be pockets of woke zealots inventing new moral fashions. The
key is not to let them treat their fashions as normative.
They can change what their coreligionists are allowed to say
every few months if they like, but they mustn't be allowed
to change what we're allowed to say.
&lt;font color="#dddddd"&gt;[&lt;a href="#f17n"&gt;&lt;font color="#dddddd"&gt;17&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;The more general problem — how to prevent similar outbreaks
of aggressively performative moralism — is of course
harder. Here we're up against human nature. There will
always be prigs. And in particular there will always be the
enforcers among them, the 
&lt;a href="conformism.html"&gt;&lt;u&gt;aggressively conventional-minded&lt;/u&gt;&lt;/a&gt;.
These people are born that way. Every society has them. So
the best we can do is to keep them bottled up.&lt;br/&gt;&lt;br/&gt;The aggressively conventional-minded aren't always on the
rampage. Usually they just enforce whatever random rules are
nearest to hand. They only become dangerous when some new
ideology gets a lot of them pointed in the same direction at
once. That's what happened during the Cultural Revolution,
and to a lesser extent (thank God) in the two waves of
political correctness we've experienced.&lt;br/&gt;&lt;br/&gt;We can't get rid of the aggressively conventional-minded.
&lt;font color="#dddddd"&gt;[&lt;a href="#f18n"&gt;&lt;font color="#dddddd"&gt;18&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;
And we couldn't prevent people from creating new
ideologies that appealed to them even if we wanted to. So if
we want to keep them bottled up, we have to do it one step
downstream. Fortunately when the aggressively
conventional-minded go on the rampage they always do one
thing that gives them away: they define new &lt;a href="heresy.html"&gt;&lt;u&gt;heresies&lt;/u&gt;&lt;/a&gt; to
punish people for. So the best way to protect ourselves from
future outbreaks of things like wokeness is to have powerful
antibodies against the concept of heresy.&lt;br/&gt;&lt;br/&gt;We should have a conscious bias against defining new forms
of heresy. Whenever anyone tries to ban saying something
that we'd previously been able to say, our initial
assumption should be that they're wrong. Only our initial
assumption of course. If they can prove we should stop
saying it, then we should. But the burden of proof is on
them. In liberal democracies, people trying to prevent
something from being said will usually claim they're not
merely engaging in censorship, but trying to prevent some
form of "harm". And maybe they're right. But once again, the
burden of proof is on them. It's not enough to claim harm;
they have to prove it.&lt;br/&gt;&lt;br/&gt;As long as the aggressively conventional-minded continue to
give themselves away by banning heresies, we'll always be
able to notice when they become aligned behind some new
ideology. And if we always fight back at that point, with
any luck we can stop them in their tracks.&lt;br/&gt;&lt;br/&gt;The number of true things we &lt;a href="say.html"&gt;&lt;u&gt;can't say&lt;/u&gt;&lt;/a&gt;
should not increase. If it does, something is wrong.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;Notes&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;[&lt;a name="f1n"&gt;&lt;font color="#000000"&gt;1&lt;/font&gt;&lt;/a&gt;]
Why did 1960s radicals focus on the causes they did?
One of the people who reviewed drafts of this essay
explained this so well that I asked if I could quote him:
&lt;blockquote&gt;
  The middle-class student protestors of the New Left
  rejected the socialist/Marxist left as unhip. They were
  interested in sexier forms of oppression uncovered by
  cultural analysis (Marcuse) and abstruse "Theory". Labor
  politics became stodgy and old-fashioned. This took a
  couple generations to work through. The woke ideology's
  conspicuous lack of interest in the working class is the
  tell-tale sign. Such fragments as are, er, left of the old
  left are anti-woke, and meanwhile the actual working class
  shifted to the populist right and gave us Trump. Trump and
  wokeness are cousins.&lt;br/&gt;&lt;br/&gt;The middle-class origins of wokeness smoothed its way
  through the institutions because it had no interest in
  "seizing the means of production" (how quaint such phrases
  seem now), which would quickly have run up against hard
  state and corporate power. The fact that wokeness only
  expressed interest in other kinds of class (race, sex,
  etc) signalled compromise with existing power: give us
  power within your system and we'll bestow the resource we
  control — moral rectitude — upon you. As an ideological
  stalking horse for gaining control over discourse and
  institutions, this succeeded where a more ambitious
  revolutionary program would not have.
&lt;/blockquote&gt;
[&lt;a name="f2n"&gt;&lt;font color="#000000"&gt;2&lt;/font&gt;&lt;/a&gt;]
It helped that the humanities and social sciences also
included some of the biggest and easiest undergrad majors.
If a political movement had to start with physics students,
it could never get off the ground; there would be too few of
them, and they wouldn't have the time to spare.&lt;br/&gt;&lt;br/&gt;At the top universities these majors are not as big as they
used to be, though. A 
&lt;a href="https://www.newyorker.com/magazine/2023/03/06/the-end-of-the-english-major"&gt;&lt;u&gt;2022 survey&lt;/u&gt;&lt;/a&gt; found that only 7% of
Harvard undergrads plan to major in the humanities, vs
nearly 30% during the 1970s. I expect wokeness is at least
part of the reason; when undergrads consider majoring in
English, it's presumably because they love the written word
and not because they want to listen to lectures about
racism.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f3n"&gt;&lt;font color="#000000"&gt;3&lt;/font&gt;&lt;/a&gt;]
The puppet-master-and-puppet character of political
correctness became clearly visible when a bakery near
Oberlin College was falsely accused of race discrimination
in 2016. In the subsequent civil trial, lawyers for the
bakery produced a text message from Oberlin Dean of Students
Meredith Raimondo that read "I'd say unleash the students if
I wasn't convinced this needs to be put behind us."&lt;br/&gt;&lt;br/&gt;[&lt;a name="f4n"&gt;&lt;font color="#000000"&gt;4&lt;/font&gt;&lt;/a&gt;]
The woke sometimes claim that wokeness is simply
treating people with respect. But if it were, that would be
the only rule you'd have to remember, and this is comically
far from being the case. My younger son likes to imitate
voices, and at one point when he was about seven I had to
explain which accents it was currently safe to imitate
publicly and which not. It took about ten minutes, and I
still hadn't covered all the cases.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f5n"&gt;&lt;font color="#000000"&gt;5&lt;/font&gt;&lt;/a&gt;]
In 1986 the Supreme Court ruled that creating a
hostile work environment could constitute sex
discrimination, which in turn affected universities via
Title IX. The court specified that the test of a hostile
environment was whether it would bother a reasonable person,
but since for a professor merely being the subject of a
sexual harassment complaint would be a disaster whether the
complainant was reasonable or not, in practice any joke or
remark remotely connected with sex was now effectively
forbidden. Which meant we'd now come full circle to
Victorian codes of behavior, when there was a large class of
things that might not be said "with ladies present."&lt;br/&gt;&lt;br/&gt;[&lt;a name="f6n"&gt;&lt;font color="#000000"&gt;6&lt;/font&gt;&lt;/a&gt;]
Much as they tried to pretend there was no conflict
between diversity and quality. But you can't simultaneously
optimize for two things that aren't identical. What
diversity actually means, judging from the way the term is
used, is proportional representation, and unless you're
selecting a group whose purpose is to be representative,
like poll respondents, optimizing for proportional
representation has to come at the expense of quality. This
is not because of anything about representation; it's the
nature of optimization; optimizing for x has to come at the
expense of y unless x and y are identical.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f7n"&gt;&lt;font color="#000000"&gt;7&lt;/font&gt;&lt;/a&gt;]
Maybe societies will eventually develop antibodies to
viral outrage. Maybe we were just the first to be exposed to
it, so it tore through us like an epidemic through a
previously isolated population. I'm fairly confident that it
would be possible to create new social media apps that were
less driven by outrage, and an app of this type would have a
good chance of stealing users from existing ones, because
the smartest people would tend to migrate to it.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f8n"&gt;&lt;font color="#000000"&gt;8&lt;/font&gt;&lt;/a&gt;]
I say "mostly" because I have hopes that journalistic
neutrality will return in some form. There is some market
for unbiased news, and while it may be small, it's valuable.
The rich and powerful want to know what's really going on;
that's how they became rich and powerful.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f9n"&gt;&lt;font color="#000000"&gt;9&lt;/font&gt;&lt;/a&gt;]
The Times made this momentous announcement very
informally, in passing in the middle of an 
&lt;a href="https://www.nytimes.com/2020/10/11/business/media/new-york-times-rukmini-callimachi-caliphate.html"&gt;&lt;u&gt;article&lt;/u&gt;&lt;/a&gt; about a
Times reporter who'd been criticized for inaccuracy. It's
quite possible no senior editor even approved it. But it's
somehow appropriate that this particular universe ended with
a whimper rather than a bang.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f10n"&gt;&lt;font color="#000000"&gt;10&lt;/font&gt;&lt;/a&gt;]
As the acronym DEI goes out of fashion, many of these
bureaucrats will try to go underground by changing their
titles. It looks like "belonging" will be a popular option.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f11n"&gt;&lt;font color="#000000"&gt;11&lt;/font&gt;&lt;/a&gt;]
If you've ever wondered why our legal system includes
protections like the separation of prosecutor, judge, and
jury, the right to examine evidence and cross-examine
witnesses, and the right to be represented by legal counsel,
the de facto 
&lt;a href="https://www.nytimes.com/2020/03/18/magazine/title-ix-sexual-harassment-accusations.html"&gt;parallel legal system&lt;/a&gt;
established by Title IX
makes that all too clear.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f12n"&gt;&lt;font color="#000000"&gt;12&lt;/font&gt;&lt;/a&gt;]
The invention of new improprieties is most visible in
the rapid evolution of woke nomenclature. This is
particularly annoying to me as a writer, because the new
names are always worse. Any religious observance has to be
inconvenient and slightly absurd; otherwise gentiles would
do it too. So "slaves" becomes "enslaved individuals." But
web search can show us the leading edge of moral growth in
real time: if you search for "individuals experiencing
slavery" you will as of this writing find five legit
attempts to use the phrase, and you'll even find two for
"individuals experiencing enslavement."&lt;br/&gt;&lt;br/&gt;[&lt;a name="f13n"&gt;&lt;font color="#000000"&gt;13&lt;/font&gt;&lt;/a&gt;]
Organizations that do dubious things are particularly
concerned with propriety, which is how you end up with
absurdities like tobacco and oil companies having higher ESG
ratings than Tesla.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f14n"&gt;&lt;font color="#000000"&gt;14&lt;/font&gt;&lt;/a&gt;]
Elon did something else that tilted Twitter rightward
though: he gave more visibility to paying users. Paying
users lean right on average, because people on the far left
dislike Elon and don't want to give him money. Elon
presumably knew this would happen. On the other hand, the
people on the far left have only themselves to blame; they
could tilt Twitter back to the left tomorrow if they wanted
to.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f15n"&gt;&lt;font color="#000000"&gt;15&lt;/font&gt;&lt;/a&gt;]
It even, as James Lindsay and Peter Boghossian
pointed out, has a concept of original sin: privilege. Which
means unlike Christianity's egalitarian version, people have varying
degrees of it. An able-bodied straight white
American male is born with such a load of sin that only by
the most abject repentance can he be saved.&lt;br/&gt;&lt;br/&gt;Wokeness also shares something rather funny with many actual
versions of Christianity: like God, the people for whose
sake wokeness purports to act are often revolted by the
things done in their name.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f16n"&gt;&lt;font color="#000000"&gt;16&lt;/font&gt;&lt;/a&gt;]
There is one exception to most of these rules: actual
religious organizations. It's reasonable for them to insist
on orthodoxy. But they in turn should declare that they're
religious organizations. It's rightly considered shady
when something that appears to be an ordinary business or
publication turns out to be a religious organization.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f17n"&gt;&lt;font color="#000000"&gt;17&lt;/font&gt;&lt;/a&gt;]
I don't want to give the impression that it will be
simple to roll back wokeness. There will be places where the
fight inevitably gets messy — particularly within
universities, which everyone has to share, yet which are
currently the most pervaded by wokeness of any institutions.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f18n"&gt;&lt;font color="#000000"&gt;18&lt;/font&gt;&lt;/a&gt;]
You can however get rid of aggressively
conventional-minded people within an organization, and in
many if not most organizations this would be an excellent
idea. Even a handful of them can do a lot of damage. I bet
you'd feel a noticeable improvement going from a handful to
none.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;font color="888888"&gt;&lt;b&gt;Thanks&lt;/b&gt; to Sam Altman, 
Ben Miller, Daniel Gackle, Robin Hanson, Jessica
Livingston, Greg Lukianoff, Harj Taggar, Garry Tan, and Tim
Urban for reading drafts of this.&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;&lt;/font&gt;</content:encoded>
      <guid isPermaLink="false">https://paulgraham.com//woke.html</guid>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>What to Do</title>
      <link>https://paulgraham.com//do.html</link>
      <description>&lt;font face="verdana" size="2"&gt;March 2025&lt;br/&gt;&lt;br/&gt;What should one do? That may seem a strange question, but it's not meaningless or unanswerable. It's the sort of question kids ask before they learn not to ask big questions. I only came across it myself in the process of investigating something else. But once I did, I thought I should at least try to answer it.&lt;br/&gt;&lt;br/&gt;So what &lt;i&gt;should&lt;/i&gt; one do? One should help people, and take care of the world. Those two are obvious. But is there anything &lt;/font&gt;</description>
      <content:encoded>&lt;font face="verdana" size="2"&gt;March 2025&lt;br/&gt;&lt;br/&gt;What should one do? That may seem a strange question, but it's not
meaningless or unanswerable. It's the sort of question kids ask
before they learn not to ask big questions. I only came across it
myself in the process of investigating something else. But once I
did, I thought I should at least try to answer it.&lt;br/&gt;&lt;br/&gt;So what &lt;i&gt;should&lt;/i&gt; one do? One should help people, and take care of
the world. Those two are obvious. But is there anything else? When
I ask that, the answer that pops up is &lt;i&gt;Make good new things&lt;/i&gt;.&lt;br/&gt;&lt;br/&gt;I can't prove that one should do this, any more than I can prove
that one should help people or take care of the world. We're talking
about first principles here. But I can explain why this principle
makes sense. The most impressive thing humans can do is to think.
It may be the most impressive thing that can be done. And the best
kind of thinking, or more precisely the best proof that one has
thought well, is to make good new things.&lt;br/&gt;&lt;br/&gt;I mean new things in a very general sense. Newton's physics was a
good new thing. Indeed, the first version of this principle was to
have good new ideas. But that didn't seem general enough: it didn't
include making art or music, for example, except insofar as they
embody new ideas. And while they may embody new ideas, that's not
all they embody, unless you stretch the word "idea" so uselessly
thin that it includes everything that goes through your nervous
system.&lt;br/&gt;&lt;br/&gt;Even for ideas that one has consciously, though, I prefer the
phrasing "make good new things." There are other ways to describe
the best kind of thinking. To make discoveries, for example, or to
understand something more deeply than others have. But how well do
you understand something if you can't make a model of it, or write
about it? Indeed, trying to express what you understand is not just
a way to prove that you understand it, but a way to understand it
better.&lt;br/&gt;&lt;br/&gt;Another reason I like this phrasing is that it biases us toward
creation. It causes us to prefer the kind of ideas that are naturally
seen as making things rather than, say, making critical observations
about things other people have made. Those are ideas too, and
sometimes valuable ones, but it's easy to trick oneself into believing
they're more valuable than they are. Criticism seems sophisticated,
and making new things often seems awkward, especially at first; and
yet it's precisely those first steps that are most rare and valuable.&lt;br/&gt;&lt;br/&gt;Is newness essential? I think so. Obviously it's essential in
science. If you copied a paper of someone else's and published it
as your own, it would seem not merely unimpressive but dishonest.
And it's similar in the arts. A copy of a good painting can be a
pleasing thing, but it's not impressive in the way the original
was. Which in turn implies it's not impressive to make the same
thing over and over, however well; you're just copying yourself.&lt;br/&gt;&lt;br/&gt;Note though that we're talking about a different kind of should
with this principle. Taking care of people and the world are shoulds
in the sense that they're one's duty, but making good new things
is a should in the sense that this is how to live to one's full
potential. Historically most rules about how to live have been a
mix of both kinds of should, though usually with more of the former
than the latter. 
&lt;font color="#dddddd"&gt;[&lt;a href="#f1n"&gt;&lt;font color="#dddddd"&gt;1&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;For most of history the question "What should one do?" got much the
same answer everywhere, whether you asked Cicero or Confucius. You
should be wise, brave, honest, temperate, and just, uphold tradition,
and serve the public interest. There was a long stretch where in
some parts of the world the answer became "Serve God," but in
practice it was still considered good to be wise, brave, honest,
temperate, and just, uphold tradition, and serve the public interest.
And indeed this recipe would have seemed right to most Victorians.
But there's nothing in it about taking care of the world or making
new things, and that's a bit worrying, because it seems like this
question should be a timeless one. The answer shouldn't change much.&lt;br/&gt;&lt;br/&gt;I'm not too worried that the traditional answers don't mention
taking care of the world. Obviously people only started to care
about that once it became clear we could ruin it. But how can making
good new things be important if the traditional answers don't mention
it?&lt;br/&gt;&lt;br/&gt;The traditional answers were answers to a slightly different question.
They were answers to the question of how to be, rather than what
to do. The audience didn't have a lot of choice about what to do.
The audience up till recent centuries was the landowning class,
which was also the political class. They weren't choosing between
doing physics and writing novels. Their work was foreordained:
manage their estates, participate in politics, fight when necessary.
It was ok to do certain other kinds of work in one's spare time,
but ideally one didn't have any. Cicero's &lt;i&gt;De Officiis&lt;/i&gt; is one of the
great classical answers to the question of how to live, and in it
he explicitly says that he wouldn't even be writing it if he hadn't
been excluded from public life by recent political upheavals.
&lt;font color="#dddddd"&gt;[&lt;a href="#f2n"&gt;&lt;font color="#dddddd"&gt;2&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;There were of course people doing what we would now call "original
work," and they were often admired for it, but they weren't seen
as models. Archimedes knew that he was the first to prove that a
sphere has 2/3 the volume of the smallest enclosing cylinder and
was very pleased about it. But you don't find ancient writers urging
their readers to emulate him. They regarded him more as a prodigy
than a model.&lt;br/&gt;&lt;br/&gt;Now many more of us can follow Archimedes's example and devote most
of our attention to one kind of work. He turned out to be a model
after all, along with a collection of other people that his
contemporaries would have found it strange to treat as a distinct
group, because the vein of people making new things ran at right
angles to the social hierarchy.&lt;br/&gt;&lt;br/&gt;What kinds of new things count? I'd rather leave that question to
the makers of them. It would be a risky business to try to define
any kind of threshold, because new kinds of work are often despised
at first. Raymond Chandler was writing literal pulp fiction, and
he's now recognized as one of the best writers of the twentieth
century. Indeed this pattern is so common that you can use it as a
recipe: if you're excited about some kind of work that's not
considered prestigious and you can explain what everyone else is
overlooking about it, then this is not merely a kind of work that's
ok to do, but one to seek out.&lt;br/&gt;&lt;br/&gt;The other reason I wouldn't want to define any thresholds is that
we don't need them. The kind of people who make good new things 
don't need rules to keep them honest.&lt;br/&gt;&lt;br/&gt;So there's my guess at a set of principles to live by: take care
of people and the world, and make good new things. Different people
will do these to varying degrees. There will presumably be lots who
focus entirely on taking care of people. There will be a few who
focus mostly on making new things. But even if you're one of those,
you should at least make sure that the new things you make don't
net &lt;i&gt;harm&lt;/i&gt; people or the world. And if you go a step further and
try to make things that help them, you may find you're ahead on the
trade. You'll be more constrained in what you can make, but you'll
make it with more energy.&lt;br/&gt;&lt;br/&gt;On the other hand, if you make something amazing, you'll often be
helping people or the world even if you didn't mean to. Newton was
driven by curiosity and ambition, not by any practical effect his
work might have, and yet the practical effect of his work has been
enormous. And this seems the rule rather than the exception. So
if you think you can make something amazing, you should probably
just go ahead and do it.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;Notes&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;[&lt;a name="f1n"&gt;&lt;font color="#000000"&gt;1&lt;/font&gt;&lt;/a&gt;]
We could treat all three as the same kind of should by saying
that it's one's duty to live well — for example by saying, as some
Christians have, that it's one's duty to make the most of one's
God-given gifts. But this seems one of those casuistries people
invented to evade the stern requirements of religion: it was permissible to
spend time studying math instead of praying or performing acts of
charity because otherwise you were rejecting a gift God had given
you. A useful casuistry no doubt, but we don't need it.&lt;br/&gt;&lt;br/&gt;We could also combine the first two principles, since people are
part of the world. Why should our species get special treatment?
I won't try to justify this choice, but I'm skeptical that anyone
who claims to think differently actually lives according to their
principles.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f2n"&gt;&lt;font color="#000000"&gt;2&lt;/font&gt;&lt;/a&gt;]
Confucius was also excluded from public life after ending up
on the losing end of a power struggle, and presumably he too would
not be so famous now if it hadn't been for this long stretch of
enforced leisure.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;font color="888888"&gt;&lt;b&gt;Thanks&lt;/b&gt; to Trevor Blackwell, Jessica 
Livingston, and Robert Morris for reading drafts of this.&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;&lt;/font&gt;</content:encoded>
      <guid isPermaLink="false">https://paulgraham.com//do.html</guid>
      <pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Good Writing</title>
      <link>https://paulgraham.com//goodwriting.html</link>
      <description>&lt;font face="verdana" size="2"&gt;May 2025&lt;br/&gt;&lt;br/&gt;There are two senses in which writing can be good: it can sound good, and the ideas can be right. It can have nice, flowing sentences, and it can draw correct conclusions about important things. It might seem as if these two kinds of good would be unrelated, like the speed of a car and the color it's painted. And yet I don't think they are. I think writing that sounds good is more likely to be right.&lt;br/&gt;&lt;br/&gt;So here we have the most excitin&lt;/font&gt;</description>
      <content:encoded>&lt;font face="verdana" size="2"&gt;May 2025&lt;br/&gt;&lt;br/&gt;There are two senses in which writing can be good: it can&#13;
sound good, and the ideas can be right. It can have nice,&#13;
flowing sentences, and it can draw correct conclusions&#13;
about important things. It might seem as if these two&#13;
kinds of good would be unrelated, like the speed of a car&#13;
and the color it's painted. And yet I don't think they&#13;
are. I think writing that sounds good is more likely to&#13;
be right.&lt;br/&gt;&lt;br/&gt;So here we have the most exciting kind of idea: one that&#13;
seems both preposterous and true. Let's examine it. How&#13;
can this possibly be true?&lt;br/&gt;&lt;br/&gt;I know it's true from writing. You can't simultaneously&#13;
optimize two unrelated things; when you push one far&#13;
enough, you always end up sacrificing the other. And yet&#13;
no matter how hard I push, I never find myself having to&#13;
choose between the sentence that sounds best and the one&#13;
that expresses an idea best. If I did, it would be&#13;
frivolous to care how sentences sound. But in practice it&#13;
feels the opposite of frivolous. Fixing sentences that&#13;
sound bad seems to help get the ideas right.&#13;
&lt;font color="#dddddd"&gt;[&lt;a href="#f1n"&gt;&lt;font color="#dddddd"&gt;1&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;By right I mean more than just true. Getting the ideas&#13;
right means developing them well — drawing the&#13;
conclusions that matter most, and exploring each one to&#13;
the right level of detail. So getting the ideas right is&#13;
not just a matter of saying true things, but saying the&#13;
right true things.&lt;br/&gt;&lt;br/&gt;How could trying to make sentences sound good help you do&#13;
that? The clue to the answer is something I noticed 30&#13;
years ago when I was doing the layout for my first book.&#13;
Sometimes when you're laying out text you have bad luck.&#13;
For example, you get a section that runs one line longer&#13;
than the page. I don't know what ordinary typesetters do&#13;
in this situation, but what I did was rewrite the section&#13;
to make it a line shorter. You'd expect such an arbitrary&#13;
constraint to make the writing worse. But I found, to my&#13;
surprise, that it never did. I always ended up with&#13;
something I liked better.&lt;br/&gt;&lt;br/&gt;I don't think this was because my writing was especially&#13;
careless. I think if you pointed to a random paragraph in&#13;
anything written by anyone and told them to make it&#13;
slightly shorter (or longer), they'd probably be able to&#13;
come up with something better.&lt;br/&gt;&lt;br/&gt;The best analogy for this phenomenon is when you shake a&#13;
bin full of different objects. The shakes are arbitrary&#13;
motions. Or more precisely, they're not calculated to&#13;
make any two specific objects fit more closely together.&#13;
And yet repeated shaking inevitably makes the objects&#13;
discover brilliantly clever ways of packing themselves.&#13;
Gravity won't let them become less tightly packed, so any&#13;
change has to be a change for the better.&#13;
&lt;font color="#dddddd"&gt;[&lt;a href="#f2n"&gt;&lt;font color="#dddddd"&gt;2&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;So it is with writing. If you have to rewrite an awkward&#13;
passage, you'll never do it in a way that makes it &lt;i&gt;less&lt;/i&gt;&#13;
true. You couldn't bear it, any more than gravity could&#13;
bear things floating upward. So any change in the ideas&#13;
has to be a change for the better.&lt;br/&gt;&lt;br/&gt;It's obvious once you think about it. Writing that sounds&#13;
good is more likely to be right for the same reason that&#13;
a well-shaken bin is more likely to be tightly packed.&#13;
But there's something else going on as well. Sounding&#13;
good isn't just a random external force that leaves the&#13;
ideas in an essay better off. It actually helps you to&#13;
get them right.&lt;br/&gt;&lt;br/&gt;The reason is that it makes the essay easier to read.&#13;
It's less work to read writing that flows well. How does&#13;
that help the writer? &lt;i&gt;Because the writer is the first&#13;
reader.&lt;/i&gt; When I'm working on an essay, I spend far more&#13;
time reading than writing. I'll reread some parts 50 or&#13;
100 times, replaying the thoughts in them and asking&#13;
myself, like someone sanding a piece of wood, does&#13;
anything catch? Does anything feel wrong? And the easier&#13;
the essay is to read, the easier it is to notice if&#13;
something catches.&lt;br/&gt;&lt;br/&gt;So yes, the two senses of good writing are connected in&#13;
at least two ways. Trying to make writing sound good&#13;
makes you fix mistakes unconsciously, and also helps you&#13;
fix them consciously; it shakes the bin of ideas, and&#13;
also makes mistakes easier to see. But now that we've&#13;
dissolved one layer of preposterousness, I can't resist&#13;
adding another. Does sounding good do more than just help&#13;
you get the ideas right? Is writing that sounds good&#13;
&lt;i&gt;inherently&lt;/i&gt; more likely to be right? Crazy as it may&#13;
seem, I think that's true too.&lt;br/&gt;&lt;br/&gt;Obviously there's a connection at the level of individual&#13;
words. There are lots of words in English that sound like&#13;
what they mean, often in wonderfully subtle ways.&#13;
Glitter. Round. Scrape. Prim. Cavalcade. But the sound of&#13;
good writing depends even more on the way you put words&#13;
together, and there's a connection at that level too.&lt;br/&gt;&lt;br/&gt;When writing sounds good, it's mostly because it has good&#13;
rhythm. But the rhythm of good writing is not the rhythm&#13;
of music, or the meter of verse. It's not so regular. If&#13;
it were, it wouldn't be good, because the rhythm of good&#13;
writing has to match the ideas in it, and ideas have all&#13;
kinds of different shapes. Sometimes they're simple and&#13;
you just state them. But other times they're more subtle,&#13;
and you need longer, more complicated sentences to tease&#13;
out all the implications.&lt;br/&gt;&lt;br/&gt;An essay is a cleaned up train of thought, in the same&#13;
way dialogue is cleaned up conversation, and a train of&#13;
thought has a natural rhythm. So when an essay sounds&#13;
good, it's not merely because it has a pleasing rhythm,&#13;
but because it has its natural one. Which means you can&#13;
use getting the rhythm right as a heuristic for getting&#13;
the ideas right. And not just in principle: good writers&#13;
do both simultaneously as a matter of course. Often I&#13;
don't even distinguish between the two problems. I just&#13;
think Ugh, this doesn't sound right; what do I mean to&#13;
say here?&#13;
&lt;font color="#dddddd"&gt;[&lt;a href="#f3n"&gt;&lt;font color="#dddddd"&gt;3&lt;/font&gt;&lt;/a&gt;]&lt;/font&gt;&lt;br/&gt;&lt;br/&gt;The sound of writing turns out to be more like the shape&#13;
of a plane than the color of a car. If it looks good, as&#13;
Kelly Johnson used to say, it will fly well.&lt;br/&gt;&lt;br/&gt;This is only true of writing that's used to develop&#13;
ideas, though. It doesn't apply when you have ideas in&#13;
some other way and then write about them afterward — for&#13;
example, if you build something, or conduct an&#13;
experiment, and then write a paper about it. In such&#13;
cases the ideas often live more in the work than the&#13;
writing, so the writing can be bad even though the ideas&#13;
are good. The writing in textbooks and popular surveys&#13;
can be bad for the same reason: the author isn't&#13;
developing the ideas, merely describing other people's.&#13;
It's only when you're writing to develop ideas that&#13;
there's such a close connection between the two senses of&#13;
doing it well.&lt;br/&gt;&lt;br/&gt;Ok, many people will be thinking, this seems plausible so&#13;
far, but what about liars? Is it not notoriously possible&#13;
for a smooth-tongued liar to write something beautiful&#13;
that's completely false?&lt;br/&gt;&lt;br/&gt;It is, of course. But not without method acting. The way&#13;
to write something beautiful and false is to begin by&#13;
making yourself almost believe it. So just like someone&#13;
writing something beautiful and true, you're presenting a&#13;
perfectly-formed train of thought. The difference is the&#13;
point where it attaches to the world. You're saying&#13;
something that would be true if certain false premises&#13;
were. If for some bizarre reason the number of jobs in a&#13;
country were fixed, then immigrants really would be&#13;
taking our jobs.&lt;br/&gt;&lt;br/&gt;So it's not quite right to say that better sounding&#13;
writing is more likely to be true. Better sounding&#13;
writing is more likely to be internally consistent. If&#13;
the writer is honest, internal consistency and truth&#13;
converge.&lt;br/&gt;&lt;br/&gt;But while we can't safely conclude that beautiful writing&#13;
is true, it's usually safe to conclude the converse:&#13;
something that seems clumsily written will usually have&#13;
gotten the ideas wrong too.&lt;br/&gt;&lt;br/&gt;Indeed, the two senses of good writing are more like two&#13;
ends of the same thing. The connection between them is&#13;
not a rigid one; the goodness of good writing is not a&#13;
rod but a rope, with multiple overlapping connections&#13;
running through it. But it's hard to move one end without&#13;
moving the other. It's hard to be right without sounding&#13;
right.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
&lt;b&gt;Notes&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;[&lt;a name="f1n"&gt;&lt;font color="#000000"&gt;1&lt;/font&gt;&lt;/a&gt;]&#13;
The closest thing to an exception is when you have&#13;
to go back and insert a new point into the middle of&#13;
something you've written. This often messes up the flow,&#13;
sometimes in ways you can never quite repair. But I think&#13;
the ultimate source of this problem is that ideas are&#13;
tree-shaped and essays are linear. You inevitably run&#13;
into difficulties when you try to cram the former into&#13;
the latter. Frankly it's suprising how much you can get&#13;
away with. But even so you sometimes have to resort to an&#13;
endnote.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f2n"&gt;&lt;font color="#000000"&gt;2&lt;/font&gt;&lt;/a&gt;]&#13;
Obviously if you shake the bin hard enough the&#13;
objects in it can become less tightly packed. And&#13;
similarly, if you imposed some huge external constraint&#13;
on your writing, like using alternating one and two&#13;
syllable words, the ideas would start to suffer.&lt;br/&gt;&lt;br/&gt;[&lt;a name="f3n"&gt;&lt;font color="#000000"&gt;3&lt;/font&gt;&lt;/a&gt;]&#13;
Bizarrely enough, this happened in the writing of&#13;
this very paragraph. An earlier version shared several&#13;
phrases in common with the preceding paragraph, and the&#13;
repetition bugged me each time I reread it. When I got&#13;
annoyed enough to fix it, I discovered that the&#13;
repetition reflected a problem in the underlying ideas,&#13;
and I fixed both simultaneously.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
&lt;font color="888888"&gt;&lt;b&gt;Thanks&lt;/b&gt; to Jessica Livingston &#13;
and Courtenay Pipkin for reading drafts of this.&lt;br/&gt;&lt;br/&gt;&lt;/font&gt;&lt;/font&gt;</content:encoded>
      <guid isPermaLink="false">https://paulgraham.com//goodwriting.html</guid>
      <pubDate>Thu, 01 May 2025 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>
