{"href":"ecw.html","title":"How to Be an Expert in a Changing World","content":"<font face=\"verdana\" size=\"2\">December 2014<br/><br/>If the world were static, we could have monotonically increasing\nconfidence in our beliefs.  The more (and more varied) experience\na belief survived, the less likely it would be false.  Most people\nimplicitly believe something like this about their opinions.  And\nthey're justified in doing so with opinions about things that don't\nchange much, like human nature.  But you can't trust your opinions\nin the same way about things that change, which could include\npractically everything else.<br/><br/>When experts are wrong, it's often because they're experts on an\nearlier version of the world.<br/><br/>Is it possible to avoid that?  Can you protect yourself against\nobsolete beliefs?  To some extent, yes. I spent almost a decade\ninvesting in early stage startups, and curiously enough protecting\nyourself against obsolete beliefs is exactly what you have to do\nto succeed as a startup investor.  Most really good startup ideas\nlook like bad ideas at first, and many of those look bad specifically\nbecause some change in the world just switched them from bad to\ngood.  I spent a lot of time learning to recognize such ideas, and\nthe techniques I used may be applicable to ideas in general.<br/><br/>The first step is to have an explicit belief in change.  People who\nfall victim to a monotonically increasing confidence in their\nopinions are implicitly concluding the world is static.  If you\nconsciously remind yourself it isn't, you start to look for change.<br/><br/>Where should one look for it?  Beyond the moderately useful\ngeneralization that human nature doesn't change much, the unfortunate\nfact is that change is hard to predict.  This is largely a tautology\nbut worth remembering all the same: change that matters usually\ncomes from an unforeseen quarter.<br/><br/>So I don't even try to predict it.  When I get asked in interviews\nto predict the future, I always have to struggle to come up with\nsomething plausible-sounding on the fly, like a student who hasn't\nprepared for an exam.\n<font color=\"#999999\">[<a href=\"#f1n\"><font color=\"#999999\">1</font></a>]</font>\nBut it's not out of laziness that I haven't\nprepared.  It seems to me that beliefs about the future are so\nrarely correct that they usually aren't worth the extra rigidity\nthey impose, and that the best strategy is simply to be aggressively\nopen-minded.  Instead of trying to point yourself in the right\ndirection, admit you have no idea what the right direction is, and\ntry instead to be super sensitive to the winds of change.<br/><br/>It's ok to have working hypotheses, even though they may constrain\nyou a bit, because they also motivate you.  It's exciting to chase\nthings and exciting to try to guess answers.  But you have to be\ndisciplined about not letting your hypotheses harden into anything\nmore.\n<font color=\"#999999\">[<a href=\"#f2n\"><font color=\"#999999\">2</font></a>]</font><br/><br/>I believe this passive m.o. works not just for evaluating new ideas\nbut also for having them.  The way to come up with new ideas is not\nto try explicitly to, but to try to solve problems and simply not\ndiscount weird hunches you have in the process.<br/><br/>The winds of change originate in the unconscious minds of domain\nexperts.  If you're sufficiently expert in a field, any weird idea\nor apparently irrelevant question that occurs to you is ipso facto\nworth exploring. \n<font color=\"#999999\">[<a href=\"#f3n\"><font color=\"#999999\">3</font></a>]</font>\n Within Y Combinator, when an idea is described\nas crazy, it's a compliment—in fact, on average probably a\nhigher compliment than when an idea is described as good.<br/><br/>Startup investors have extraordinary incentives for correcting\nobsolete beliefs.  If they can realize before other investors that\nsome apparently unpromising startup isn't, they can make a huge\namount of money.  But the incentives are more than just financial.\nInvestors' opinions are explicitly tested: startups come to them\nand they have to say yes or no, and then, fairly quickly, they learn\nwhether they guessed right.  The investors who say no to a Google\n(and there were several) will remember it for the rest of their\nlives.<br/><br/>Anyone who must in some sense bet on ideas rather than merely\ncommenting on them has similar incentives.  Which means anyone who\nwants such incentives can have them, by turning their comments into\nbets: if you write about a topic in some fairly durable and public\nform, you'll find you worry much more about getting things right\nthan most people would in a casual conversation.\n<font color=\"#999999\">[<a href=\"#f4n\"><font color=\"#999999\">4</font></a>]</font><br/><br/>Another trick I've found to protect myself against obsolete beliefs\nis to focus initially on people rather than ideas. Though the nature\nof future discoveries is hard to predict, I've found I can predict\nquite well what sort of people will make them.  Good new ideas come\nfrom earnest, energetic, independent-minded people.<br/><br/>Betting on people over ideas saved me countless times as an investor.\nWe thought Airbnb was a bad idea, for example. But we could tell\nthe founders were earnest, energetic, and independent-minded.\n(Indeed, almost pathologically so.)  So we suspended disbelief and\nfunded them.<br/><br/>This too seems a technique that should be generally applicable.\nSurround yourself with the sort of people new ideas come from.  If\nyou want to notice quickly when your beliefs become obsolete, you\ncan't do better than to be friends with the people whose discoveries\nwill make them so.<br/><br/>It's hard enough already not to become the prisoner of your own\nexpertise, but it will only get harder, because change is accelerating.\nThat's not a recent trend; change has been accelerating since the\npaleolithic era.  Ideas beget ideas.  I don't expect that to change.\nBut I could be wrong.<br/><br/><br/><br/><br/><br/>\n<b>Notes</b><br/><br/>[<a name=\"f1n\"><font color=\"#000000\">1</font></a>]\nMy usual trick is to talk about aspects of the present that\nmost people haven't noticed yet.<br/><br/>[<a name=\"f2n\"><font color=\"#000000\">2</font></a>]\nEspecially if they become well enough known that people start\nto identify them with you.  You have to be extra skeptical about\nthings you want to believe, and once a hypothesis starts to be\nidentified with you, it will almost certainly start to be in that\ncategory.<br/><br/>[<a name=\"f3n\"><font color=\"#000000\">3</font></a>]\nIn practice \"sufficiently expert\" doesn't require one to be\nrecognized as an expert—which is a trailing indicator in any\ncase.  In many fields a year of focused work plus caring a lot would\nbe enough.<br/><br/>[<a name=\"f4n\"><font color=\"#000000\">4</font></a>]\nThough they are public and persist indefinitely, comments on\ne.g. forums and places like Twitter seem empirically to work like\ncasual conversation.  The threshold may be whether what you write\nhas a title.<br/><br/>\n<b>Thanks</b> to Sam Altman, Patrick Collison, and Robert Morris\nfor reading drafts of this.<br/><br/></font>","date":"2014-12-01T00:00:00Z"}