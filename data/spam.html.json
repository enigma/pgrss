{"href":"spam.html","title":"A Plan for Spam","content":"<font face=\"verdana\" size=\"2\"><table cellspacing=\"0\" width=\"100%\">\n<tr><td bgcolor=\"#ff9922\"><img height=\"15\" src=\"http://www.virtumundo.com/images/spacer.gif\" width=\"1\"/><font size=\"2\">\n<b>Like to build things?</b> Try <a href=\"http://news.ycombinator.com\">Hacker\nNews</a>.\n</font>\n<br/><img height=\"5\" src=\"http://www.virtumundo.com/images/spacer.gif\" width=\"1\"/></td></tr>\n</table>\n<p>\nAugust 2002<br><br/><i>(This article describes the spam-filtering techniques\nused in the spamproof web-based mail reader we\nbuilt to exercise <a href=\"arc.html\">Arc</a>. An\nimproved algorithm is described in <a href=\"better.html\">Better\nBayesian Filtering</a>.)</i><br/><br/>I think it's possible to stop spam, and that \ncontent-based filters are the way to do it.\nThe Achilles heel of the spammers is their message.\nThey can circumvent any other barrier you set up.  They have so far, at\nleast.  But they have to deliver their message, whatever it\nis.  If we can write software that recognizes their messages,\nthere is no way they can get around that.<br/><br/><center>_ _ _</center><br/><br/>To the recipient, spam is easily recognizable.  If you hired \nsomeone to read your mail and discard the spam, they would\nhave little trouble doing it.  How much do we have\nto do, short of AI, to automate this process?<br/><br/>I think we will be able to solve the problem with fairly\nsimple algorithms.  In fact, I've found that you can filter\npresent-day spam acceptably well using nothing more than a\nBayesian combination of the spam probabilities of individual\nwords.  Using a slightly tweaked (as described below) Bayesian\nfilter, we now miss less than 5 per 1000 spams, with 0 false positives.<br/><br/>The statistical approach is not usually the first one people\ntry when they write spam filters.  Most hackers' first instinct is\nto try to write software that recognizes individual properties of\nspam.  You look at spams\nand you think, the gall of these guys to try sending me mail \nthat begins \"Dear Friend\" or has a subject line that's all\nuppercase and ends in eight exclamation points.  I can filter\nout that stuff with about one line of code.<br/><br/>And so you do,\nand in the beginning it works.  A few simple rules will take\na big bite out of your incoming spam.  Merely looking\nfor the word \"click\" will catch 79.7% of the\nemails in my spam corpus, with only 1.2% false positives.<br/><br/>I spent about six months writing software that looked for\nindividual spam features before I tried the statistical\napproach.  What I found was that recognizing that last few\npercent of spams got very hard, and that as I\nmade the filters stricter I got more false positives.<br/><br/>False positives are innocent emails that get mistakenly\nidentified as spams.\nFor most users,\nmissing legitimate email is\nan order of magnitude worse than receiving spam, so a\nfilter that yields false positives is like an acne cure\nthat carries a risk of death to the patient.<br/><br/>The more spam a user gets, the less\nlikely he'll be to notice one innocent mail sitting in his\nspam folder.  And strangely enough, the better your spam filters get,\nthe more dangerous false positives become, because when the\nfilters are really good, users will be more likely to\nignore everything they catch.<br/><br/>I don't know why I avoided trying the statistical approach\nfor so long.  I think it was because I got addicted to\ntrying to identify spam features myself, as if I were playing\nsome kind of competitive game with the spammers.  (Nonhackers\ndon't often realize this, but most hackers are very competitive.)\nWhen I did try statistical analysis, I\nfound immediately that it was much cleverer than I had been.\nIt discovered, of course, that terms like \"virtumundo\" and\n\"teens\" were good indicators of spam.  But it also\ndiscovered that \"per\" and \"FL\" and \"ff0000\" are good \nindicators of spam.  In fact, \"ff0000\" (html for bright red)\nturns out to be as good an indicator of spam as any  \npornographic term.<br/><br/><center>_ _ _</center><br/><br/>Here's a sketch of how I do statistical filtering.  I start\nwith one corpus of spam and one of nonspam mail.  At the\nmoment each one has about 4000 messages in it.  I scan\nthe entire text, including headers and embedded html\nand javascript, of each message in each corpus.\nI currently consider alphanumeric characters,\ndashes, apostrophes, and dollar signs to be part of tokens,\nand everything else to be a token separator.  (There is\nprobably room for improvement here.)  I ignore tokens that\nare all digits, and I also ignore html comments, not even\nconsidering them as token separators.<br/><br/>I count the number\nof times each token (ignoring case, currently) occurs in\neach corpus.  At this stage I end up with two large hash   \ntables, one for each corpus, mapping tokens to number\nof occurrences.<br/><br/>Next I create a third hash table, this time mapping\neach token to the probability that an email containing it is a spam,\nwhich I calculate as follows [1]:\n<font face=\"courier\" size=\"2\"><xmp>\n(let ((g (* 2 (or (gethash word good) 0)))\n      (b (or (gethash word bad) 0)))\n   (unless (&lt; (+ g b) 5)\n     (max .01\n          (min .99 (float (/ (min 1 (/ b nbad))\n                             (+ (min 1 (/ g ngood))   \n                                (min 1 (/ b nbad)))))))))\n</xmp></font>\nwhere <font face=\"courier\">word</font> is the token whose probability we're\ncalculating, <font face=\"courier\">good</font> and <font face=\"courier\">bad</font> are the hash tables\nI created in the first step, and <font face=\"courier\">ngood</font> and <font face=\"courier\">nbad</font>\nare the number of nonspam and spam messages respectively.<br/><br/>I explained this as code to show a couple of important details.\nI want to bias the probabilities slightly to avoid false\npositives, and by trial and error I've found that a good\nway to do it is to double all the numbers in <font face=\"courier\">good</font>.\nThis helps to distinguish between words that occasionally\ndo occur in legitimate email and words that almost never do. \nI only consider words that occur more than five times in\ntotal (actually, because of the doubling, occurring three \ntimes in nonspam mail would be enough).  And then there is\nthe question of what probability to assign to words that\noccur in one corpus but not the other.  Again by trial and   \nerror I chose .01 and .99.  There may be room for tuning\nhere, but as the corpus grows such tuning will happen\nautomatically anyway.<br/><br/>The especially observant will notice that while I consider\neach corpus to be a single long stream of text for purposes\nof counting occurrences, I use the number of emails in\neach, rather than their combined length, as the divisor     \nin calculating spam probabilities.  This adds another\nslight bias to protect against false positives.<br/><br/>When new mail arrives, it is scanned into tokens, and\nthe most interesting fifteen tokens, where interesting is  \nmeasured by how far their spam probability is from a\nneutral .5, are used to calculate the probability that\nthe mail is spam.  If <font face=\"courier\">probs</font>\nis a list of the fifteen individual probabilities, you\ncalculate the \n<a href=\"naivebayes.html\">combined</a> probability thus:\n<font face=\"courier\" size=\"2\"><xmp>\n(let ((prod (apply #'* probs)))\n  (/ prod (+ prod (apply #'* (mapcar #'(lambda (x) \n                                         (- 1 x))\n                                     probs)))))\n</xmp></font>\nOne question that arises in\npractice is what probability to assign to a word you've\nnever seen, i.e. one that doesn't occur in the hash table\nof word probabilities.  I've found, again by trial and\nerror, that .4 is a good number to use.  If you've never\nseen a word before, it is probably fairly innocent; spam\nwords tend to be all too familiar.<br/><br/>There are examples of this algorithm being applied to\nactual emails in an appendix at the end.<br/><br/>I treat mail as spam if the algorithm above gives it a\nprobability of more than .9 of being spam.  But in practice\nit would not matter much where I put this threshold, because\nfew probabilities end up in the middle of the range.<br/><br/><center>_ _ _</center><br/><br/>One great advantage of the statistical approach is that you\ndon't have to read so many spams.  Over the past six months,\nI've read literally thousands of spams, and it is really\nkind of demoralizing.  Norbert Wiener said if you compete\nwith slaves you become a slave, and there is something\nsimilarly degrading about competing with spammers.   To\nrecognize individual spam features you have to try to get\ninto the mind of the spammer, and frankly I want to spend\nas little time inside the minds of spammers as possible.<br/><br/>But the real advantage of the Bayesian approach, of course,\nis that you know what\nyou're measuring.  Feature-recognizing filters like\nSpamAssassin assign a spam \"score\" to email.  The Bayesian\napproach assigns an actual probability.  The problem with\na \"score\" is that no one knows what it means.  The user\ndoesn't know what it means, but worse still, neither does\nthe developer of the filter.  How many <i>points</i> should an\nemail get for having the word \"sex\" in it?  A probability\ncan of course be mistaken, but there is little ambiguity\nabout what it means, or how evidence should be combined\nto calculate it.  Based on my corpus, \"sex\" indicates\na .97 probability of the containing email being a spam,\nwhereas \"sexy\" indicates .99 probability.\nAnd Bayes' Rule, equally unambiguous, says that an email\ncontaining both words would, in the (unlikely)\nabsence of any other evidence, have a 99.97% chance of\nbeing a spam.<br/><br/>Because it is measuring probabilities, the Bayesian approach\nconsiders all the evidence in the email, both good and bad.\nWords that occur disproportionately <i>rarely</i>\nin spam (like \"though\" or \"tonight\" or \"apparently\")\ncontribute as much to decreasing the probability as\nbad words like \"unsubscribe\" and \"opt-in\" do to\nincreasing it.  So an otherwise innocent email that happens\nto include the word \"sex\" is not going to get tagged as spam.<br/><br/>Ideally, of course, the probabilities should be calculated\nindividually for each user.  I get a lot of email containing\nthe word \"Lisp\", and (so far) no spam that does.  So a word\nlike that is effectively a kind of password for sending\nmail to me.  In my earlier spam-filtering software, the user\ncould set up a list of such words and mail containing\nthem would automatically get past the filters.  On my\nlist I put words like \"Lisp\" and also my zipcode, so\nthat (otherwise rather spammy-sounding) receipts from\nonline orders would get through.  I thought I was being\nvery clever, but I found that the Bayesian filter did the\nsame thing for me, and moreover discovered of a lot of words I\nhadn't thought of.<br/><br/>When I said at the start that our filters let through less than\n5 spams per 1000 with 0 false positives, I'm talking about\nfiltering my mail based on a corpus of my mail.  But these\nnumbers are not misleading, because that is the approach I'm\nadvocating: filter each user's mail based on the spam and\nnonspam mail he receives.  Essentially, each user should\nhave two delete buttons, ordinary delete and delete-as-spam.\nAnything deleted as spam goes into the spam corpus,   \nand everything else goes into the nonspam corpus.<br/><br/>You could start\nusers with a seed filter, but ultimately each user should have\nhis own per-word probabilities based on the actual mail he\nreceives.  This (a) makes the filters more effective, (b) lets\neach user decide their own precise definition of spam,\nand (c) perhaps best of all makes it hard for spammers\nto tune mails to get through the filters.  If a lot of the  \nbrain of the filter is in the individual databases, then \nmerely tuning spams to get through the seed filters\nwon't guarantee anything about how well they'll get through\nindividual users' varying and much more trained filters.<br/><br/>Content-based spam filtering is often combined with a whitelist,\na list of senders whose mail can be accepted with no filtering.\nOne easy way to build such a\nwhitelist is to keep a list of every address the user has\never sent mail to.  If a mail reader has a delete-as-spam\nbutton then you could also add the from address\nof every email the user has deleted as ordinary trash.<br/><br/>I'm an advocate of whitelists, but more as a way to save  \ncomputation than as a way to improve filtering.  I used to think that\nwhitelists would make filtering easier, because you'd\nonly have to filter email from people you'd never heard\nfrom, and someone sending you mail for the first time is\nconstrained by convention in what they can say to you.\nSomeone you already know might send you an email talking about sex,\nbut someone sending you mail for the first time would not   \nbe likely to.  The problem is, people can have more than one \nemail address, so a new from-address doesn't guarantee that\nthe sender is writing to you for the first time.\nIt is not unusual\nfor an old friend (especially if he is a hacker) to suddenly\nsend you an email with a new from-address, so you can't\nrisk false positives by filtering mail from unknown  \naddresses especially stringently.<br/><br/>In a sense, though, my filters do themselves embody a kind\nof whitelist (and blacklist) because they are based on\nentire messages, including the headers.  So to that\nextent they \"know\" the email addresses of trusted senders\nand even the routes by which mail gets from them to me.   \nAnd they know the same about spam, including the server   \nnames, mailer versions, and protocols.<br/><br/><center>_ _ _</center><br/><br/>If I thought that I could keep up current rates of spam\nfiltering, I would consider this problem solved.  But it\ndoesn't mean much to be able to filter out most present-day\nspam, because spam evolves.\nIndeed, most \n<a href=\"falsepositives.html\">antispam techniques</a> so far have been like pesticides that\ndo nothing more than create a new, resistant strain of bugs.<br/><br/>I'm more hopeful about Bayesian filters, because they evolve\nwith the spam.  So as spammers start using \"c0ck\"   \ninstead of \"cock\" to evade simple-minded spam filters     \nbased on individual words, Bayesian filters automatically\nnotice.  Indeed, \"c0ck\" is far more damning evidence than\n\"cock\", and Bayesian filters know precisely how much more.<br/><br/>Still, anyone who proposes a plan for spam filtering has to\nbe able to answer the question: if the spammers knew\nexactly what you were doing,\nhow well could they get past you?  For example, I think that if\nchecksum-based spam filtering becomes a serious obstacle,\nthe spammers will just\nswitch to mad-lib techniques for generating message bodies.<br/><br/>To beat Bayesian filters, it would not be enough for spammers\nto make their emails unique or to stop using individual\nnaughty words.  They'd have to make their mails indistinguishable\nfrom your ordinary mail.  And this I think would severely\nconstrain them.  Spam is mostly sales\npitches, so unless your regular mail is all sales pitches,\nspams will inevitably have a different character.  And    \nthe spammers would also, of course, have to change (and keep \nchanging) their whole infrastructure, because otherwise\nthe headers would look as bad to the Bayesian filters as ever,\nno matter what they did to the message body.  I don't know\nenough about the infrastructure that spammers use to know\nhow hard it would be to make the headers look innocent, but\nmy guess is that it would be even harder than making the    \nmessage look innocent.<br/><br/>Assuming they could solve the problem of the headers,\nthe spam of the future will probably look something like\nthis:\n<font face=\"courier\"><xmp>\nHey there.  Thought you should check out the following:\nhttp://www.27meg.com/foo\n</xmp></font>\nbecause that is about as much sales pitch as content-based\nfiltering will leave the spammer room to make.  (Indeed, it\nwill be hard even to get this past filters, because if everything\nelse in the email is neutral, the spam probability will hinge on\nthe url, and it will take some effort to make that look neutral.)<br/><br/>Spammers range from businesses running so-called\nopt-in lists who don't even try to conceal their identities,\nto guys who hijack mail servers to send out spams promoting\nporn sites.  If we use filtering to whittle their\noptions down to mails like the one above, that should\npretty much put the spammers on the \"legitimate\" end of\nthe spectrum out of business; they feel obliged\nby various state laws to include boilerplate about why\ntheir spam is not spam, and how to cancel your\n\"subscription,\"  and that kind of text is easy to   \nrecognize.<br/><br/>(I used to think it was naive to believe that stricter laws\nwould decrease spam.  Now I think that while stricter laws  \nmay not decrease the amount of spam that spammers <i>send,</i>\nthey can certainly help filters to decrease the amount of  \nspam that recipients actually see.)<br/><br/>All along the spectrum, if you restrict the sales pitches spammers\ncan make, you will inevitably tend to put them out of\nbusiness.  That word <i>business</i> is an important one to\nremember.  The spammers are businessmen.  They send spam because\nit works.  It works because although the response rate\nis abominably low (at best 15 per million, vs 3000 per\nmillion for a catalog mailing), the cost, to them, is  \npractically nothing.  The cost is enormous for the recipients,   \nabout 5 man-weeks for each million recipients who spend  \na second to delete the spam, but the spammer\ndoesn't have to pay that.<br/><br/>Sending spam does cost the spammer something, though. [2]\nSo the lower we can get the\nresponse rate-- whether by filtering, or by using filters to force\nspammers to dilute their pitches-- the fewer businesses will find it\nworth their while to send spam.<br/><br/>The reason the spammers use the kinds of \n<a href=\"http://www.milliondollaremails.com\">sales\npitches</a> that they do is to increase response rates.\nThis is possibly even more disgusting\nthan getting inside the mind of a spammer,\nbut let's take a quick look inside the mind of someone\nwho <i>responds</i> to a spam.  This person is either\nastonishingly credulous or deeply in denial about their   \nsexual interests.  In either case, repulsive or\nidiotic as the spam seems to us, it is exciting\nto them.  The spammers wouldn't say these things if they\ndidn't sound exciting.  And \"thought you\nshould check out the following\" is just not going to\nhave nearly the pull with the spam recipient as\nthe kinds of things that spammers say now.\nResult: if it can't contain exciting sales pitches,\nspam becomes less effective as a marketing vehicle,\nand fewer businesses want to use it.<br/><br/>That is the big win in the end.  I started writing spam\nfiltering software because I didn't want have to look at\nthe stuff anymore.\nBut if we get good enough at filtering\nout spam, it will stop working, and the spammers\nwill actually stop sending it.<br/><br/><center>_ _ _</center><br/><br/>Of all the approaches to fighting spam, from software to laws,\nI believe Bayesian filtering will be the single most\neffective.  But I also\nthink that the more different kinds of antispam efforts\nwe undertake, the better, because any measure that\nconstrains spammers will tend to make filtering easier.\nAnd even within the world of content-based filtering, I think\nit will be a good thing if there are many different kinds\nof software being used simultaneously.  The more different \nfilters there are, the harder it will be for\nspammers to tune spams to get through them.<br/><br/><br/><br/>\n<b>Appendix: Examples of Filtering</b><br/><br/><a href=\"https://sep.turbifycdn.com/ty/cdn/paulgraham/spam1.txt?t=1688221954&amp;\" target=\"txtwin\">Here</a> is an example of a spam that arrived while I was writing\nthis article.  The fifteen most interesting words in this spam are:\n<font face=\"courier\"><xmp>\nqvp0045\nindira\nmx-05\nintimail\n$7500\nfreeyankeedom\ncdo\nbluefoxmedia\njpg\nunsecured\nplatinum\n3d0\nqves\n7c5\n7c266675\n</xmp></font>\nThe words are a mix of stuff from the headers and from the\nmessage body, which is typical of spam.  Also typical of spam\nis that every one of these words has a spam probability,\nin my database, of .99.  In fact there are more than fifteen words\nwith probabilities of .99, and these are just the first\nfifteen seen.<br/><br/>Unfortunately that makes this email a boring example of\nthe use of Bayes' Rule.  To see an interesting variety of\nprobabilities we have to look at <a href=\"https://sep.turbifycdn.com/ty/cdn/paulgraham/spam2.txt?t=1688221954&amp;\" target=\"txtwin\">this</a> actually quite\natypical spam.<br/><br/>The fifteen most interesting words in this spam, with their probabilities,\nare:\n<font face=\"courier\"><xmp>\nmadam           0.99\npromotion       0.99\nrepublic        0.99\nshortest        0.047225013\nmandatory       0.047225013\nstandardization 0.07347802\nsorry           0.08221981\nsupported       0.09019077\npeople's        0.09019077\nenter           0.9075001\nquality         0.8921298\norganization    0.12454646\ninvestment      0.8568143\nvery            0.14758544\nvaluable        0.82347786 \n</xmp></font>\nThis time the evidence is a mix of good and bad.  A word like  \n\"shortest\" is almost as much evidence for innocence as a\nword like \"madam\" or \"promotion\" is for guilt.  But still the\ncase for guilt is stronger.  If you combine these numbers\naccording to Bayes' Rule, the resulting probability is .9027.<br/><br/>\"Madam\" is obviously from spams beginning\n\"Dear Sir or Madam.\"  They're not very common, but the\nword \"madam\" <i>never</i> occurs in my legitimate email, and\nit's all about the ratio.<br/><br/>\"Republic\" scores high because\nit often shows up in Nigerian scam emails, and also occurs once\nor twice in spams referring to Korea and South Africa.\nYou might say that it's\nan accident that it thus helps identify this spam.  But I've\nfound when examining spam probabilities that there are\na lot of these accidents, and they have an uncanny tendency to\npush things in the right direction rather than the wrong one.\nIn this case, it is not entirely a coincidence that the word\n\"Republic\" occurs in Nigerian scam emails and this spam.\nThere is a whole class of dubious business propositions involving\nless developed countries, and these in turn are more likely\nto have names that specify explicitly (because they aren't) that they\nare republics.[3]<br/><br/>On the other hand, \"enter\" is a genuine miss.  It occurs\nmostly in unsubscribe instructions, but here is used in a\ncompletely innocent way.  Fortunately the statistical approach is\nfairly robust, and can tolerate quite a lot of misses\nbefore the results start to be thrown off.<br/><br/>For comparison, \n<a href=\"https://sep.turbifycdn.com/ty/cdn/paulgraham/hostexspam.txt?t=1688221954&amp;\" target=\"txtwin\">here</a> is an example of that rare bird, a spam that\ngets through the filters.  Why?  Because by sheer chance it happens\nto be loaded with words that occur in my actual email:\n<font face=\"courier\"><xmp>\nperl       0.01\npython     0.01\ntcl        0.01\nscripting  0.01\nmorris     0.01\ngraham     0.01491078\nguarantee  0.9762507\ncgi        0.9734398\npaul       0.027040077\nquite      0.030676773\npop3       0.042199217\nvarious    0.06080265\nprices     0.9359873\nmanaged    0.06451222\ndifficult  0.071706355\n</xmp></font>\nThere are a couple pieces of good news here.  First, this mail\nprobably wouldn't get through the filters of someone who didn't\nhappen to specialize in programming languages and have a good\nfriend called Morris.  For the average user, all the top five words here \nwould be neutral and would not contribute to the spam probability.<br/><br/>Second, I think filtering based on word pairs \n(see below) might well\ncatch this one:  \"cost effective\", \"setup fee\", \"money back\" -- pretty\nincriminating stuff.  And of course if they continued to spam me\n(or a network I was part of), \"Hostex\" itself would be\nrecognized as  a spam term.<br/><br/>Finally, <a href=\"https://sep.turbifycdn.com/ty/cdn/paulgraham/legit.txt?t=1688221954&amp;\" target=\"txtwin\">here</a> is an innocent email.\nIts  fifteen most interesting words are as follows:\n<font face=\"courier\"><xmp>\ncontinuation  0.01\ndescribe      0.01\ncontinuations 0.01\nexample       0.033600237\nprogramming   0.05214485 \ni'm           0.055427782\nexamples      0.07972858 \ncolor         0.9189189  \nlocalhost     0.09883721\nhi            0.116539136\ncalifornia    0.84421706\nsame          0.15981844\nspot          0.1654587\nus-ascii      0.16804294\nwhat          0.19212411\n</xmp></font>\nMost of the words here indicate the mail is an innocent one.\nThere are two bad smelling words,  \"color\"\n(spammers love colored fonts) and \"California\"\n(which occurs in testimonials and also in menus in\nforms), but they are not enough to outweigh obviously\ninnocent words like \"continuation\" and \"example\".<br/><br/>It's interesting that \"describe\" rates as so thoroughly\ninnocent.  It hasn't occurred in a\nsingle one of my 4000 spams.  The data turns out to be\nfull of such surprises.  One of the things you learn\nwhen you analyze spam texts is how\nnarrow a subset of the language spammers operate in.  It's\nthat fact, together with the equally characteristic vocabulary\nof any individual user's mail, that makes Bayesian filtering\na good bet.<br/><br/><b>Appendix: More Ideas</b><br/><br/>One idea that I haven't tried yet is to filter based on\nword pairs, or even triples, rather than individual words.\nThis should yield a much sharper estimate of the probability.\nFor example, in my current database, the word \"offers\"\nhas a probability of .96.  If you based the probabilities  \non word pairs, you'd end up with \"special offers\"\nand \"valuable offers\" having probabilities of .99\nand, say, \"approach offers\" (as in \"this approach offers\")\nhaving a probability of .1 or less.<br/><br/>The reason I haven't done this is that filtering based on\nindividual words already works so well.  But it does\nmean that there is room to tighten the filters if spam\ngets harder to detect.\n(Curiously, a filter based on word pairs would be\nin effect a Markov-chaining text generator running\nin reverse.)<br/><br/>Specific spam features (e.g. not seeing the recipient's\naddress in the to: field) do of course have value in \nrecognizing spam.  They can be considered in this\nalgorithm by treating them as virtual words.  I'll probably\ndo this in future versions, at least for a handful of the\nmost egregious spam indicators. Feature-recognizing\nspam filters are right in many details; what they lack\nis an overall discipline for combining evidence.<br/><br/>Recognizing nonspam features may be more important than\nrecognizing spam features.  False positives are such a\nworry that they demand extraordinary measures.  I will\nprobably in future versions add a second level of testing\ndesigned specifically to avoid false positives.  If a\nmail triggers this second level of filters it will be accepted\neven if its spam probability is above the threshold.<br/><br/>I don't expect this second level of filtering to be Bayesian.\nIt will inevitably \nbe not only ad hoc, but based on guesses, because the number of\nfalse positives will not tend to be large enough to notice patterns.\n(It is just as well, anyway, if a backup system doesn't rely on the same\ntechnology as the primary system.)<br/><br/>Another thing I may try in the future is to focus extra attention\non specific parts of the email.  For example, about 95% of current\nspam includes the url of a site they want\nyou to visit.  (The remaining 5% want you to call a phone number,\nreply by email or to a US mail address, or in a few\ncases to buy a certain stock.)   The url is in such cases\npractically enough by itself to determine whether the email\nis spam.<br/><br/>Domain names differ from the rest of the text in\na (non-German) email in that they often consist of several\nwords stuck together.  Though computationally expensive \nin the general case, it might be worth trying to \ndecompose them.  If a filter has never seen the\ntoken \"xxxporn\" before it will have an individual spam\nprobability of .4, whereas \"xxx\" and \"porn\" individually\nhave probabilities (in my corpus) of .9889 and .99\nrespectively, and a combined probability of .9998.<br/><br/>I expect decomposing domain names to become more\nimportant as spammers are gradually forced to stop using\nincriminating words in the text of their messages.  (A url\nwith an ip address is of course an extremely incriminating sign,\nexcept in the mail of a few sysadmins.)<br/><br/>It might be a good idea to have a cooperatively maintained\nlist of urls promoted by spammers.  We'd need a trust metric\nof the type studied by Raph Levien to prevent malicious\nor incompetent submissions, but if we had such a thing it\nwould provide a boost to any filtering software.   It would\nalso be a convenient basis for boycotts.<br/><br/>Another way to test dubious urls would be to send out a\ncrawler to look at the site before the user looked at the\nemail mentioning it.  You could use a Bayesian filter to\nrate the site just as you would an email, and whatever\nwas found on the site could be included in calculating\nthe probability of the email being a spam.  A url that led\nto a redirect would of course be especially suspicious.<br/><br/>One cooperative project that I think really would be a good\nidea would be to accumulate a giant corpus of spam.  A large,\nclean corpus is the key to making Bayesian filtering work\nwell.  Bayesian filters could actually use the corpus as\ninput.  But such a corpus would be useful for other kinds\nof filters too, because it could be used to test them.<br/><br/>Creating such a corpus poses some technical problems.  We'd\nneed trust metrics to prevent malicious or incompetent\nsubmissions, of course.  We'd also need ways of erasing   \npersonal information (not just to-addresses and ccs, but\nalso e.g. the arguments to unsubscribe urls, which often\nencode the to-address) from mails in the corpus.  If anyone\nwants to take on this project, it would be a good thing for\nthe world.<br/><br/><b>Appendix: Defining Spam</b><br/><br/>I think there is a rough\nconsensus on what spam is, but it would be useful to have\nan explicit definition.  We'll need to do this if we want to establish\na central corpus of spam, or even to compare spam filtering\nrates meaningfully.<br/><br/>To start with, spam is not unsolicited commercial email.\nIf someone in my neighborhood heard that I was looking for an old\nRaleigh three-speed in good condition, and sent me an email\noffering to sell me one, I'd be delighted, and yet this\nemail would be both commercial and unsolicited.  The\ndefining feature of spam (in fact, its <i>raison d'etre</i>)\nis not that it is unsolicited, but that it is automated.<br/><br/>It is merely incidental, too, that spam is usually commercial.\nIf someone started sending mass email to support some political\ncause, for example, it would be just as much spam as email\npromoting a porn site.<br/><br/>I propose we define spam as <b>unsolicited automated email</b>.\nThis definition thus includes some email\nthat many legal definitions of spam don't.  Legal definitions\nof spam, influenced presumably by lobbyists, tend to exclude\nmail sent by companies that have an \"existing relationship\" with\nthe recipient.  But buying something from a company, for\nexample, does not imply that you have solicited\nongoing email from them.\nIf I order something from an online\nstore, and they then send me a stream of spam, it's still\nspam.<br/><br/>Companies sending spam often give you a way to \"unsubscribe,\"\nor ask you to go to their site and change your \"account\npreferences\" if you want to stop getting spam.  This is\nnot enough to stop the mail from being spam.  Not opting out\nis not the same as opting in.  Unless the   \nrecipient explicitly checked a clearly labelled box (whose\ndefault was no) asking to receive the email, then it is spam.<br/><br/>In some business relationships, you do implicitly solicit\ncertain kinds of mail.   When you order online, I think you\nimplicitly solicit a receipt, and notification when the\norder ships.\nI don't mind when Verisign sends me mail warning that\na domain name is about to expire (at least, if they are the\n<a href=\"http://siliconvalley.internet.com/news/article.php/1441651\">actual \nregistrar</a> for it).  But when Verisign sends me\nemail offering a FREE Guide to Building My\nE-Commerce Web Site, that's spam.<br/><br/>\n<b>Notes:</b><br/><br/>[1] The examples in this article are translated\ninto Common Lisp for, believe it or not, greater accessibility.\nThe application described here is one that we wrote in order to\ntest a new Lisp dialect called <a href=\"arc.html\">Arc</a> that is \nnot yet released.<br/><br/>[2] Currently the lowest rate seems to be about $200 to send a million spams.\nThat's very cheap, 1/50th of a cent per spam.\nBut filtering out 95%\nof spam, for example, would increase the spammers' cost to reach\na given audience by a factor of 20.  Few can have\nmargins big enough to absorb that.<br/><br/>[3] As a rule of thumb, the more qualifiers there are before the\nname of a country, the more corrupt the rulers.  A\ncountry called The Socialist People's Democratic Republic\nof X is probably the last place in the world you'd want to live.<br/><br/>\n<b>Thanks</b> to Sarah Harlin for reading drafts of this; Daniel Giffin (who is \nalso writing the production Arc interpreter) for several good ideas about\nfiltering and for creating our mail infrastructure; Robert Morris,\nTrevor Blackwell and Erann Gat for many discussions about spam; Raph \nLevien for advice about trust metrics;  and Chip Coldwell \nand Sam Steingold for advice about statistics.<br/><br/><table cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n<tr><td bgcolor=\"#ffe799\"><img height=\"15\" src=\"http://www.virtumundo.com/images/spacer.gif\" width=\"1\"/><font size=\"2\">\nYou'll find this essay and 14 others in\n<a href=\"http://www.amazon.com/gp/product/0596006624\"><b><i>Hackers &amp; Painters</i></b></a>.</font>\n<br/><img height=\"5\" src=\"http://www.virtumundo.com/images/spacer.gif\" width=\"1\"/></td><tr>\n</tr></tr></table><br><br/>\n<b>More Info:</b><br/><br/></br></br></p></font>","date":"2002-08-01T00:00:00Z"}