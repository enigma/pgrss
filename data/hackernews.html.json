{"href":"hackernews.html","title":"What I've Learned from Hacker News","content":"<font face=\"verdana\" size=\"2\">February 2009<br/><br/>Hacker News was two years\nold last week.  Initially it was supposed to be a side project—an\napplication to sharpen Arc on, and a place for current and future\nY Combinator founders to exchange news.  It's grown bigger and taken\nup more time than I expected, but I don't regret that because I've\nlearned so much from working on it.<br/><br/><b>Growth</b><br/><br/>When we launched in February 2007, weekday traffic was around 1600\ndaily uniques.  It's since <a href=\"http://ycombinator.com/images/2yeartraffic.png\">grown</a> to around 22,000.  This growth\nrate is a bit higher than I'd like.  I'd like the site to grow,\nsince a site that isn't growing at least slowly is probably dead.\nBut I wouldn't want it to grow as large as Digg or Reddit—mainly\nbecause that would dilute the character of the site, but also because\nI don't want to spend all my time dealing with scaling.<br/><br/>I already have problems enough with that.  Remember, the original\nmotivation for HN was to test a new programming language, and\nmoreover one that's focused on experimenting with language design,\nnot performance.  Every time the site gets slow, I fortify myself\nby recalling McIlroy and Bentley's famous quote\n<blockquote>\n  The key to performance is elegance, not battalions of special\n  cases.\n</blockquote>\nand look for the bottleneck I can remove with least code.  So far\nI've been able to keep up, in the sense that performance has remained\nconsistently mediocre despite 14x growth. I don't know what I'll\ndo next, but I'll probably think of something.<br/><br/>This is my attitude to the site generally.  Hacker News is an\nexperiment, and an experiment in a very young field.  Sites of this\ntype are only a few years old.  Internet conversation generally is\nonly a few decades old.  So we've probably only discovered a fraction\nof what we eventually will.<br/><br/>That's why I'm so optimistic about HN.  When a technology is this\nyoung, the existing solutions are usually terrible; which means it\nmust be possible to do much better; which means many problems that\nseem insoluble aren't. Including, I hope, the problem that has\nafflicted so many previous communities: being ruined by growth.<br/><br/><b>Dilution</b><br/><br/>Users have worried about that since the site was a few months old.\nSo far these alarms have been false, but they may not always be.\nDilution is a hard problem. But probably soluble; it doesn't mean\nmuch that open conversations have \"always\" been destroyed by growth\nwhen \"always\" equals 20 instances.<br/><br/>But it's important to remember we're trying to solve a new problem,\nbecause that means we're going to have to try new things, most of\nwhich probably won't work.  A couple weeks ago I tried displaying\nthe names of users with the highest average comment scores in orange.\n<font color=\"#999999\">[<a href=\"https://paulgraham.com/hackernews.html#f1n\"><font color=\"#999999\">1</font></a>]</font>\nThat was a mistake.  Suddenly a culture that had been more\nor less united was divided into haves and have-nots.  I didn't\nrealize how united the culture had been till I saw it divided.  It\nwas painful to watch.\n<font color=\"#999999\">[<a href=\"https://paulgraham.com/hackernews.html#f2n\"><font color=\"#999999\">2</font></a>]</font><br/><br/>So orange usernames won't be back.  (Sorry about that.)  But there\nwill be other equally broken-seeming ideas in the future, and the\nones that turn out to work will probably seem just as broken as\nthose that don't.<br/><br/>Probably the most important thing I've learned about dilution is\nthat it's measured more in behavior than users. It's bad behavior\nyou want to keep out more than bad people. User behavior turns out\nto be surprisingly malleable.  If people are \n<a href=\"http://ycombinator.com/newswelcome.html\">expected</a> to behave\nwell, they tend to; and vice versa.<br/><br/>Though of course forbidding bad behavior does tend to keep away bad\npeople, because they feel uncomfortably constrained in a place where\nthey have to behave well.  But this way of keeping them out is\ngentler and probably also more effective than overt barriers.<br/><br/>It's pretty clear now that the broken windows theory applies to\ncommunity sites as well.  The theory is that minor forms of bad\nbehavior encourage worse ones: that a neighborhood with lots of\ngraffiti and broken windows becomes one where robberies occur.  I\nwas living in New York when Giuliani introduced the reforms that\nmade the broken windows theory famous, and the transformation was\nmiraculous. And I was a Reddit user when the opposite happened\nthere, and the transformation was equally dramatic.<br/><br/>I'm not criticizing Steve and Alexis.  What happened to Reddit\ndidn't happen out of neglect.  From the start they had a policy of\ncensoring nothing except spam.  Plus Reddit had different goals\nfrom Hacker News.  Reddit was a startup, not a side project; its\ngoal was to grow as fast as possible.  Combine rapid growth and\nzero censorship, and the result is a free for all.  But I don't\nthink they'd do much differently if they were doing it again.\nMeasured by traffic, Reddit is much more successful than Hacker\nNews.<br/><br/>But what happened to Reddit won't inevitably happen to HN. There\nare several local maxima.  There can be places that are free for\nalls and places that are more thoughtful, just as there are in the\nreal world; and people will behave differently depending on which\nthey're in, just as they do in the real world.<br/><br/>I've observed this in the wild.  I've seen people cross-posting on\nReddit and Hacker News who actually took the trouble to write two\nversions, a flame for Reddit and a more subdued version for HN.<br/><br/><b>Submissions</b><br/><br/>There are two major types of problems a site like Hacker News needs\nto avoid: bad stories and bad comments.  So far the danger of bad\nstories seems smaller.  The stories on the frontpage now are still\nroughly the ones that would have been there when HN started.<br/><br/>I once thought I'd have to weight votes to keep crap off the\nfrontpage, but I haven't had to yet.  I wouldn't have predicted the\nfrontpage would hold up so well, and I'm not sure why it has.\nPerhaps only the more thoughtful users care enough to submit and\nupvote links, so the marginal cost of one random new user approaches\nzero.  Or perhaps the frontpage protects itself, by advertising what type of submission is expected.<br/><br/>The most dangerous thing for the frontpage is stuff that's too easy\nto upvote.  If someone proves a new theorem, it takes some work by\nthe reader to decide whether or not to upvote it.  An amusing cartoon\ntakes less.  A rant with a rallying cry as the title takes zero,\nbecause people vote it up without even reading it.<br/><br/>Hence what I call the Fluff Principle: on a user-voted news site,\nthe links that are easiest to judge will take over unless you take\nspecific measures to prevent it.<br/><br/>Hacker News has two kinds of protections against fluff.  The most\ncommon types of fluff links are banned as off-topic.  Pictures of\nkittens, political diatribes, and so on are explicitly banned.  This\nkeeps out most fluff, but not all of it.  Some links are both fluff,\nin the sense of being very short, and also on topic.<br/><br/>There's no single solution to that.  If a link is just an empty\nrant, editors will sometimes kill it even if it's on topic in the\nsense of being about hacking, because it's not on topic by the real\nstandard, which is to engage one's intellectual curiosity.  If the\nposts on a site are characteristically of this type I sometimes ban\nit, which means new stuff at that url is auto-killed.  If a post\nhas a linkbait title, editors sometimes rephrase it to be more\nmatter-of-fact.  This is especially necessary with links whose\ntitles are rallying cries, because otherwise they become implicit\n\"vote up if you believe such-and-such\" posts, which are the most\nextreme form of fluff.<br/><br/>The techniques for dealing with links have to evolve, because the\nlinks do. The existence of aggregators has already affected what\nthey aggregate. Writers now deliberately write things to draw traffic\nfrom aggregators—sometimes even specific ones.  (No, the irony\nof this statement is not lost on me.)  Then there are the more\nsinister mutations, like linkjacking—posting a paraphrase of\nsomeone else's article and submitting that instead of the original.\nThese can get a lot of upvotes, because a lot of what's good in an\narticle often survives; indeed, the closer the paraphrase is to\nplagiarism, the more survives.\n<font color=\"#999999\">[<a href=\"https://paulgraham.com/hackernews.html#f3n\"><font color=\"#999999\">3</font></a>]</font><br/><br/>I think it's important that a site that kills submissions provide\na way for users to see what got killed if they want to.  That keeps\neditors honest, and just as importantly, makes users confident\nthey'd know if the editors stopped being honest. HN users can do\nthis by flipping a switch called showdead in their profile.\n<font color=\"#999999\">[<a href=\"https://paulgraham.com/hackernews.html#f4n\"><font color=\"#999999\">4</font></a>]</font><br/><br/><b>Comments</b><br/><br/>Bad comments seem to be a harder problem than bad submissions.\nWhile the quality of links on the frontpage of HN hasn't changed\nmuch, the quality of the median comment may have decreased somewhat.<br/><br/>There are two main kinds of badness in comments: meanness and\nstupidity.  There is a lot of overlap between the two—mean\ncomments are disproportionately likely also to be dumb—but\nthe strategies for dealing with them are different.  Meanness is\neasier to control.  You can have rules saying one shouldn't be mean,\nand if you enforce them it seems possible to keep a lid on meanness.<br/><br/>Keeping a lid on stupidity is harder, perhaps because stupidity is\nnot so easily distinguishable.  Mean people are more likely to know\nthey're being mean than stupid people are to know they're being\nstupid.<br/><br/>The most dangerous form of stupid comment is not the long but\nmistaken argument, but the dumb joke.  Long but mistaken arguments\nare actually quite rare.  There is a strong correlation between\ncomment quality and length; if you wanted to compare the quality\nof comments on community sites, average length would be a good\npredictor.  Probably the cause is human nature rather than anything\nspecific to comment threads. Probably it's simply that stupidity\nmore often takes the form of having few ideas than wrong ones.<br/><br/>Whatever the cause, stupid comments tend to be short.  And since\nit's hard to write a short comment that's distinguished for the\namount of information it conveys, people try to distinguish them\ninstead by being funny.  The most tempting format for stupid comments\nis the supposedly witty put-down, probably because put-downs are\nthe easiest form of humor. \n<font color=\"#999999\">[<a href=\"https://paulgraham.com/hackernews.html#f5n\"><font color=\"#999999\">5</font></a>]</font>\nSo one advantage of forbidding\nmeanness is that it also cuts down on these.<br/><br/>Bad comments are like kudzu: they take over rapidly. Comments have\nmuch more effect on new comments than submissions have on new\nsubmissions.  If someone submits a lame article, the other submissions\ndon't all become lame.  But if someone posts a stupid comment on a\nthread, that sets the tone for the region around it.  People reply\nto dumb jokes with dumb jokes.<br/><br/>Maybe the solution is to add a delay before people can respond to\na comment, and make the length of the delay inversely proportional\nto some prediction of its quality.  Then dumb threads would grow\nslower.\n<font color=\"#999999\">[<a href=\"https://paulgraham.com/hackernews.html#f6n\"><font color=\"#999999\">6</font></a>]</font><br/><br/>\n<b>People</b><br/><br/>I notice most of the techniques I've described are conservative:\nthey're aimed at preserving the character of the site rather than\nenhancing it.  I don't think that's a bias of mine.  It's due to\nthe shape of the problem.  Hacker News had the good fortune to start\nout good, so in this case it's literally a matter of preservation.\nBut I think this principle would also apply to sites with different\norigins.<br/><br/>The good things in a community site come from people more than\ntechnology; it's mainly in the prevention of bad things that\ntechnology comes into play. Technology certainly can enhance\ndiscussion.  Nested comments do, for example.  But I'd rather use\na site with primitive features and smart, nice users than a more\nadvanced one whose users were idiots or <a href=\"https://paulgraham.com/trolls.html\">trolls</a>.<br/><br/>So the most important thing a community site can do is attract the\nkind of people it wants.  A site trying to be as big as possible\nwants to attract everyone.  But a site aiming at a particular subset\nof users has to attract just those—and just as importantly,\nrepel everyone else.  I've made a conscious effort to do this on\nHN.  The graphic design is as plain as possible, and the site rules\ndiscourage dramatic link titles.  The goal is that the only thing\nto interest someone arriving at HN for the first time should be the\nideas expressed there.<br/><br/>The downside of tuning a site to attract certain people is that,\nto those people, it can be too attractive.  I'm all too aware how\naddictive Hacker News can be.  For me, as for many users, it's a\nkind of virtual town square.  When I want to take a break from\nworking, I walk into the square, just as I might into Harvard Square\nor University Ave in the physical world.\n<font color=\"#999999\">[<a href=\"https://paulgraham.com/hackernews.html#f7n\"><font color=\"#999999\">7</font></a>]</font>\nBut an online square is\nmore dangerous than a physical one.  If I spent half the day loitering\non University Ave, I'd notice.  I have to walk a mile to get there,\nand sitting in a cafe feels different from working. But visiting\nan online forum takes just a click, and feels superficially very\nmuch like working.  You may be wasting your time, but you're not\nidle.  Someone is <a href=\"http://xkcd.com/386/\">wrong</a> on the Internet, and you're fixing the\nproblem.<br/><br/>Hacker News is definitely useful.  I've learned a lot from things\nI've read on HN.  I've written several essays that began as comments\nthere.  So I wouldn't want the site to go away.  But I would like\nto be sure it's not a net drag on productivity.  What a disaster\nthat would be, to attract thousands of smart people to a site that\ncaused them to waste lots of time.  I wish I could be 100% sure\nthat's not a description of HN.<br/><br/>I feel like the addictiveness of games and social applications is\nstill a mostly unsolved problem.  The situation now is like it was\nwith crack in the 1980s: we've invented terribly addictive new\nthings, and we haven't yet evolved ways to protect ourselves from\nthem.  We will eventually, and that's one of the problems I hope\nto focus on next.<br/><br/><br/><br/><br/><br/>\n<b>Notes</b><br/><br/>[<a name=\"f1n\"><font color=\"#000000\">1</font></a>]\nI tried ranking users by both average and median comment\nscore, and average (with the high score thrown out) seemed the more\naccurate predictor of high quality.  Median may be the more accurate\npredictor of low quality though.<br/><br/>[<a name=\"f2n\"><font color=\"#000000\">2</font></a>]\nAnother thing I learned from this experiment is that if you're\ngoing to distinguish between people, you better be sure you do it\nright.  This is one problem where rapid prototyping doesn't work.<br/><br/>Indeed, that's the intellectually honest argument for not discriminating\nbetween various types of people.  The reason not to do it is not\nthat everyone's the same, but that it's bad to do wrong and hard\nto do right.<br/><br/>[<a name=\"f3n\"><font color=\"#000000\">3</font></a>]\nWhen I catch egregiously linkjacked posts I replace the url\nwith that of whatever they copied.  Sites that habitually linkjack\nget banned.<br/><br/>[<a name=\"f4n\"><font color=\"#000000\">4</font></a>]\nDigg is notorious for its lack of transparency.  The root of\nthe problem is not that the guys running Digg are especially sneaky,\nbut that they use the wrong algorithm for generating their frontpage.\nInstead of bubbling up from the bottom as they get more votes, as\non Reddit, stories start at the top and get pushed down by new\narrivals.<br/><br/>The reason for the difference is that Digg is derived from Slashdot,\nwhile Reddit is derived from Delicious/popular.  Digg is Slashdot\nwith voting instead of editors, and Reddit is Delicious/popular\nwith voting instead of bookmarking.  (You can still see fossils of\ntheir origins in their graphic design.)<br/><br/>Digg's algorithm is very vulnerable to gaming, because any story\nthat makes it onto the frontpage is the new top story.  Which in\nturn forces Digg to respond with extreme countermeasures.  A lot\nof startups have some kind of secret about the subterfuges they had\nto resort to in the early days, and I suspect Digg's is the extent\nto which the top stories were de facto chosen by human editors.<br/><br/>[<a name=\"f5n\"><font color=\"#000000\">5</font></a>]\nThe dialog on Beavis and Butthead was composed largely of\nthese, and when I read comments on really bad sites I can hear them\nin their voices.<br/><br/>[<a name=\"f6n\"><font color=\"#000000\">6</font></a>]\nI suspect most of the techniques for discouraging stupid\ncomments have yet to be discovered.  Xkcd implemented a particularly\nclever one in its IRC channel: don't allow the same thing twice.\nOnce someone has said \"fail,\" no one can ever say it again.  This\nwould penalize short comments especially, because they have less\nroom to avoid collisions in.<br/><br/>Another promising idea is the <a href=\"http://stupidfilter.org\">stupid \nfilter</a>, which is just like a\nprobabilistic spam filter, but trained on corpora of stupid and\nnon-stupid comments instead.<br/><br/>You may not have to kill bad comments to solve the problem.  Comments\nat the bottom of a long thread are rarely seen, so it may be enough\nto incorporate a prediction of quality in the comment sorting\nalgorithm.<br/><br/>[<a name=\"f7n\"><font color=\"#000000\">7</font></a>]\nWhat makes most suburbs so demoralizing is that there's no\ncenter to walk to.<br/><br/>\n<b>Thanks</b> to Justin Kan, Jessica Livingston, Robert Morris,\nAlexis Ohanian, Emmet Shear, and Fred Wilson for reading drafts of\nthis.<br/><br/><img src=\"http://ycombinator.com/images/y18.gif\"/>\n<a href=\"http://news.ycombinator.com/item?id=495053\">Comment</a> on this essay.<br/><br/><br/><br/></font>","date":"2009-02-01T00:00:00Z"}